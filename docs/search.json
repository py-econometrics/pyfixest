[
  {
    "objectID": "benchmarks/readme.html",
    "href": "benchmarks/readme.html",
    "title": "",
    "section": "",
    "text": "All benchmarks follow fixest’s benchmarks, which you can find here. PyFixest benchmarks were run on a Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz, 2304Mhz, 4 Core(s), 8 Logical Processor(s). Timings for R, Stata and Julia programs are taken from the fixest’s benchmarks.\nTo run the python benchmarks, you need to install the following packages: - pyfixest - pandas - numpy - tqdm First, you need to create the data by running the data_generation.R files. This will populate the _STATA and data folders. Then, you can run the run_benchmarks.ipynb notebook to run the benchmarks. This will populate the results_py.csv file. Finally, you can run the plot_benchmarks.ipynb notebook to generate the plots."
  },
  {
    "objectID": "benchmarks/run_benchmarks.html",
    "href": "benchmarks/run_benchmarks.html",
    "title": "",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\nimport time\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.estimation import feols, fepois\nfrom tqdm import tqdm  # note: tqdm is not a dependency of pyfixest\n\n\ndef run_standard_benchmark(model, fixed_effect):\n    \"\"\"\n    Runs the fixest standard benchmark.\n    Args:\n        model (str): \"feols\" or \"fepois\"\n        fixed_effect (str): \"dum_1\" or \"dum_1+dum_2\" or \"dum_1+dum_2+dum_3\"\n    Returns:\n        A pd.DataFrame with the results.\n    \"\"\"\n\n    assert model in [\"feols\", \"fepois\"]\n    assert fixed_effect in [\"dum_1\", \"dum_1+dum_2\", \"dum_1+dum_2+dum_3\"]\n\n    # one fixed effect\n    res = []\n\n    if model == \"feols\":\n        fml_base = \"ln_y ~ X1\"\n        model2 = \"Gaussian\"\n    else:\n        fml_base = \"y ~ X1\"\n        model2 = \"Poisson\"\n\n    fml = f\"{fml_base} | {fixed_effect}\"\n\n    # warmup\n    df = pd.read_stata(f\"./data/_STATA/base_s2_r1.dta\")\n    feols(fml, data=df)\n\n    for size in tqdm(range(1, 6)):\n        if size == 5:\n            if model == \"fepois\":\n                pass\n            else:\n                df = pd.read_csv(\"./data/data/base_10M.csv\")\n\n        for rep in range(1, 11):\n            if size < 5:\n                df = pd.read_stata(f\"./data/_STATA/base_s{size}_r{rep}.dta\")\n\n            tic = time.time()\n            if model == \"feols\":\n                feols(fml, data=df)\n            else:\n                fepois(fml, data=df)\n            toc = time.time()\n\n            res.append(\n                pd.Series(\n                    {\n                        \"method\": model,\n                        \"n_obs\": df.shape[0],\n                        \"G\": len(fixed_effect.split(\"+\")),\n                        \"rep\": rep,\n                        \"time\": toc - tic,\n                    }\n                )\n            )\n\n    return pd.concat(res, axis=1).T\n\n\ndef run_all_benchmarks():\n    \"\"\"\n    Run all the benchmarks.\n    \"\"\"\n\n    res = pd.DataFrame()\n    for model in [\"feols\", \"fepois\"]:\n        for fixef in [\"dum_1\", \"dum_1+dum_2\", \"dum_1+dum_2+dum_3\"]:\n            res = pd.concat([res, run_standard_benchmark(model, fixef)], axis=1)\n\n    res.to_csv(\"./results_py.csv\")\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\nrun_all_benchmarks()\n\n100%|██████████| 3/3 [00:00<00:00,  3.54it/s]\n100%|██████████| 3/3 [00:00<00:00,  3.33it/s]\n\n\n\na = run_standard_benchmark(\"feols\", \"dum_1\")\na\n\n100%|██████████| 3/3 [00:00<00:00,  3.61it/s]\n\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n    \n  \n  \n    \n      0\n      feols\n      1000\n      1\n      1\n      0.011204\n    \n    \n      1\n      feols\n      1000\n      1\n      2\n      0.009486\n    \n    \n      2\n      feols\n      1000\n      1\n      3\n      0.010987\n    \n    \n      3\n      feols\n      1000\n      1\n      4\n      0.010687\n    \n    \n      4\n      feols\n      1000\n      1\n      5\n      0.011018\n    \n    \n      5\n      feols\n      1000\n      1\n      6\n      0.009798\n    \n    \n      6\n      feols\n      1000\n      1\n      7\n      0.008976\n    \n    \n      7\n      feols\n      1000\n      1\n      8\n      0.008977\n    \n    \n      8\n      feols\n      1000\n      1\n      9\n      0.008486\n    \n    \n      9\n      feols\n      1000\n      1\n      10\n      0.007978\n    \n    \n      10\n      feols\n      10000\n      1\n      1\n      0.01097\n    \n    \n      11\n      feols\n      10000\n      1\n      2\n      0.012004\n    \n    \n      12\n      feols\n      10000\n      1\n      3\n      0.013207\n    \n    \n      13\n      feols\n      10000\n      1\n      4\n      0.011819\n    \n    \n      14\n      feols\n      10000\n      1\n      5\n      0.010875\n    \n    \n      15\n      feols\n      10000\n      1\n      6\n      0.011104\n    \n    \n      16\n      feols\n      10000\n      1\n      7\n      0.009973\n    \n    \n      17\n      feols\n      10000\n      1\n      8\n      0.009973\n    \n    \n      18\n      feols\n      10000\n      1\n      9\n      0.01097\n    \n    \n      19\n      feols\n      10000\n      1\n      10\n      0.009974\n    \n    \n      20\n      feols\n      100000\n      1\n      1\n      0.042234\n    \n    \n      21\n      feols\n      100000\n      1\n      2\n      0.04016\n    \n    \n      22\n      feols\n      100000\n      1\n      3\n      0.043736\n    \n    \n      23\n      feols\n      100000\n      1\n      4\n      0.049093\n    \n    \n      24\n      feols\n      100000\n      1\n      5\n      0.052659\n    \n    \n      25\n      feols\n      100000\n      1\n      6\n      0.048541\n    \n    \n      26\n      feols\n      100000\n      1\n      7\n      0.051272\n    \n    \n      27\n      feols\n      100000\n      1\n      8\n      0.044816\n    \n    \n      28\n      feols\n      100000\n      1\n      9\n      0.041823\n    \n    \n      29\n      feols\n      100000\n      1\n      10\n      0.044947\n    \n  \n\n\n\n\n\na.T\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n      method\n      n_obs\n      G\n      rep\n      time\n      ...\n      method\n      n_obs\n      G\n      rep\n      time\n      method\n      n_obs\n      G\n      rep\n      time\n    \n  \n  \n    \n      0\n      feols\n      1000\n      1\n      1\n      0.009973\n      feols\n      1000\n      1\n      2\n      0.01043\n      ...\n      feols\n      10000000\n      2\n      9\n      10.188134\n      feols\n      10000000\n      2\n      10\n      10.136924\n    \n  \n\n1 rows × 500 columns\n\n\n\n\n\n\nres_all = pd.concat(\n    [\n        pd.read_csv(\"./benchmarks/results_py.csv\"),\n        pd.read_csv(\"./benchmarks/results_all.txt\"),\n    ]\n)\n\n\nres_all\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n      model\n    \n  \n  \n    \n      0\n      fepois\n      1000.0\n      1\n      1\n      0.060000\n      Poisson\n    \n    \n      1\n      glmmboot\n      1000.0\n      1\n      1\n      0.020000\n      Poisson\n    \n    \n      2\n      feglm (alpaca)\n      1000.0\n      1\n      1\n      0.020000\n      Poisson\n    \n    \n      3\n      fepois\n      1000.0\n      1\n      2\n      0.030000\n      Poisson\n    \n    \n      4\n      glmmboot\n      1000.0\n      1\n      2\n      0.010000\n      Poisson\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1575\n      FixedEffectModels\n      10000000.0\n      3\n      6\n      6.800669\n      Gaussian\n    \n    \n      1576\n      FixedEffectModels\n      10000000.0\n      3\n      7\n      6.756505\n      Gaussian\n    \n    \n      1577\n      FixedEffectModels\n      10000000.0\n      3\n      8\n      6.802480\n      Gaussian\n    \n    \n      1578\n      FixedEffectModels\n      10000000.0\n      3\n      9\n      6.761793\n      Gaussian\n    \n    \n      1579\n      FixedEffectModels\n      10000000.0\n      3\n      10\n      6.759143\n      Gaussian\n    \n  \n\n1580 rows × 6 columns"
  },
  {
    "objectID": "benchmarks/visualise_benchmarks.html",
    "href": "benchmarks/visualise_benchmarks.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n\nres_py = pd.read_csv(\"./results_py.csv\")\nres_py[\"model\"] = np.where(res_py[\"method\"] == \"feols\", \"Gaussian\", \"Poisson\")\nres_py[\"method\"] = \"pyfixest\"\nres_other = pd.read_csv(\"./results_all.txt\")\nres_all = pd.concat([res_py, res_other], axis=0)\n\n\nres_all.method.unique()\n\narray(['pyfixest', 'fepois', 'glmmboot', 'feglm (alpaca)', 'ppmlhdfe',\n       'fenegbin', 'glmnb', 'nbreg', 'feglm (fixest)', 'logit', 'feols',\n       'lfe', 'reghdfe', 'FixedEffectModels'], dtype=object)\n\n\n\nres_agg = (\n    res_all.groupby([\"method\", \"n_obs\", \"G\", \"model\"]).mean()[\"time\"].reset_index()\n)\nres_agg[\"G\"] = res_agg[\"G\"].apply(lambda x: f\"{x} FE\")\nres_agg[\"method\"] = pd.Categorical(\n    res_agg[\"method\"],\n    [\n        \"pyfixest\",\n        \"feols\",\n        \"reghdfe\",\n        \"lfe\",\n        \"FixedEffectModels\",\n        \"fepois\",\n        \"glmmboot\",\n        \"ppmlhdfe\",\n        \"feglm (alpaca)\",\n    ],\n)\n\n\nplot_ols = (\n    ggplot(\n        res_agg[res_agg[\"model\"] == \"Gaussian\"],\n        aes(x=\"n_obs\", y=\"time\", color=\"method\"),\n    )\n    + geom_line()\n    + geom_point()\n    + facet_wrap(\"G\", nrow=1)\n    + scale_x_discrete()\n    + scale_y_continuous(trans=\"log10\", limits=(0, 120))\n    + ylab(\"Time in Seconds\")\n    + xlab(\"Number of Observations\")\n    + ggtitle(\"Fixest Standard Benchmark for OLS\")\n    + ggsize(1000, 500)\n)\nggsave(plot_ols, filename=\"benchmarks_ols.svg\")\n\n\nplot_ols\n\n\n  \n  \n    \n    \n    \n      \n        \n        1 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n            \n            0.01\n            \n          \n        \n        \n          \n            \n            0.03\n            \n          \n        \n        \n          \n            \n            0.10\n            \n          \n        \n        \n          \n            \n            0.3\n            \n          \n        \n        \n          \n            \n            1.0\n            \n          \n        \n        \n          \n            \n            3\n            \n          \n        \n        \n          \n            \n            10\n            \n          \n        \n        \n          \n            \n            32\n            \n          \n        \n        \n          \n            \n            100\n            \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        2 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        3 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n      Fixest Standard Benchmark for OLS\n      \n    \n    \n      \n      Time in Seconds\n      \n    \n    \n      \n      Number of Observations\n      \n    \n    \n      \n      \n      \n        \n          \n          method\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              FixedEffectModels\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              feols\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              lfe\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              pyfixest\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              reghdfe\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nplot_poisson = (\n    ggplot(\n        res_agg[(res_agg[\"model\"] == \"Poisson\") & (res_agg.n_obs < 1e07)],\n        aes(x=\"n_obs\", y=\"time\", color=\"method\"),\n    )\n    + geom_line()\n    + geom_point()\n    + facet_wrap(\"G\", nrow=1)\n    + scale_x_discrete()\n    + scale_y_continuous(trans=\"log10\", limits=(0, 120))\n    + ylab(\"Time in Seconds\")\n    + xlab(\"Number of Observations\")\n    + ggtitle(\"Fixest Standard Benchmark for Poisson Regression\")\n    + ggsize(1000, 500)\n)\n\nggsave(plot_poisson, filename=\"benchmarks_poisson.svg\")\n\nplot_poisson\n\n\n  \n  \n    \n    \n    \n      \n        \n        1 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n            \n            0.03\n            \n          \n        \n        \n          \n            \n            0.10\n            \n          \n        \n        \n          \n            \n            0.3\n            \n          \n        \n        \n          \n            \n            1.0\n            \n          \n        \n        \n          \n            \n            3\n            \n          \n        \n        \n          \n            \n            10\n            \n          \n        \n        \n          \n            \n            32\n            \n          \n        \n        \n          \n            \n            100\n            \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        2 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        3 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n      Fixest Standard Benchmark for Poisson Regression\n      \n    \n    \n      \n      Time in Seconds\n      \n    \n    \n      \n      Number of Observations\n      \n    \n    \n      \n      \n      \n        \n          \n          method\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              feglm (alpaca)\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              fepois\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              glmmboot\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              ppmlhdfe\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              pyfixest"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "",
    "section": "",
    "text": "Copyright (c) 2022 pyfixest authors\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "reference/demean.html",
    "href": "reference/demean.html",
    "title": "",
    "section": "",
    "text": "demean\n\n\n\n\n\nName\nDescription\n\n\n\n\ndemean\nWorkhorse for demeaning an input array x based on the specified fixed effects and weights\n\n\ndemean_model\nDemeans a single regression model via the alterating projections algorithm (see demean function).\n\n\n\n\n\ndemean.demean(x, flist, weights, tol=1e-08, maxiter=100000)\nWorkhorse for demeaning an input array x based on the specified fixed effects and weights via the alternating projections algorithm.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnumpy.numpy.ndarray\nInput array of shape (n_samples, n_features). Needs to be of type float.\nrequired\n\n\nflist\nnumpy.numpy.ndarray\nArray of shape (n_samples, n_factors) specifying the fixed effects. Needs to already be converted to integers.\nrequired\n\n\nweights\nnumpy.numpy.ndarray\nArray of shape (n_samples,) specifying the weights.\nrequired\n\n\ntol\nfloat\nTolerance criterion for convergence. Defaults to 1e-08.\n1e-08\n\n\nmaxiter\nint\nMaximum number of iterations. Defaults to 100_000.\n100000\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.Tuple[numpy.numpy.ndarray, bool]\nA tuple containing the demeaned array of shape (n_samples, n_features) and a boolean indicating whether the algorithm converged successfully.\n\n\n\n\n\n\n\ndemean.demean_model(Y, X, fe, weights, lookup_demeaned_data, na_index_str)\nDemeans a single regression model via the alterating projections algorithm (see demean function). Prior to demeaning, the function checks if some of the variables have already been demeaned and uses values from the cache lookup_demeaned_data if possible. If the model has no fixed effects, the function does not demean the data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nY\npandas.pandas.DataFrame\nA DataFrame of the dependent variable.\nrequired\n\n\nX\npandas.pandas.DataFrame\nA DataFrame of the covariates.\nrequired\n\n\nfe\npandas.pandas.DataFrame or None\nA DataFrame of the fixed effects. None if no fixed effects specified.\nrequired\n\n\nweights\nnumpy.numpy.ndarray or None\nA numpy array of weights. None if no weights.\nrequired\n\n\nlookup_demeaned_data\ntyping.Dict[str, typing.Any]\nA dictionary with keys for each fixed effects combination and potentially values of demeaned data frames. The function checks this dictionary to see if some of the variables have already been demeaned.\nrequired\n\n\nna_index_str\nstr\nA string with indices of dropped columns. Used for caching of demeaned variables.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntyping.Tuple[pandas.pandas.DataFrame, pandas.pandas.DataFrame, typing.Optional[pandas.pandas.DataFrame]]\nA tuple of the following elements: - Yd : pd.DataFrame A DataFrame of the demeaned dependent variable. - Xd : pd.DataFrame A DataFrame of the demeaned covariates. - Id : pd.DataFrame or None A DataFrame of the demeaned Instruments. None if no IV."
  },
  {
    "objectID": "reference/detect_singletons.html",
    "href": "reference/detect_singletons.html",
    "title": "",
    "section": "",
    "text": "detect_singletons\n\n\n\n\n\nName\nDescription\n\n\n\n\ndetect_singletons\nDetect singleton fixed effects in a dataset.\n\n\n\n\n\ndetect_singletons.detect_singletons(ids)\nDetect singleton fixed effects in a dataset.\nThis function iterates over the columns of a 2D numpy array representing fixed effects to identify singleton fixed effects. An observation is considered a singleton if it is the only one in its group (fixed effect identifier).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nids\nnumpy.numpy.ndarray\nA 2D numpy array representing fixed effects, with a shape of (n_samples, n_features). Elements should be non-negative integers representing fixed effect identifiers.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.ndarray\nA boolean array of shape (n_samples,), indicating which observations have a singleton fixed effect.\n\n\n\n\n\n\nThe algorithm iterates over columns to identify fixed effects. After each column is processed, it updates the record of non-singleton rows. This approach accounts for the possibility that removing an observation in one column can lead to the emergence of new singletons in subsequent columns.\nFor performance reasons, the input array should be in column-major order. Operating on a row-major array can lead to significant performance losses."
  },
  {
    "objectID": "reference/estimation.feols.html",
    "href": "reference/estimation.feols.html",
    "title": "",
    "section": "",
    "text": "estimation.feols(fml, data, vcov=None, ssc=ssc(), fixef_rm='none', collin_tol=1e-10, drop_intercept=False, i_ref1=None, i_ref2=None)\nEstimate linear regression models with fixed effects using fixest formula syntax.\nThis method accommodates complex models with stepwise regressions, multiple dependent variables, interaction of variables, interacted fixed effects, and instruments. It’s compatible with various syntax elements from the formulaic module.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nA three-sided formula string using fixest formula syntax. Syntax: “Y ~ X1 + X2 | FE1 + FE2 | X1 ~ Z1”. “|” separates dependent variable, fixed effects, and instruments. Special syntax includes stepwise regressions, cumulative stepwise regression, multiple dependent variables, interaction of variables (i(X1,X2)), and interacted fixed effects (fe1^fe2).\nrequired\n\n\ndata\npyfixest.dev_utils.DataFrameType\nA pandas or polars dataframe containing the variables in the formula.\nrequired\n\n\nvcov\ntyping.Union[str, dict[str, str]]\nType of variance-covariance matrix for inference. Options include “iid”, “hetero”, “HC1”, “HC2”, “HC3”, or a dictionary for CRV1/CRV3 inference.\nNone\n\n\nssc\nstr\nA ssc object specifying the small sample correction for inference.\nssc()\n\n\nfixef_rm\nstr\nSpecifies whether to drop singleton fixed effects. Options: “none” (default), “singleton”.\n'none'\n\n\ncollin_tol\nfloat\nTolerance for collinearity check, by default 1e-06.\n1e-10\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model, by default False.\nFalse\n\n\ni_ref1\ntyping.Optional[typing.Union[list, str]]\nReference category for the first set of categorical variables interacted via “i()”, by default None.\nNone\n\n\ni_ref2\ntyping.Optional[typing.Union[list, str]]\nReference category for the second set of categorical variables interacted via “i()”, by default None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nAn instance of the Feols class or FixestMulti class for multiple models specified via fml.\n\n\n\n\n\n\nAs in fixest, the feols function can be used to estimate a simple linear regression model with fixed effects. The following example regresses Y on X1 and X2 with fixed effects for f1 and f2: fixed effects are specified after the | symbol.\n\nfrom pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\nfrom pyfixest.summarize import etable\n\ndata = get_data()\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.summary()\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.924 |        0.061 |   -15.165 |      0.000 |  -1.049 |   -0.799 |\n| X2            |     -0.174 |        0.015 |   -11.918 |      0.000 |  -0.204 |   -0.144 |\n---\nRMSE: 1.346   R2: 0.659   R2 Within: 0.303\n\n\nCalling feols() returns an instance of the Feols class. The summary() method can be used to print the results.\nAn alternative way to retrieve model results is via the tidy() method, which returns a pandas dataframe with the estimated coefficients, standard errors, t-statistics, and p-values.\n\nfit.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      X1\n      -0.924046\n      0.060934\n      -15.164621\n      2.664535e-15\n      -1.048671\n      -0.799421\n    \n    \n      X2\n      -0.174107\n      0.014608\n      -11.918277\n      1.069367e-12\n      -0.203985\n      -0.144230\n    \n  \n\n\n\n\nYou can also access all elements in the tidy data frame by dedicated methods, e.g. fit.coef() for the coefficients, fit.se() for the standard errors, fit.tstat() for the t-statistics, and fit.pval() for the p-values, and fit.confint() for the confidence intervals.\nThe employed type of inference can be specified via the vcov argument. If vcov is not provided, PyFixest employs the fixest default of iid inference, unless there are fixed effects in the model, in which case feols() clusters the standard error by the first fixed effect (CRV1 inference).\n\nfit1 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov=\"iid\")\nfit2 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov=\"hetero\")\nfit3 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov={\"CRV1\": \"f1\"})\n\nSupported inference types are “iid”, “hetero”, “HC1”, “HC2”, “HC3”, and “CRV1”/“CRV3”. Clustered standard errors are specified via a dictionary, e.g. {\"CRV1\": \"f1\"} for CRV1 inference with clustering by f1 or {\"CRV3\": \"f1\"} for CRV3 inference with clustering by f1. For two-way clustering, you can provide a formula string, e.g. {\"CRV1\": \"f1 + f2\"} for CRV1 inference with clustering by f1.\n\nfit4 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov={\"CRV1\": \"f1 + f2\"})\n\nInference can be adjusted post estimation via the vcov method:\n\nfit.summary()\nfit.vcov(\"iid\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.924 |        0.061 |   -15.165 |      0.000 |  -1.049 |   -0.799 |\n| X2            |     -0.174 |        0.015 |   -11.918 |      0.000 |  -0.204 |   -0.144 |\n---\nRMSE: 1.346   R2: 0.659   R2 Within: 0.303\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.924 |        0.054 |   -16.995 |      0.000 |  -1.031 |   -0.817 |\n| X2            |     -0.174 |        0.014 |   -12.081 |      0.000 |  -0.202 |   -0.146 |\n---\nRMSE: 1.346   R2: 0.659   R2 Within: 0.303\n\n\nThe ssc argument specifies the small sample correction for inference. In general, feols() uses all of fixest::feols() defaults, but sets the fixef.K argument to \"none\" whereas the fixest::feols() default is \"nested\". See here for more details: link to github.\nfeols() supports a range of multiple estimation syntax, i.e. you can estimate multiple models in one call. The following example estimates two models, one with fixed effects for f1 and one with fixed effects for f2 using the sw() syntax.\n\nfit = feols(\"Y ~ X1 + X2 | sw(f1, f2)\", data)\ntype(fit)\n\npyfixest.FixestMulti.FixestMulti\n\n\nThe returned object is an instance of the FixestMulti class. You can access the results of the first model via fit.fetch_model(0) and the results of the second model via fit.fetch_model(1). You can compare the model results via the etable() function:\n\netable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f2\n                           est1               est2\n------------  -----------------  -----------------\ndepvar                        Y                  Y\n--------------------------------------------------\nX1             -0.95*** (0.067)  -0.979*** (0.077)\nX2            -0.174*** (0.018)  -0.175*** (0.022)\n--------------------------------------------------\nf1                            x                  -\nf2                            -                  x\n--------------------------------------------------\nR2                        0.489              0.354\nS.E. type                by: f1             by: f2\nObservations                997                998\n--------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nOther supported multiple estimation syntax include sw0(), csw() and csw0(). While sw() adds variables in a “stepwise” fashinon, csw() does so cumulatively.\n\nfit = feols(\"Y ~ X1 + X2 | csw(f1, f2)\", data)\netable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f1+f2\n                           est1               est2\n------------  -----------------  -----------------\ndepvar                        Y                  Y\n--------------------------------------------------\nX1             -0.95*** (0.067)  -0.924*** (0.061)\nX2            -0.174*** (0.018)  -0.174*** (0.015)\n--------------------------------------------------\nf1                            x                  x\nf2                            -                  x\n--------------------------------------------------\nR2                        0.489              0.659\nS.E. type                by: f1             by: f1\nObservations                997                997\n--------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nThe sw0() and csw0() syntax are similar to sw() and csw(), but start with a model that exludes the variables specified in sw() and csw():\n\nfit = feols(\"Y ~ X1 + X2 | sw0(f1, f2)\", data)\netable([fit.fetch_model(0), fit.fetch_model(1), fit.fetch_model(2)])\n\nModel:  Y~X1+X2\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f2\n                           est1               est2               est3\n------------  -----------------  -----------------  -----------------\ndepvar                        Y                  Y                  Y\n---------------------------------------------------------------------\nIntercept      0.889*** (0.108)\nX1            -0.993*** (0.082)   -0.95*** (0.067)  -0.979*** (0.077)\nX2            -0.176*** (0.022)  -0.174*** (0.018)  -0.175*** (0.022)\n---------------------------------------------------------------------\nf1                            -                  x                  -\nf2                            -                  -                  x\n---------------------------------------------------------------------\nR2                        0.177              0.489              0.354\nS.E. type                   iid             by: f1             by: f2\nObservations                998                997                998\n---------------------------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nThe feols() function also supports multiple dependent variables. The following example estimates two models, one with Y1 as the dependent variable and one with Y2 as the dependent variable.\n\nfit = feols(\"Y + Y2 ~ X1 | f1 + f2\", data)\netable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1|f1+f2\nModel:  Y2~X1|f1+f2\n                           est1               est2\n------------  -----------------  -----------------\ndepvar                        Y                 Y2\n--------------------------------------------------\nX1            -0.919*** (0.065)  -1.228*** (0.195)\n--------------------------------------------------\nf1                            x                  x\nf2                            x                  x\n--------------------------------------------------\nR2                        0.609              0.168\nS.E. type                by: f1             by: f1\nObservations                997                998\n--------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nIt is possible to combine different multiple estimation operators:\n\nfit = feols(\"Y + Y2 ~ X1 | sw(f1, f2)\", data)\netable([fit.fetch_model(0), fit.fetch_model(1), fit.fetch_model(2), fit.fetch_model(3)])\n\nModel:  Y~X1|f1\nModel:  Y2~X1|f1\nModel:  Y~X1|f2\nModel:  Y2~X1|f2\n                           est1               est2               est3               est4\n------------  -----------------  -----------------  -----------------  -----------------\ndepvar                        Y                 Y2                  Y                 Y2\n----------------------------------------------------------------------------------------\nX1            -0.949*** (0.069)  -1.266*** (0.176)  -0.982*** (0.081)  -1.301*** (0.205)\n----------------------------------------------------------------------------------------\nf1                            x                  x                  -                  -\nf2                            -                  -                  x                  x\n----------------------------------------------------------------------------------------\nR2                        0.437              0.115              0.302               0.09\nS.E. type                by: f1             by: f1             by: f2             by: f2\nObservations                997                998                998                999\n----------------------------------------------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nIn general, using muliple estimation syntax can improve the estimation time as covariates that are demeaned in one model and are used in another model do not need to be demeaned again: feols() implements a caching mechanism that stores the demeaned covariates.\nBesides OLS, feols() also supports IV estimation via three part formulas:\n\nfit = feols(\"Y ~  X2 | f1 + f2 | X1 ~ Z1\", data)\nfit.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      X1\n      -1.050097\n      0.085493\n      -12.282912\n      5.133671e-13\n      -1.224949\n      -0.875245\n    \n    \n      X2\n      -0.174351\n      0.014779\n      -11.797039\n      1.369793e-12\n      -0.204578\n      -0.144124\n    \n  \n\n\n\n\nHere, X1 is the endogenous variable and Z1 is the instrument. f1 and f2 are the fixed effects, as before. To estimate IV models without fixed effects, simply omit the fixed effects part of the formula:\n\nfit = feols(\"Y ~  X2 | X1 ~ Z1\", data)\nfit.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      0.861939\n      0.151187\n      5.701137\n      1.567858e-08\n      0.565257\n      1.158622\n    \n    \n      X1\n      -0.967238\n      0.130078\n      -7.435847\n      2.238210e-13\n      -1.222497\n      -0.711980\n    \n    \n      X2\n      -0.176416\n      0.021769\n      -8.104001\n      1.554312e-15\n      -0.219134\n      -0.133697\n    \n  \n\n\n\n\nLast, feols() supports interaction of variables via the i() syntax. Documentation on this is tba.\nAfter fitting a model via feols(), you can use the predict() method to get the predicted values:\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.predict()[0:5]\n\narray([ 3.0633663 , -0.69574133, -0.91240433, -0.46370257, -1.67331154])\n\n\nThe predict() method also supports a newdata argument to predict on new data, which returns a numpy array of the predicted values:\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.predict(newdata=data)[0:5]\n\narray([ 2.14598765,         nan,         nan,  3.0633663 , -0.69574133])\n\n\nLast, you can plot the results of a model via the coefplot() method:\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.coefplot()"
  },
  {
    "objectID": "reference/estimation.fepois.html",
    "href": "reference/estimation.fepois.html",
    "title": "",
    "section": "",
    "text": "estimation.fepois(fml, data, vcov=None, ssc=ssc(), fixef_rm='none', iwls_tol=1e-08, iwls_maxiter=25, collin_tol=1e-10, drop_intercept=False, i_ref1=None, i_ref2=None)\nEstimate Poisson regression models with fixed effects using the pplmhdfe algorithm.\nThis method is based on the Stata package of the same name and supports various features like stepwise regressions, cumulative stepwise regression, multiple dependent variables, interaction of variables, and interacted fixed effects.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nA two-sided formula string using fixest formula syntax. Syntax: “Y ~ X1 + X2 | FE1 + FE2”. “|” separates left-hand side and fixed effects. Special syntax includes: - Stepwise regressions (sw, sw0) - Cumulative stepwise regression (csw, csw0) - Multiple dependent variables (Y1 + Y2 ~ X) - Interaction of variables (i(X1,X2)) - Interacted fixed effects (fe1^fe2) Compatible with formula parsing via the formulaic module.\nrequired\n\n\ndata\npyfixest.dev_utils.DataFrameType\nA pandas or polars dataframe containing the variables in the formula.\nrequired\n\n\nvcov\ntyping.Union[str, dict[str, str]]\nType of variance-covariance matrix for inference. Options include “iid”, “hetero”, “HC1”, “HC2”, “HC3”, or a dictionary for CRV1/CRV3 inference.\nNone\n\n\nssc\nstr\nA ssc object specifying the small sample correction for inference.\nssc()\n\n\nfixef_rm\nstr\nSpecifies whether to drop singleton fixed effects. Options: “none” (default), “singleton”.\n'none'\n\n\niwls_tol\ntyping.Optional[float]\nTolerance for IWLS convergence, by default 1e-08.\n1e-08\n\n\niwls_maxiter\ntyping.Optional[float]\nMaximum number of iterations for IWLS convergence, by default 25.\n25\n\n\ncollin_tol\nfloat\nTolerance for collinearity check, by default 1e-06.\n1e-10\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model, by default False.\nFalse\n\n\ni_ref1\ntyping.Optional[typing.Union[list, str]]\nReference category for the first set of categorical variables interacted via “i()”, by default None.\nNone\n\n\ni_ref2\ntyping.Optional[typing.Union[list, str]]\nReference category for the second set of categorical variables interacted via “i()”, by default None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nAn instance of the Fepois class or an instance of class FixestMulti for multiple models specified via fml.\n\n\n\n\n\n\nThe fepois() function can be used to estimate a simple Poisson regression model with fixed effects. The following example regresses Y on X1 and X2 with fixed effects for f1 and f2: fixed effects are specified after the | symbol.\n\nfrom pyfixest.estimation import fepois\nfrom pyfixest.utils import get_data\nfrom pyfixest.summarize import etable\n\ndata = get_data(model = \"Fepois\")\nfit = fepois(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.summary()\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.008 |        0.035 |    -0.239 |      0.811 |  -0.076 |    0.060 |\n| X2            |     -0.015 |        0.010 |    -1.471 |      0.141 |  -0.035 |    0.005 |\n---\nDeviance: 1068.836\n\n\nFor more examples, please take a look at the documentation of the feols() function."
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "",
    "section": "",
    "text": "User facing estimation functions\n\n\n\nestimation.feols\nEstimate linear regression models with fixed effects using fixest formula syntax.\n\n\nestimation.fepois\nEstimate Poisson regression models with fixed effects using the pplmhdfe algorithm.\n\n\ndid.estimation.did2s\nEstimate a Difference-in-Differences model using Gardner’s two-step DID2S estimator.\n\n\ndid.estimation.lpdid\nEstimate a Difference-in-Differences / Event Study Model via the Local Projections Approach.\n\n\n\n\n\n\nPost-Processing of Estimation Results\n\n\n\nsummarize.summary\n# Summary\n\n\nsummarize.etable\nCreate an esttab-like table from a list of models#\n\n\nvisualize.coefplot\n# coefplot\n\n\nvisualize.iplot\n# iplot\n\n\n\n\n\n\nPyFixest internals and utilities\n\n\n\ndemean\n\n\n\ndetect_singletons\n\n\n\nmodel_matrix_fixest"
  },
  {
    "objectID": "reference/summarize.etable.html",
    "href": "reference/summarize.etable.html",
    "title": "",
    "section": "",
    "text": "summarize.etable(models, digits=3, type='md')\nCreate an esttab-like table from a list of models# Args: models: A list of models of type Feols, Feiv, Fepois. digits: Number of digits to round to. type: Type of output. Either “df” for pandas DataFrame, “md” for markdown, or “tex” for LaTeX table. “md” by default. Returns: A pandas DataFrame with the coefficients and standard errors of the models."
  },
  {
    "objectID": "reference/summarize.summary.html",
    "href": "reference/summarize.summary.html",
    "title": "",
    "section": "",
    "text": "Summary\nPrints a summary of the feols() estimation results for each estimated model.\nFor each model, the method prints a header indicating the fixed-effects and the dependent variable, followed by a table of coefficient estimates with standard errors, t-values, and p-values.\nArgs: digits (int, optional): The number of decimal places to round the summary statistics to. Default is 3.\nReturns: None"
  },
  {
    "objectID": "reference/visualize.coefplot.html",
    "href": "reference/visualize.coefplot.html",
    "title": "",
    "section": "",
    "text": "coefplot\nPlot model coefficients with confidence intervals.\nArgs: models (list): A list of fitted models of type Feols or Fepois, or just a single model. figsize (tuple): The size of the figure. alpha (float): The significance level for the confidence intervals. yintercept (float or None): The value at which to draw a horizontal line on the plot. Default is 0. xintercept (float or None): The value at which to draw a vertical line on the plot. Default is None. rotate_xticks (float): The angle in degrees to rotate the xticks labels. Default is 0 (no rotation). coefficients (list): A list of coefficients to plot. If None, all coefficients are plotted. title (str): The title of the plot. coord_flip (bool): Whether to flip the coordinates of the plot. Default is True. Returns: A lets-plot figure."
  },
  {
    "objectID": "reference/visualize.iplot.html",
    "href": "reference/visualize.iplot.html",
    "title": "",
    "section": "",
    "text": "iplot\nPlot model coefficients for variables interacted via “i()” syntax, with confidence intervals. Args: models (list): A list of fitted models of type Feols or Fepois, or just a single model. figsize (tuple): The size of the figure. alpha (float): The significance level for the confidence intervals. yintercept (int or None): The value at which to draw a horizontal line on the plot. xintercept (int or None): The value at which to draw a vertical line on the plot. rotate_xticks (float): The angle in degrees to rotate the xticks labels. Default is 0 (no rotation). title (str): The title of the plot. coord_flip (bool): Whether to flip the coordinates of the plot. Default is True. Returns: A lets-plot figure."
  },
  {
    "objectID": "tests/readme.html",
    "href": "tests/readme.html",
    "title": "",
    "section": "",
    "text": "Check How close PyFixest reproduces standard errors produced via fixest and stats::glm\nTest PyFixest against fixest\npandas needs to be a version lower than 1.5.3 to be compatible with rpy2, else you’ll run into this error. The github actions for testing ensures that pandas is of a version lower than 1.5.3."
  },
  {
    "objectID": "readme.html#pyfixest-fast-high-dimensional-fixed-effects-regression-in-python",
    "href": "readme.html#pyfixest-fast-high-dimensional-fixed-effects-regression-in-python",
    "title": "",
    "section": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python",
    "text": "PyFixest: Fast High-Dimensional Fixed Effects Regression in Python\n   \nPyFixest is a Python implementation of the formidable fixest package for fast high-dimensional fixed effects regression. The package aims to mimic fixest syntax and functionality as closely as Python allows: if you are used to fixest, the goal is that you won’t have to read the docs to get started! Nevertheless, for a quick introduction, you can take a look at the tutorial or the regression chapter of Arthur Turrell’s book on Coding for Economists.\nPyFixest supports\n\nOLS and IV Regression\nPoisson Regression\nMultiple Estimation Syntax\nSeveral Robust and Cluster Robust Variance-Covariance Types\nWild Cluster Bootstrap Inference (via wildboottest)\nDifference-in-Difference Estimators:\n\nThe canonical Two-Way Fixed Effects Estimator\nGardner’s two-stage (“Did2s”) estimator\nBasic Versions of the Local Projections estimator following Dube et al (2023)"
  },
  {
    "objectID": "readme.html#installation",
    "href": "readme.html#installation",
    "title": "",
    "section": "Installation",
    "text": "Installation\nYou can install the release version from PyPi by running\npip install pyfixest\nor the development version from github by running\npip install git+https://github.com/s3alfisc/pyfixest.git"
  },
  {
    "objectID": "readme.html#news",
    "href": "readme.html#news",
    "title": "",
    "section": "News",
    "text": "News\nPyFixest 0.13 adds support for the local projections Difference-in-Differences Estimator."
  },
  {
    "objectID": "readme.html#benchmarks",
    "href": "readme.html#benchmarks",
    "title": "",
    "section": "Benchmarks",
    "text": "Benchmarks\nAll benchmarks follow the fixest benchmarks. All non-pyfixest timings are taken from the fixest benchmarks."
  },
  {
    "objectID": "readme.html#quickstart",
    "href": "readme.html#quickstart",
    "title": "",
    "section": "Quickstart",
    "text": "Quickstart\n\nFixed Effects Regression via feols()\nYou can estimate a linear regression models just as you would in fixest - via feols():\n\nfrom pyfixest.estimation import feols, fepois\nfrom pyfixest.utils import get_data\nfrom pyfixest.summarize import etable\n\ndata = get_data()\nfeols(\"Y ~ X1 | f1 + f2\", data=data).summary()\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.919 |        0.065 |   -14.057 |      0.000 |  -1.053 |   -0.786 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\n\n\n\nMultiple Estimation\nYou can estimate multiple models at once by using multiple estimation syntax:\n\n# OLS Estimation: estimate multiple models at once\nfit = feols(\"Y + Y2 ~X1 | csw0(f1, f2)\", data = data, vcov = {'CRV1':'group_id'})\n# Print the results\netable([fit.fetch_model(i) for i in range(6)])\n\nModel:  Y~X1\nModel:  Y2~X1\nModel:  Y~X1|f1\nModel:  Y2~X1|f1\nModel:  Y~X1|f1+f2\nModel:  Y2~X1|f1+f2\n                          est1               est2               est3               est4               est5               est6\n------------  ----------------  -----------------  -----------------  -----------------  -----------------  -----------------\ndepvar                       Y                 Y2                  Y                 Y2                  Y                 Y2\n-----------------------------------------------------------------------------------------------------------------------------\nIntercept     0.919*** (0.121)   1.064*** (0.232)\nX1             -1.0*** (0.117)  -1.322*** (0.211)  -0.949*** (0.087)  -1.266*** (0.212)  -0.919*** (0.069)  -1.228*** (0.194)\n-----------------------------------------------------------------------------------------------------------------------------\nf2                           -                  -                  -                  -                  x                  x\nf1                           -                  -                  x                  x                  x                  x\n-----------------------------------------------------------------------------------------------------------------------------\nR2                       0.123              0.037              0.437              0.115              0.609              0.168\nS.E. type         by: group_id       by: group_id       by: group_id       by: group_id       by: group_id       by: group_id\nObservations               998                999                997                998                997                998\n-----------------------------------------------------------------------------------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\nAdjust Standard Errors “on-the-fly”\nStandard Errors can be adjusted after estimation, “on-the-fly”:\n\nfit1 = fit.fetch_model(0)\nfit1.vcov(\"hetero\").summary()\n\nModel:  Y~X1\n###\n\nEstimation:  OLS\nDep. var.: Y\nInference:  hetero\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.919 |        0.112 |     8.223 |      0.000 |   0.699 |    1.138 |\n| X1            |     -1.000 |        0.082 |   -12.134 |      0.000 |  -1.162 |   -0.838 |\n---\nRMSE: 2.158   R2: 0.123\n\n\n\n\nPoisson Regression via fepois()\nYou can estimate Poisson Regressions via the fepois() function:\n\npoisson_data = get_data(model = \"Fepois\")\nfepois(\"Y ~ X1 + X2 | f1 + f2\", data = poisson_data).summary()\n\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.008 |        0.035 |    -0.239 |      0.811 |  -0.076 |    0.060 |\n| X2            |     -0.015 |        0.010 |    -1.471 |      0.141 |  -0.035 |    0.005 |\n---\nDeviance: 1068.836\n\n\n\n\nIV Estimation via three-part formulas\nLast, PyFixest also supports IV estimation via three part formula syntax:\n\nfit_iv = feols(\"Y ~ 1 | f1 | X1 ~ Z1\", data = data)\nfit_iv.summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y, Fixed effects: f1\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -1.025 |        0.115 |    -8.930 |      0.000 |  -1.259 |   -0.790 |\n---"
  },
  {
    "objectID": "reference/did.estimation.did2s.html",
    "href": "reference/did.estimation.did2s.html",
    "title": "",
    "section": "",
    "text": "did.estimation.did2s(data, yname, first_stage, second_stage, treatment, cluster, i_ref1=None, i_ref2=None)\nEstimate a Difference-in-Differences model using Gardner’s two-step DID2S estimator.\nThis function estimates the effects of treatments in panel data using a two-stage approach. It requires specification of both the first and second stage formulas and supports interaction references for the second stage.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npandas.pandas.DataFrame\nThe DataFrame containing all variables.\nrequired\n\n\nyname\nstr\nThe name of the dependent variable.\nrequired\n\n\nfirst_stage\nstr\nThe formula for the first stage, starting with ‘~’.\nrequired\n\n\nsecond_stage\nstr\nThe formula for the second stage, starting with ‘~’.\nrequired\n\n\ntreatment\nstr\nThe name of the treatment variable.\nrequired\n\n\ncluster\nstr\nThe name of the cluster variable.\nrequired\n\n\ni_ref1\n(int, str, list)\nThe reference value(s) for the first variable used with “i()” syntax in the second stage formula. Default is None.\nNone\n\n\ni_ref2\n(int, str, list)\nThe reference value(s) for the second variable used with “i()” syntax in the second stage formula. Default is None.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nA fitted model object of class feols.\n\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.did.estimation import did2s\n\nurl = \"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\ndf_het.head()\n\n\n      You have loaded the 'pyfixest.did' module. While every function is tested in `tests/test_did.py`,\n      the module is not yet as thoroughly tested as I would like. So please use it with caution and\n      provide feedback in case you stumble over any bugs!\n      \n\n\n\n            \n            \n            \n\n\n\n\n\n\n  \n    \n      \n      unit\n      state\n      group\n      unit_fe\n      g\n      year\n      year_fe\n      treat\n      rel_year\n      rel_year_binned\n      error\n      te\n      te_dynamic\n      dep_var\n    \n  \n  \n    \n      0\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1990\n      0.066159\n      False\n      -20.0\n      -6\n      -0.086466\n      0\n      0.0\n      7.022709\n    \n    \n      1\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1991\n      -0.030980\n      False\n      -19.0\n      -6\n      0.766593\n      0\n      0.0\n      7.778628\n    \n    \n      2\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1992\n      -0.119607\n      False\n      -18.0\n      -6\n      1.512968\n      0\n      0.0\n      8.436377\n    \n    \n      3\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1993\n      0.126321\n      False\n      -17.0\n      -6\n      0.021870\n      0\n      0.0\n      7.191207\n    \n    \n      4\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1994\n      -0.106921\n      False\n      -16.0\n      -6\n      -0.017603\n      0\n      0.0\n      6.918492\n    \n  \n\n\n\n\nIn a first step, we estimate a classical event study model:\n\n# estimate the model\nfit = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(rel_year)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n    i_ref1=[-1.0, np.inf],\n)\n\nfit.tidy().head()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(rel_year,contr.treatment(base=-1.0))[T.-20.0]\n      -0.058226\n      0.035809\n      -1.626011\n      0.103954\n      -0.128412\n      0.011960\n    \n    \n      C(rel_year,contr.treatment(base=-1.0))[T.-19.0]\n      -0.006032\n      0.030341\n      -0.198816\n      0.842408\n      -0.065500\n      0.053436\n    \n    \n      C(rel_year,contr.treatment(base=-1.0))[T.-18.0]\n      -0.006152\n      0.035094\n      -0.175310\n      0.860837\n      -0.074937\n      0.062632\n    \n    \n      C(rel_year,contr.treatment(base=-1.0))[T.-17.0]\n      -0.012533\n      0.024834\n      -0.504689\n      0.613780\n      -0.061208\n      0.036141\n    \n    \n      C(rel_year,contr.treatment(base=-1.0))[T.-16.0]\n      -0.034698\n      0.029806\n      -1.164128\n      0.244378\n      -0.093117\n      0.023722\n    \n  \n\n\n\n\nWe can also inspect the model visually:\n\nfit.iplot(figsize= [1200, 400], coord_flip=False).show()\n\n   \n   \n\n\nTo estimate a pooled effect, we need to slightly update the second stage formula:\n\nfit = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(treat)\",\n    treatment=\"treat\",\n    cluster=\"state\"\n)\nfit.tidy().head()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(treat)[T.True]\n      2.230482\n      0.024709\n      90.271437\n      0.0\n      2.182052\n      2.278911"
  },
  {
    "objectID": "reference/did.estimation.lpdid.html",
    "href": "reference/did.estimation.lpdid.html",
    "title": "",
    "section": "",
    "text": "did.estimation.lpdid(data, yname, idname, tname, gname, vcov=None, pre_window=None, post_window=None, never_treated=0, att=True, xfml=None)\nEstimate a Difference-in-Differences / Event Study Model via the Local Projections Approach.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\nDataFrame\nThe DataFrame containing all variables.\nrequired\n\n\nyname\nstr\nThe name of the dependent variable.\nrequired\n\n\nidname\nstr\nThe name of the id variable.\nrequired\n\n\ntname\nstr\nVariable name for calendar period.\nrequired\n\n\ngname\nstr\nUnit-specific time of initial treatment.\nrequired\n\n\nvcov\n(str, dict)\nThe type of inference to employ. Defaults to {“CRV1”: idname}. Options include “iid”, “hetero”, or a dictionary like {“CRV1”: idname}.\nNone\n\n\npre_window\nint\nThe number of periods before the treatment to include in the estimation. Default is the minimum relative year in the data.\nNone\n\n\npost_window\nint\nThe number of periods after the treatment to include in the estimation. Default is the maximum relative year in the data.\nNone\n\n\nnever_treated\nint\nValue in gname indicating units never treated. Default is 0.\n0\n\n\natt\nbool\nIf True, estimates the pooled average treatment effect on the treated (ATT). Default is False.\nTrue\n\n\nxfml\nstr\nFormula for the covariates. Not yet supported.\nNone\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nDataFrame\nA DataFrame with the estimated coefficients.\n\n\n\n\n\n\n\nimport pandas as pd\nfrom pyfixest.did.estimation import lpdid\n\nurl = \"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\n\nfit = lpdid(\n    df_het,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=False\n)\n\nfit.tidy().head()\nfit.iplot(figsize= [1200, 400], coord_flip=False).show()\n\n\n      You have loaded the 'pyfixest.did' module. While every function is tested in `tests/test_did.py`,\n      the module is not yet as thoroughly tested as I would like. So please use it with caution and\n      provide feedback in case you stumble over any bugs!\n      \n\n\n\n            \n            \n            \n\n\n   \n   \n\n\nTo get the ATT, set att=True:\n\nfit = lpdid(\n    df_het,\n    yname=\"dep_var\",\n    idname=\"unit\",\n    tname=\"year\",\n    gname=\"g\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=True\n)\nfit.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n      N\n    \n  \n  \n    \n      treat_diff\n      2.506746\n      0.071357\n      35.129648\n      0.0\n      2.362413\n      2.65108\n      5716.0"
  },
  {
    "objectID": "reference/model_matrix_fixest.html",
    "href": "reference/model_matrix_fixest.html",
    "title": "",
    "section": "",
    "text": "model_matrix_fixest\n\n\n\n\n\nName\nDescription\n\n\n\n\nmodel_matrix_fixest\nCreate model matrices for fixed effects estimation.\n\n\n\n\n\nmodel_matrix_fixest.model_matrix_fixest(fml, data, drop_singletons=False, weights=None, drop_intercept=False, i_ref1=None, i_ref2=None)\nCreate model matrices for fixed effects estimation.\nThis function preprocesses the data and then calls formulaic.model_matrix() to create the model matrices.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nA two-sided formula string using fixest formula syntax.\nrequired\n\n\ndata\npandas.pandas.DataFrame\nThe input DataFrame containing the data.\nrequired\n\n\ndrop_singletons\nbool\nWhether to drop singleton fixed effects. Default is False.\nFalse\n\n\nweights\nstr or None\nWeights as a string if provided, or None if no weights, e.g., “weights”.\nNone\n\n\ndata\npandas.pandas.DataFrame\nThe input DataFrame containing the data.\nrequired\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model matrix. Default is False. If True, the intercept is dropped ex post from the model matrix created by formulaic.\nFalse\n\n\ni_ref1\nstr or list\nThe reference level for the first variable in the i() syntax.\nNone\n\n\ni_ref2\nstr or list\nThe reference level for the second variable in the i() syntax.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntuple\nA tuple of the following elements: - Y : pd.DataFrame A DataFrame of the dependent variable. - X : pd.DataFrame A DataFrame of the covariates. If combine = True, contains covariates and fixed effects as dummies. - I : Optional[pd.DataFrame] A DataFrame of the Instruments, None if no IV. - fe : Optional[pd.DataFrame] A DataFrame of the fixed effects, None if no fixed effects specified. Only applicable if combine = False. - na_index : np.array An array with indices of dropped columns. - fe_na : np.array An array with indices of dropped columns due to fixed effect singletons or NaNs in the fixed effects. - na_index_str : str na_index, but as a comma-separated string. Used for caching of demeaned variables. - z_names : Optional[List[str]] Names of all covariates, minus the endogenous variables, plus the instruments. None if no IV. - weights : Optional[str] Weights as a string if provided, or None if no weights, e.g., “weights”. - has_weights : bool A boolean indicating whether weights are used. - icovars : Optional[List[str]] A list of interaction variables provided via i(). None if no interaction variables via i() provided.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nlist or None\n\nicovars - A list of interaction variables. None if no interaction variables via i() provided."
  },
  {
    "objectID": "readme.html#functionality",
    "href": "readme.html#functionality",
    "title": "",
    "section": "Functionality",
    "text": "Functionality\n\nOLS and IV Regression\nPoisson Regression\nMultiple Estimation Syntax\nSeveral Robust and Cluster Robust Variance-Covariance Types\nWild Cluster Bootstrap Inference (via wildboottest)\nDifference-in-Difference Estimators:\n\nThe canonical Two-Way Fixed Effects Estimator\nGardner’s two-stage (“Did2s”) estimator\nBasic Versions of the Local Projections estimator following Dube et al (2023)"
  },
  {
    "objectID": "readme.html#features",
    "href": "readme.html#features",
    "title": "",
    "section": "Features",
    "text": "Features\n\nOLS and IV Regression\nPoisson Regression\nMultiple Estimation Syntax\nSeveral Robust and Cluster Robust Variance-Covariance Types\nWild Cluster Bootstrap Inference (via wildboottest)\nDifference-in-Difference Estimators:\n\nThe canonical Two-Way Fixed Effects Estimator\nGardner’s two-stage (“Did2s”) estimator\nBasic Versions of the Local Projections estimator following Dube et al (2023)"
  }
]