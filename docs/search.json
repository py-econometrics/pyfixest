[
  {
    "objectID": "benchmarks/readme.html",
    "href": "benchmarks/readme.html",
    "title": "",
    "section": "",
    "text": "All benchmarks follow fixest’s benchmarks, which you can find here. PyFixest benchmarks were run on a Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz, 2304Mhz, 4 Core(s), 8 Logical Processor(s). Timings for R, Stata and Julia programs are taken from the fixest’s benchmarks.\nTo run the python benchmarks, you need to install the following packages: - pyfixest - pandas - numpy - tqdm First, you need to create the data by running the data_generation.R files. This will populate the _STATA and data folders. Then, you can run the run_benchmarks.ipynb notebook to run the benchmarks. This will populate the results_py.csv file. Finally, you can run the plot_benchmarks.ipynb notebook to generate the plots."
  },
  {
    "objectID": "benchmarks/run_benchmarks.html",
    "href": "benchmarks/run_benchmarks.html",
    "title": "",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\nimport time\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.estimation import feols, fepois\nfrom tqdm import tqdm  # note: tqdm is not a dependency of pyfixest\n\n\ndef run_standard_benchmark(model, fixed_effect):\n    \"\"\"\n    Runs the fixest standard benchmark.\n    Args:\n        model (str): \"feols\" or \"fepois\"\n        fixed_effect (str): \"dum_1\" or \"dum_1+dum_2\" or \"dum_1+dum_2+dum_3\"\n    Returns:\n        A pd.DataFrame with the results.\n    \"\"\"\n\n    assert model in [\"feols\", \"fepois\"]\n    assert fixed_effect in [\"dum_1\", \"dum_1+dum_2\", \"dum_1+dum_2+dum_3\"]\n\n    # one fixed effect\n    res = []\n\n    if model == \"feols\":\n        fml_base = \"ln_y ~ X1\"\n        model2 = \"Gaussian\"\n    else:\n        fml_base = \"y ~ X1\"\n        model2 = \"Poisson\"\n\n    fml = f\"{fml_base} | {fixed_effect}\"\n\n    # warmup\n    df = pd.read_stata(f\"./data/_STATA/base_s2_r1.dta\")\n    feols(fml, data=df)\n\n    for size in tqdm(range(1, 6)):\n        if size == 5:\n            if model == \"fepois\":\n                pass\n            else:\n                df = pd.read_csv(\"./data/data/base_10M.csv\")\n\n        for rep in range(1, 11):\n            if size < 5:\n                df = pd.read_stata(f\"./data/_STATA/base_s{size}_r{rep}.dta\")\n\n            tic = time.time()\n            if model == \"feols\":\n                feols(fml, data=df)\n            else:\n                fepois(fml, data=df)\n            toc = time.time()\n\n            res.append(\n                pd.Series(\n                    {\n                        \"method\": model,\n                        \"n_obs\": df.shape[0],\n                        \"G\": len(fixed_effect.split(\"+\")),\n                        \"rep\": rep,\n                        \"time\": toc - tic,\n                    }\n                )\n            )\n\n    return pd.concat(res, axis=1).T\n\n\ndef run_all_benchmarks():\n    \"\"\"\n    Run all the benchmarks.\n    \"\"\"\n\n    res = pd.DataFrame()\n    for model in [\"feols\", \"fepois\"]:\n        for fixef in [\"dum_1\", \"dum_1+dum_2\", \"dum_1+dum_2+dum_3\"]:\n            res = pd.concat([res, run_standard_benchmark(model, fixef)], axis=1)\n\n    res.to_csv(\"./results_py.csv\")\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\nrun_all_benchmarks()\n\n100%|██████████| 3/3 [00:00<00:00,  3.54it/s]\n100%|██████████| 3/3 [00:00<00:00,  3.33it/s]\n\n\n\na = run_standard_benchmark(\"feols\", \"dum_1\")\na\n\n100%|██████████| 3/3 [00:00<00:00,  3.61it/s]\n\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n    \n  \n  \n    \n      0\n      feols\n      1000\n      1\n      1\n      0.011204\n    \n    \n      1\n      feols\n      1000\n      1\n      2\n      0.009486\n    \n    \n      2\n      feols\n      1000\n      1\n      3\n      0.010987\n    \n    \n      3\n      feols\n      1000\n      1\n      4\n      0.010687\n    \n    \n      4\n      feols\n      1000\n      1\n      5\n      0.011018\n    \n    \n      5\n      feols\n      1000\n      1\n      6\n      0.009798\n    \n    \n      6\n      feols\n      1000\n      1\n      7\n      0.008976\n    \n    \n      7\n      feols\n      1000\n      1\n      8\n      0.008977\n    \n    \n      8\n      feols\n      1000\n      1\n      9\n      0.008486\n    \n    \n      9\n      feols\n      1000\n      1\n      10\n      0.007978\n    \n    \n      10\n      feols\n      10000\n      1\n      1\n      0.01097\n    \n    \n      11\n      feols\n      10000\n      1\n      2\n      0.012004\n    \n    \n      12\n      feols\n      10000\n      1\n      3\n      0.013207\n    \n    \n      13\n      feols\n      10000\n      1\n      4\n      0.011819\n    \n    \n      14\n      feols\n      10000\n      1\n      5\n      0.010875\n    \n    \n      15\n      feols\n      10000\n      1\n      6\n      0.011104\n    \n    \n      16\n      feols\n      10000\n      1\n      7\n      0.009973\n    \n    \n      17\n      feols\n      10000\n      1\n      8\n      0.009973\n    \n    \n      18\n      feols\n      10000\n      1\n      9\n      0.01097\n    \n    \n      19\n      feols\n      10000\n      1\n      10\n      0.009974\n    \n    \n      20\n      feols\n      100000\n      1\n      1\n      0.042234\n    \n    \n      21\n      feols\n      100000\n      1\n      2\n      0.04016\n    \n    \n      22\n      feols\n      100000\n      1\n      3\n      0.043736\n    \n    \n      23\n      feols\n      100000\n      1\n      4\n      0.049093\n    \n    \n      24\n      feols\n      100000\n      1\n      5\n      0.052659\n    \n    \n      25\n      feols\n      100000\n      1\n      6\n      0.048541\n    \n    \n      26\n      feols\n      100000\n      1\n      7\n      0.051272\n    \n    \n      27\n      feols\n      100000\n      1\n      8\n      0.044816\n    \n    \n      28\n      feols\n      100000\n      1\n      9\n      0.041823\n    \n    \n      29\n      feols\n      100000\n      1\n      10\n      0.044947\n    \n  \n\n\n\n\n\na.T\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n      method\n      n_obs\n      G\n      rep\n      time\n      ...\n      method\n      n_obs\n      G\n      rep\n      time\n      method\n      n_obs\n      G\n      rep\n      time\n    \n  \n  \n    \n      0\n      feols\n      1000\n      1\n      1\n      0.009973\n      feols\n      1000\n      1\n      2\n      0.01043\n      ...\n      feols\n      10000000\n      2\n      9\n      10.188134\n      feols\n      10000000\n      2\n      10\n      10.136924\n    \n  \n\n1 rows × 500 columns\n\n\n\n\n\n\nres_all = pd.concat(\n    [\n        pd.read_csv(\"./benchmarks/results_py.csv\"),\n        pd.read_csv(\"./benchmarks/results_all.txt\"),\n    ]\n)\n\n\nres_all\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n      model\n    \n  \n  \n    \n      0\n      fepois\n      1000.0\n      1\n      1\n      0.060000\n      Poisson\n    \n    \n      1\n      glmmboot\n      1000.0\n      1\n      1\n      0.020000\n      Poisson\n    \n    \n      2\n      feglm (alpaca)\n      1000.0\n      1\n      1\n      0.020000\n      Poisson\n    \n    \n      3\n      fepois\n      1000.0\n      1\n      2\n      0.030000\n      Poisson\n    \n    \n      4\n      glmmboot\n      1000.0\n      1\n      2\n      0.010000\n      Poisson\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1575\n      FixedEffectModels\n      10000000.0\n      3\n      6\n      6.800669\n      Gaussian\n    \n    \n      1576\n      FixedEffectModels\n      10000000.0\n      3\n      7\n      6.756505\n      Gaussian\n    \n    \n      1577\n      FixedEffectModels\n      10000000.0\n      3\n      8\n      6.802480\n      Gaussian\n    \n    \n      1578\n      FixedEffectModels\n      10000000.0\n      3\n      9\n      6.761793\n      Gaussian\n    \n    \n      1579\n      FixedEffectModels\n      10000000.0\n      3\n      10\n      6.759143\n      Gaussian\n    \n  \n\n1580 rows × 6 columns"
  },
  {
    "objectID": "benchmarks/visualise_benchmarks.html",
    "href": "benchmarks/visualise_benchmarks.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n\nres_py = pd.read_csv(\"./results_py.csv\")\nres_py[\"model\"] = np.where(res_py[\"method\"] == \"feols\", \"Gaussian\", \"Poisson\")\nres_py[\"method\"] = \"pyfixest\"\nres_other = pd.read_csv(\"./results_all.txt\")\nres_all = pd.concat([res_py, res_other], axis=0)\n\n\nres_all.method.unique()\n\narray(['pyfixest', 'fepois', 'glmmboot', 'feglm (alpaca)', 'ppmlhdfe',\n       'fenegbin', 'glmnb', 'nbreg', 'feglm (fixest)', 'logit', 'feols',\n       'lfe', 'reghdfe', 'FixedEffectModels'], dtype=object)\n\n\n\nres_agg = (\n    res_all.groupby([\"method\", \"n_obs\", \"G\", \"model\"]).mean()[\"time\"].reset_index()\n)\nres_agg[\"G\"] = res_agg[\"G\"].apply(lambda x: f\"{x} FE\")\nres_agg[\"method\"] = pd.Categorical(\n    res_agg[\"method\"],\n    [\n        \"pyfixest\",\n        \"feols\",\n        \"reghdfe\",\n        \"lfe\",\n        \"FixedEffectModels\",\n        \"fepois\",\n        \"glmmboot\",\n        \"ppmlhdfe\",\n        \"feglm (alpaca)\",\n    ],\n)\n\n\nplot_ols = (\n    ggplot(\n        res_agg[res_agg[\"model\"] == \"Gaussian\"],\n        aes(x=\"n_obs\", y=\"time\", color=\"method\"),\n    )\n    + geom_line()\n    + geom_point()\n    + facet_wrap(\"G\", nrow=1)\n    + scale_x_discrete()\n    + scale_y_continuous(trans=\"log10\", limits=(0, 120))\n    + ylab(\"Time in Seconds\")\n    + xlab(\"Number of Observations\")\n    + ggtitle(\"Fixest Standard Benchmark for OLS\")\n    + ggsize(1000, 500)\n)\nggsave(plot_ols, filename=\"benchmarks_ols.svg\")\n\n\nplot_ols\n\n\n  \n  \n    \n    \n    \n      \n        \n        1 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n            \n            0.01\n            \n          \n        \n        \n          \n            \n            0.03\n            \n          \n        \n        \n          \n            \n            0.10\n            \n          \n        \n        \n          \n            \n            0.3\n            \n          \n        \n        \n          \n            \n            1.0\n            \n          \n        \n        \n          \n            \n            3\n            \n          \n        \n        \n          \n            \n            10\n            \n          \n        \n        \n          \n            \n            32\n            \n          \n        \n        \n          \n            \n            100\n            \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        2 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        3 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n      Fixest Standard Benchmark for OLS\n      \n    \n    \n      \n      Time in Seconds\n      \n    \n    \n      \n      Number of Observations\n      \n    \n    \n      \n      \n      \n        \n          \n          method\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              FixedEffectModels\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              feols\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              lfe\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              pyfixest\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              reghdfe\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nplot_poisson = (\n    ggplot(\n        res_agg[(res_agg[\"model\"] == \"Poisson\") & (res_agg.n_obs < 1e07)],\n        aes(x=\"n_obs\", y=\"time\", color=\"method\"),\n    )\n    + geom_line()\n    + geom_point()\n    + facet_wrap(\"G\", nrow=1)\n    + scale_x_discrete()\n    + scale_y_continuous(trans=\"log10\", limits=(0, 120))\n    + ylab(\"Time in Seconds\")\n    + xlab(\"Number of Observations\")\n    + ggtitle(\"Fixest Standard Benchmark for Poisson Regression\")\n    + ggsize(1000, 500)\n)\n\nggsave(plot_poisson, filename=\"benchmarks_poisson.svg\")\n\nplot_poisson\n\n\n  \n  \n    \n    \n    \n      \n        \n        1 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n            \n            0.03\n            \n          \n        \n        \n          \n            \n            0.10\n            \n          \n        \n        \n          \n            \n            0.3\n            \n          \n        \n        \n          \n            \n            1.0\n            \n          \n        \n        \n          \n            \n            3\n            \n          \n        \n        \n          \n            \n            10\n            \n          \n        \n        \n          \n            \n            32\n            \n          \n        \n        \n          \n            \n            100\n            \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        2 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        3 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n      Fixest Standard Benchmark for Poisson Regression\n      \n    \n    \n      \n      Time in Seconds\n      \n    \n    \n      \n      Number of Observations\n      \n    \n    \n      \n      \n      \n        \n          \n          method\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              feglm (alpaca)\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              fepois\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              glmmboot\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              ppmlhdfe\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              pyfixest"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "",
    "section": "",
    "text": "Copyright (c) 2022 pyfixest authors\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "readme.html#features",
    "href": "readme.html#features",
    "title": "",
    "section": "Features",
    "text": "Features\n\nOLS and IV Regression\nPoisson Regression\nMultiple Estimation Syntax\nSeveral Robust and Cluster Robust Variance-Covariance Types\nWild Cluster Bootstrap Inference (via wildboottest)\nDifference-in-Difference Estimators:\n\nThe canonical Two-Way Fixed Effects Estimator\nGardner’s two-stage (“Did2s”) estimator\nBasic Versions of the Local Projections estimator following Dube et al (2023)"
  },
  {
    "objectID": "readme.html#installation",
    "href": "readme.html#installation",
    "title": "",
    "section": "Installation",
    "text": "Installation\nYou can install the release version from PyPi by running\npip install pyfixest\nor the development version from github by running\npip install git+https://github.com/s3alfisc/pyfixest.git"
  },
  {
    "objectID": "readme.html#news",
    "href": "readme.html#news",
    "title": "",
    "section": "News",
    "text": "News\nPyFixest 0.13 adds support for the local projections Difference-in-Differences Estimator."
  },
  {
    "objectID": "readme.html#benchmarks",
    "href": "readme.html#benchmarks",
    "title": "",
    "section": "Benchmarks",
    "text": "Benchmarks\nAll benchmarks follow the fixest benchmarks. All non-pyfixest timings are taken from the fixest benchmarks."
  },
  {
    "objectID": "readme.html#quickstart",
    "href": "readme.html#quickstart",
    "title": "",
    "section": "Quickstart",
    "text": "Quickstart\n\nFixed Effects Regression via feols()\nYou can estimate a linear regression models just as you would in fixest - via feols():\n\nfrom pyfixest.estimation import feols, fepois\nfrom pyfixest.utils import get_data\nfrom pyfixest.summarize import etable\ndata = get_data()\nfeols(\"Y ~ X1 | f1 + f2\", data=data).summary()\n\n            \n            \n\n\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.919 |        0.065 |   -14.057 |      0.000 |  -1.053 |   -0.786 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\n\n\n\nMultiple Estimation\nYou can estimate multiple models at once by using multiple estimation syntax:\n\n# OLS Estimation: estimate multiple models at once\nfit = feols(\"Y + Y2 ~X1 | csw0(f1, f2)\", data = data, vcov = {'CRV1':'group_id'})\n# Print the results\netable([fit.fetch_model(i) for i in range(6)])\n\nModel:  Y~X1\nModel:  Y2~X1\nModel:  Y~X1|f1\nModel:  Y2~X1|f1\nModel:  Y~X1|f1+f2\nModel:  Y2~X1|f1+f2\n                          est1               est2               est3               est4               est5               est6\n------------  ----------------  -----------------  -----------------  -----------------  -----------------  -----------------\ndepvar                       Y                 Y2                  Y                 Y2                  Y                 Y2\n-----------------------------------------------------------------------------------------------------------------------------\nIntercept     0.919*** (0.121)   1.064*** (0.232)\nX1             -1.0*** (0.117)  -1.322*** (0.211)  -0.949*** (0.087)  -1.266*** (0.212)  -0.919*** (0.069)  -1.228*** (0.194)\n-----------------------------------------------------------------------------------------------------------------------------\nf1                           -                  -                  x                  x                  x                  x\nf2                           -                  -                  -                  -                  x                  x\n-----------------------------------------------------------------------------------------------------------------------------\nR2                       0.123              0.037              0.437              0.115              0.609              0.168\nS.E. type         by: group_id       by: group_id       by: group_id       by: group_id       by: group_id       by: group_id\nObservations               998                999                997                998                997                998\n-----------------------------------------------------------------------------------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\nAdjust Standard Errors “on-the-fly”\nStandard Errors can be adjusted after estimation, “on-the-fly”:\n\nfit1 = fit.fetch_model(0)\nfit1.vcov(\"hetero\").summary()\n\nModel:  Y~X1\n###\n\nEstimation:  OLS\nDep. var.: Y\nInference:  hetero\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.919 |        0.112 |     8.223 |      0.000 |   0.699 |    1.138 |\n| X1            |     -1.000 |        0.082 |   -12.134 |      0.000 |  -1.162 |   -0.838 |\n---\nRMSE: 2.158   R2: 0.123\n\n\n\n\nPoisson Regression via fepois()\nYou can estimate Poisson Regressions via the fepois() function:\n\npoisson_data = get_data(model = \"Fepois\")\nfepois(\"Y ~ X1 + X2 | f1 + f2\", data = poisson_data).summary()\n\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.008 |        0.035 |    -0.239 |      0.811 |  -0.076 |    0.060 |\n| X2            |     -0.015 |        0.010 |    -1.471 |      0.141 |  -0.035 |    0.005 |\n---\nDeviance: 1068.836\n\n\n\n\nIV Estimation via three-part formulas\nLast, PyFixest also supports IV estimation via three part formula syntax:\n\nfit_iv = feols(\"Y ~ 1 | f1 | X1 ~ Z1\", data = data)\nfit_iv.summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y, Fixed effects: f1\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -1.025 |        0.115 |    -8.930 |      0.000 |  -1.259 |   -0.790 |\n---"
  },
  {
    "objectID": "tests/readme.html",
    "href": "tests/readme.html",
    "title": "",
    "section": "",
    "text": "Check How close PyFixest reproduces standard errors produced via fixest and stats::glm\nTest PyFixest against fixest\npandas needs to be a version lower than 1.5.3 to be compatible with rpy2, else you’ll run into this error. The github actions for testing ensures that pandas is of a version lower than 1.5.3."
  },
  {
    "objectID": "vignettes/difference-in-differences.html",
    "href": "vignettes/difference-in-differences.html",
    "title": "",
    "section": "",
    "text": "PyFixest supports eventy study designs via the canonical two-way fixed effects design Gardner’s 2-stage estimator, and the local projections approach following Dube et al (2023).\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.estimation import feols\nfrom pyfixest.did.estimation import did2s\nfrom pyfixest.did.estimation import lpdid\n\nurl = \"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\ndf_het.head()\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\n\n\n  \n    \n      \n      unit\n      state\n      group\n      unit_fe\n      g\n      year\n      year_fe\n      treat\n      rel_year\n      rel_year_binned\n      error\n      te\n      te_dynamic\n      dep_var\n    \n  \n  \n    \n      0\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1990\n      0.066159\n      False\n      -20.0\n      -6\n      -0.086466\n      0\n      0.0\n      7.022709\n    \n    \n      1\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1991\n      -0.030980\n      False\n      -19.0\n      -6\n      0.766593\n      0\n      0.0\n      7.778628\n    \n    \n      2\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1992\n      -0.119607\n      False\n      -18.0\n      -6\n      1.512968\n      0\n      0.0\n      8.436377\n    \n    \n      3\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1993\n      0.126321\n      False\n      -17.0\n      -6\n      0.021870\n      0\n      0.0\n      7.191207\n    \n    \n      4\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1994\n      -0.106921\n      False\n      -16.0\n      -6\n      -0.017603\n      0\n      0.0\n      6.918492\n    \n  \n\n\n\n\n\n\nWe can estimate a simple two-way fixed effects DiD regression via feols():\n\nfit_twfe = feols(\n    \"dep_var ~ i(rel_year) | state + year\",\n    df_het,\n    i_ref1=[-1.0, np.inf],\n    vcov={\"CRV1\": \"state\"},\n)\n\nTo do the same via Gardners 2-stage estimator, we employ the the did2s() function:\n\nfrom pyfixest.did.estimation import did2s\n\nfit_did2s = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n    i_ref1=[-1.0, np.inf],\n)\n\nLast, we can estimate the ATT for each time period via local projections by using the lpdid() function:\n\nfrom pyfixest.did.estimation import lpdid\n\nfit_lpdid = lpdid(\n    data=df_het,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=False,\n)\n\nLet’s look at some results:\n\nfigsize = [1200, 400]\n\n\nfit_twfe.iplot(\n    coord_flip=False,\n    title=\"TWFE-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n    figsize=[1200, 400],\n).show()\n\n   \n   \n\n\n\nfit_did2s.iplot(\n    coord_flip=False,\n    title=\"DID2s-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n    figsize=[1200, 400],\n).show()\n\n   \n   \n\n\n\nfit_lpdid.iplot(\n    coord_flip=False,\n    title=\"Local-Projections-Estimator\",\n    figsize=figsize,\n    yintercept=0,\n    xintercept=18.5,\n    figsize=[1200, 400],\n).show()\n\n   \n   \n\n\nWhat if we are not interested in the ATT per treatment period, but in a pooled effects?\n\nfit_twfe = feols(\n    \"dep_var ~ i(treat) | unit + year\",\n    df_het,\n    vcov={\"CRV1\": \"state\"},\n)\n\nfit_did2s = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(treat)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\nfit_lpdid = lpdid(\n    data=df_het,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=True,\n)\n\n\nfit_twfe.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(treat)[T.True]\n      1.98254\n      0.019331\n      102.55618\n      0.0\n      1.943439\n      2.021642\n    \n  \n\n\n\n\n\nfit_did2s.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(treat)[T.True]\n      2.230482\n      0.024709\n      90.271437\n      0.0\n      2.182052\n      2.278911\n    \n  \n\n\n\n\n\nfit_lpdid.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n      N\n    \n  \n  \n    \n      treat_diff\n      2.506746\n      0.071357\n      35.129648\n      0.0\n      2.362413\n      2.65108\n      5716.0"
  },
  {
    "objectID": "vignettes/news.html",
    "href": "vignettes/news.html",
    "title": "",
    "section": "",
    "text": "Moves the documentation to quartodoc.\nChanges all docstrings to numpy format.\nDifference-in-differences estimation functions now need to be imported via the pyfixest.did.estimation module:\n\n\nfrom pyfixest.did.estimation import did2s, lpdid, event_study\n\n\n      You have loaded the 'pyfixest.did' module. While every function is tested in `tests/test_did.py`,\n      the module is not yet as thoroughly tested as I would like. So please use it with caution and\n      provide feedback in case you stumble over any bugs!\n      \n\n\n\n            \n            \n            \n\n\n\n\n\n\nFixes a bug in etable() with IV’s that occurred because feols() does not report R2 statistics for IVs.\n\n\n\n\n\nFixes a bug in etable() and a warning in fixest_model_matrix that arose with higher pandas versions. Thanks to @aeturrell for reporting!\n\n\n\n\n\n\n\nIntroduces a new pyfixest.did module which contains routines for Difference-in-Differences estimation.\nIntroduces support for basic versions of the local projections DiD estimator following Dube et al (2023)\nAdds a new vignette for Difference-in-Differences estimation.\nReports R2 values in etable().\n\n\n\n\n\n\n\n\nGood performance improvements for singleton fixed effects detection. Thanks to @styfenschaer for the PR! See #229.\nUses the r2u project for installing R and R packages on github actions, with great performance improvements.\nAllows to pass polars data frames to feols(), fepois() and predict(). #232. Thanks to @vincentarelbundock for the suggestion!\n\n\n\n\n\nMissing variables in features were not always handled correctly in predict() with newdata not None in the presence of missing data, which would lead to an error. See #246 for details.\nCategorical variables were not always handled correctly in predict() with newdata not None, because the number of fixed effects levels in newdata might be smaller than in data. In consequence, some levels were not found, which lead to an error. See #245 for details. Thanks to @jiafengkevinchen for the pointer!\nMulticollinearity checks for over-identified IV was not implemented correctly, which lead to a dimension error. See #236 for details. Thanks to @jiafengkevinchen for the pointer!\nThe number of degrees of freedom k was computed incorrectly if columns were dropped from the design matrix X in the presence of multicollinearity. See #235 for details. Thanks to @jiafengkevinchen for the pointer!\nIf all variables were dropped due to multicollinearity, an unclear and imprecise error message was produced. See #228 for details. Thanks to @manferdinig for the pointer!\nIf selection fixef_rm = 'singleton', feols() and fepois() would fail, which has been fixed. #192\n\n\n\n\n\nFor now, sets formulaic versions to be 0.6.6 or lower as version 1.0.0 seems to have introduced a problem with the i() operator, See #244 for details.\nDrops dependency on pyhdfe.\n\n\n\n\n\n\nFixes some bugs around the computation of R-squared values (see issue #103).\nReports R-squared values again when calling .summary().\n\n\n\n\n\nSignificant speedups for CRV1 inference.\n\n\n\n\nFixes a small bug with the separation check for poisson regression #138.\n\n\n\nFixes bugs with i(var1, var2) syntax introduced with PyFixest 0.10.10.\n\n\n\nFixes a bug with variable interactions via i(var) syntax. See issue #221.\n\n\n\nMakes etable() prettier and more informative.\n\n\n\n\n\nReference levels for the i() formula syntax can no longer be set within the formula, but need to be added via the i_ref1 function argument to either feols() and fepois().\n\n\n\nA dids2() function is added, which implements the 2-stage difference-in-differences procedure à la Gardner and follows the syntax of @kylebutts did2s R package.\nfrom pyfixest.did.did import did2s\nfrom pyfixest.estimation import feols\nfrom pyfixest.visualize import iplot\nimport pandas as pd\nimport numpy as np\n\ndf_het = pd.read_csv(\"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\")\n\nfit = did2s(\n    df_het,\n    yname = \"dep_var\",\n    first_stage = \"~ 0 | state + year\",\n    second_stage = \"~i(rel_year)\",\n    treatment = \"treat\",\n    cluster = \"state\",\n    i_ref1 = [-1.0, np.inf],\n)\n\nfit_twfe = feols(\n    \"dep_var ~ i(rel_year) | state + year\",\n    df_het,\n    i_ref1 = [-1.0, np.inf]\n)\n\niplot([fit, fit_twfe], coord_flip=False, figsize = (900, 400), title = \"TWFE vs DID2S\")\n\n\n\n\n\n\nAdds basic support for event study estimation via two-way fixed effects and Gardner’s two-stage “Did2s” approach. This is a beta version and experimental. Further updates (i.e. proper event studies vs “only” ATTs) and a more flexible did2s front end will follow in future releases.\n\n%load_ext autoreload\n%autoreload 2\n\nfrom pyfixest.did.did import event_study\nfrom pyfixest.summarize import etable\nimport pandas as pd\ndf_het = pd.read_csv(\"pyfixest/did/data/df_het.csv\")\n\nfit_twfe = event_study(\n    data = df_het,\n    yname = \"dep_var\",\n    idname= \"state\",\n    tname = \"year\",\n    gname = \"g\",\n    estimator = \"twfe\"\n)\n\nfit_did2s = event_study(\n    data = df_het,\n    yname = \"dep_var\",\n    idname= \"state\",\n    tname = \"year\",\n    gname = \"g\",\n    estimator = \"did2s\"\n)\n\netable([fit_twfe, fit_did2s])\n# | Coefficient   | est1             | est2             |\n# |:--------------|:-----------------|:-----------------|\n# | ATT           | 2.135*** (0.044) | 2.152*** (0.048) |\n# Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\nAdds an etable() function that outputs markdown, latex or a pd.DataFrame.\n\n\n\n\n\nFixes a big in IV estimation that would trigger an error. See here for details. Thanks to @aeturrell for reporting!\n\n\n\n\n\nImplements a custom function to drop singleton fixed effects.\nAdditional small performance improvements.\n\n\n\n\n\nAllows for white space in the multiway clustering formula.\nAdds documentation for multiway clustering.\n\n\n\n\n\nAdds support for two-way clustering.\nAdds support for CRV3 inference for Poisson regression.\n\n\n\n\n\nAdapts the internal fixed effects demeaning criteron to match `PyHDFE’s default.\nAdds Styfen as coauthor.\n\n\n\n\n\nMultiple performance improvements.\nMost importantly, implements a custom demeaning algorithm in numba - thanks to Styfen Schaer (@styfenschaer), which leads to performance improvements of 5x or more:\n\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport time\nimport pyhdfe\nfrom pyfixest.demean import demean\n\nnp.random.seed(1238)\nN = 10_000_000\nx = np.random.normal(0, 1, 10*N).reshape((N,10))\nf1 = np.random.choice(list(range(1000)), N).reshape((N,1))\nf2 = np.random.choice(list(range(1000)), N).reshape((N,1))\n\nflist = np.concatenate((f1, f2), axis = 1)\nweights = np.ones(N)\n\nalgorithm = pyhdfe.create(flist)\n\nstart_time = time.time()\nres_pyhdfe = algorithm.residualize(x)\nend_time = time.time()\nprint(end_time - start_time)\n# 26.04527711868286\n\n\nstart_time = time.time()\nres_pyfixest, success = demean(x, flist, weights, tol = 1e-10)\n# Calculate the execution time\nend_time = time.time()\nprint(end_time - start_time)\n#4.334428071975708\n\nnp.allclose(res_pyhdfe , res_pyfixest)\n# True\n\n\n\n\nBump required formulaic version to 0.6.5.\nStop copying the data frame in fixef().\n\n\n\n\n\nFixes a big in the wildboottest method (see #158).\nAllows to run a wild bootstrap after fixed effect estimation.\n\n\n\n\n\nAdds support for wildboottest for Python 3.11.\n\n\n\n\n\nFixes a couple more bugs in the predict() and fixef() methods.\nThe predict() argument data is renamed to newdata.\n\n\n\n\nFixes a bug in predict() produced when multicollinear variables are dropped.\n\n\n\nImproved Collinearity handling. See #145\n\n\n\n\nMoves plotting from matplotlib to lets-plot.\nFixes a few minor bugs in plotting and the fixef() method.\n\n\n\n\n\n\nIt is no longer required to initiate an object of type Fixest prior to running [Feols(/reference/Feols.qmd) or fepois. Instead, you can now simply use feols() and fepois() as functions, just as in fixest. Both function can be found in an estimation module and need to obtain a pd.DataFrame as a function argument:\nfrom pyfixest.estimation import fixest, fepois\nfrom pyfixest.utils import get_data\n\ndata = get_data()\nfit = feols(\"Y ~ X1 | f1\", data = data, vcov = \"iid\")\nCalling feols() will return an instance of class [Feols(/reference/Feols.qmd), while calling fepois() will return an instance of class Fepois. Multiple estimation syntax will return an instance of class FixestMulti.\nPost processing works as before via .summary(), .tidy() and other methods.\n\n\n\nA summary function allows to compare multiple models:\nfrom pyfixest.summarize import summary\nfit2 = feols(\"Y ~ X1 + X2| f1\", data = data, vcov = \"iid\")\nsummary([fit, fit2])\nVisualization is possible via custom methods (.iplot() & .coefplot()), but a new module allows to visualize a list of [Feols(/reference/Feols.qmd) and/or Fepois instances:\nfrom pyfixest.visualize import coefplot, iplot\ncoefplot([fit, fit2])\nThe documentation has been improved (though there is still room for progress), and the code has been cleaned up a bit (also lots of room for improvements)."
  },
  {
    "objectID": "vignettes/Replicating-The-Effect.html",
    "href": "vignettes/Replicating-The-Effect.html",
    "title": "",
    "section": "",
    "text": "This notebook replicates code examples from Nick Huntington-Klein’s book on causal inference, The Effect.\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.estimation import feols\nfrom pyfixest.summarize import summary\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\n\nfrom causaldata import Mroz\n\n# Read in data\ndt = Mroz.load_pandas().data\n# Keep just working women\ndt = dt[dt[\"lfp\"] == True]\n# Create unlogged earnings\ndt.loc[:, \"earn\"] = dt[\"lwg\"].apply(\"exp\")\n\n# 5. Run multiple linear regression models by succesively adding controls\nfit = feols(fml=\"lwg ~ csw(inc, wc, k5)\", data=dt, vcov=\"iid\")\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: lwg\nInference:  iid\nObservations:  428\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      1.007 |        0.071 |    14.180 |      0.000 |   0.868 |    1.147 |\n| inc           |      0.010 |        0.003 |     2.947 |      0.003 |   0.003 |    0.016 |\n---\nRMSE: 0.715   R2: 0.02\n###\n\nEstimation:  OLS\nDep. var.: lwg\nInference:  iid\nObservations:  428\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.972 |        0.070 |    13.909 |      0.000 |   0.834 |    1.109 |\n| inc           |      0.005 |        0.003 |     1.640 |      0.102 |  -0.001 |    0.012 |\n| wc            |      0.342 |        0.075 |     4.595 |      0.000 |   0.196 |    0.489 |\n---\nRMSE: 0.698   R2: 0.066\n###\n\nEstimation:  OLS\nDep. var.: lwg\nInference:  iid\nObservations:  428\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.982 |        0.071 |    13.819 |      0.000 |   0.843 |    1.122 |\n| inc           |      0.005 |        0.003 |     1.590 |      0.113 |  -0.001 |    0.012 |\n| wc            |      0.349 |        0.075 |     4.656 |      0.000 |   0.202 |    0.497 |\n| k5            |     -0.072 |        0.087 |    -0.825 |      0.410 |  -0.243 |    0.099 |\n---\nRMSE: 0.697   R2: 0.068\n\n\nC:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_13896\\3519125210.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dt.loc[:, \"earn\"] = dt[\"lwg\"].apply(\"exp\")\n\n\n\n\n\n\n\n\nfrom causaldata import restaurant_inspections\n\nres = restaurant_inspections.load_pandas().data\nres.inspection_score = res.inspection_score.astype(float)\nres.NumberofLocations = res.NumberofLocations.astype(float)\nres.dtypes\n\nfit = feols(fml=\"inspection_score ~ NumberofLocations\", data=res)\nsummary(fit)\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  iid\nObservations:  27178\n\n| Coefficient       |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept         |     94.866 |        0.046 |  2049.047 |      0.000 |  94.775 |   94.956 |\n| NumberofLocations |     -0.019 |        0.000 |   -43.321 |      0.000 |  -0.020 |   -0.018 |\n---\nRMSE: 6.051   R2: 0.065\n\n\n\n\n\n\ndf = restaurant_inspections.load_pandas().data\n\nfit1 = feols(\n    fml=\"inspection_score ~ NumberofLocations + I(NumberofLocations^2) + Year\", data=df\n)\nfit2 = feols(fml=\"inspection_score ~ NumberofLocations*Weekend + Year\", data=df)\n\nsummary([fit1, fit2])\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  iid\nObservations:  27178\n\n| Coefficient            |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:-----------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept              |    225.504 |       12.409 |    18.172 |      0.000 | 201.181 |  249.827 |\n| NumberofLocations      |     -0.075 |        0.019 |    -4.041 |      0.000 |  -0.111 |   -0.039 |\n| I(NumberofLocations^2) |      0.056 |        0.019 |     3.009 |      0.003 |   0.020 |    0.093 |\n| Year                   |     -0.065 |        0.006 |   -10.527 |      0.000 |  -0.077 |   -0.053 |\n---\nRMSE: 6.038   R2: 0.069\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  iid\nObservations:  27178\n\n| Coefficient               |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept                 |    225.126 |       12.415 |    18.134 |      0.000 | 200.793 |  249.460 |\n| NumberofLocations         |     -0.019 |        0.000 |   -43.759 |      0.000 |  -0.020 |   -0.018 |\n| Weekend                   |      1.759 |        0.488 |     3.606 |      0.000 |   0.803 |    2.715 |\n| Year                      |     -0.065 |        0.006 |   -10.494 |      0.000 |  -0.077 |   -0.053 |\n| NumberofLocations:Weekend |     -0.010 |        0.008 |    -1.307 |      0.191 |  -0.025 |    0.005 |\n---\nRMSE: 6.038   R2: 0.069\n\n\n\n\n\n\nfeols(fml=\"inspection_score ~ Year + Weekend\", data=df, vcov=\"HC3\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  HC3\nObservations:  27178\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |    185.380 |       12.150 |    15.257 |      0.000 | 161.564 |  209.196 |\n| Year          |     -0.046 |        0.006 |    -7.551 |      0.000 |  -0.057 |   -0.034 |\n| Weekend       |      2.057 |        0.353 |     5.829 |      0.000 |   1.365 |    2.749 |\n---\nRMSE: 6.248   R2: 0.003\n\n\n\n\n\n\nfeols(fml=\"inspection_score ~ Year + Weekend\", data=df, vcov={\"CRV1\": \"Weekend\"}).tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      185.380033\n      3.264345\n      56.789343\n      0.011209\n      143.902592\n      226.857474\n    \n    \n      Year\n      -0.045640\n      0.001624\n      -28.107556\n      0.022640\n      -0.066272\n      -0.025008\n    \n    \n      Weekend\n      2.057166\n      0.001401\n      1468.256800\n      0.000434\n      2.039364\n      2.074969\n    \n  \n\n\n\n\n\n\n\n\nfit = feols(fml=\"inspection_score ~ Year + Weekend\", data=df)\nfit.wildboottest(B=999, param=\"Year\")\n\n\n\n\n\n\n\ntba\n\n\n\n\nfrom causaldata import gapminder\n\ngm = gapminder.load_pandas().data\ngm[\"logGDPpercap\"] = gm[\"gdpPercap\"].apply(\"log\")\n\nfit = feols(fml=\"lifeExp ~ C(country) + np.log(gdpPercap)\", data=gm)\nfit.tidy().head()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      -27.773459\n      2.500533\n      -11.107015\n      0.000000e+00\n      -32.678217\n      -22.868701\n    \n    \n      C(country)[T.Albania]\n      17.782625\n      2.195160\n      8.100835\n      1.110223e-15\n      13.476853\n      22.088397\n    \n    \n      C(country)[T.Algeria]\n      5.241055\n      2.214496\n      2.366704\n      1.806875e-02\n      0.897356\n      9.584755\n    \n    \n      C(country)[T.Angola]\n      -13.907122\n      2.201727\n      -6.316460\n      3.481857e-10\n      -18.225777\n      -9.588468\n    \n    \n      C(country)[T.Argentina]\n      8.132158\n      2.272781\n      3.578065\n      3.567229e-04\n      3.674133\n      12.590183\n    \n  \n\n\n\n\n\n\n\n\n# Set our individual and time (index) for our data\nfit = feols(fml=\"lifeExp ~ np.log(gdpPercap) | country + year\", data=gm)\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: lifeExp, Fixed effects: country+year\nInference:  CRV1\nObservations:  1704\n\n| Coefficient       |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| np.log(gdpPercap) |      1.450 |        0.677 |     2.141 |      0.034 |   0.111 |    2.788 |\n---\nRMSE: 3.267  Adj. R2: 0.018  Adj. R2 Within: 0.018\n\n\n\n\n\n\n\n\n\nfrom causaldata import organ_donations\n\nod = organ_donations.load_pandas().data\n\n# Create Treatment Variable\nod[\"California\"] = od[\"State\"] == \"California\"\nod[\"After\"] = od[\"Quarter_Num\"] > 3\nod[\"Treated\"] = 1 * (od[\"California\"] & od[\"After\"])\n\ndid = feols(fml=\"Rate ~ Treated | State + Quarter\", data=od)\ndid.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Rate, Fixed effects: State+Quarter\nInference:  CRV1\nObservations:  162\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Treated       |     -0.022 |        0.006 |    -3.733 |      0.001 |  -0.035 |   -0.010 |\n---\nRMSE: 0.022  Adj. R2: 0.003  Adj. R2 Within: 0.003\n\n\n\n\n\n\nfrom causaldata import organ_donations\nfrom pyfixest.visualize import iplot\n\nod = organ_donations.load_pandas().data\n\n# Create Treatment Variable\nod[\"California\"] = od[\"State\"] == \"California\"\n# od[\"Quarter_Num\"] = pd.Categorical(od.Quarter_Num)\nod[\"California\"] = od.California.astype(float)\n\ndid2 = feols(\n    fml=\"Rate ~ i(Quarter_Num, California) | State + Quarter_Num\", data=od, i_ref1=3\n)\n\ndid2.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.1]:California\n      -0.002942\n      0.004986\n      -0.590105\n      0.560215\n      -0.013191\n      0.007307\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.2]:California\n      0.006296\n      0.002222\n      2.833502\n      0.008782\n      0.001729\n      0.010864\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.4]:California\n      -0.021565\n      0.004937\n      -4.368464\n      0.000178\n      -0.031713\n      -0.011418\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.5]:California\n      -0.020292\n      0.004387\n      -4.625529\n      0.000090\n      -0.029310\n      -0.011275\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.6]:California\n      -0.022165\n      0.009820\n      -2.257160\n      0.032627\n      -0.042351\n      -0.001980"
  },
  {
    "objectID": "vignettes/tutorial.html",
    "href": "vignettes/tutorial.html",
    "title": "",
    "section": "",
    "text": "In a first step, we load the module and some example data:\n\n%load_ext autoreload\n%autoreload 2\n\nfrom pyfixest.estimation import feols, fepois\nfrom pyfixest.summarize import summary, etable\nfrom pyfixest.visualize import coefplot, iplot\nfrom pyfixest.utils import get_data\n\n\n            \n            \n            \n\n\n\ndata = get_data()\ndata.head()\n\n\n\n\n\n  \n    \n      \n      Y\n      Y2\n      X1\n      X2\n      f1\n      f2\n      f3\n      group_id\n      Z1\n      Z2\n    \n  \n  \n    \n      0\n      NaN\n      2.357103\n      0.0\n      0.457858\n      15.0\n      0.0\n      7.0\n      9.0\n      -0.330607\n      1.054826\n    \n    \n      1\n      -1.458643\n      5.163147\n      NaN\n      -4.998406\n      6.0\n      21.0\n      4.0\n      8.0\n      NaN\n      -4.113690\n    \n    \n      2\n      0.169132\n      0.751140\n      2.0\n      1.558480\n      NaN\n      1.0\n      7.0\n      16.0\n      1.207778\n      0.465282\n    \n    \n      3\n      3.319513\n      -2.656368\n      1.0\n      1.560402\n      1.0\n      10.0\n      11.0\n      3.0\n      2.869997\n      0.467570\n    \n    \n      4\n      0.134420\n      -1.866416\n      2.0\n      -3.472232\n      19.0\n      20.0\n      6.0\n      14.0\n      0.835819\n      -3.115669\n    \n  \n\n\n\n\n\n\nWe can estimate a fixed effects regression via the feols() function. feols() has three arguments: a two-sided model formula, the data, and optionally, the type of inference.\n\nfit = feols(fml=\"Y~X1 | f1\", data=data, vcov=\"HC1\")\ntype(fit)\n\npyfixest.feols.Feols\n\n\nThe first part of the formula contains the dependent variable and “regular” covariates, while the second part contains fixed effects.\nfeols() returns an instance of the Fixest class.\nTo inspect the results, we can use a summary function or method:\n\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.066 |   -14.311 |      0.000 |  -1.080 |   -0.819 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n\n\nAlternatively, the .summarize module contains a summary function, which can be applied on instances of regression model objects or lists of regression model objects.\n\nsummary(fit)\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.066 |   -14.311 |      0.000 |  -1.080 |   -0.819 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n\n\nYou can access individual elements of the summary via dedicated methods: .tidy() returns a “tidy” pd.DataFrame, .coef() returns estimated parameters, and se() estimated standard errors. Other methods include pvalue(), confint() and tstat().\n\nfit.coef()\n\nCoefficient\nX1   -0.949441\nName: Estimate, dtype: float64\n\n\n\nfit.se()\n\nCoefficient\nX1    0.066343\nName: Std. Error, dtype: float64\n\n\n\n\n\nSupported covariance types are “iid”, “HC1-3”, CRV1 and CRV3 (up to two-way clustering). Inference can be adjusted “on-the-fly” via the .vcov() method:\n\nfit.vcov({\"CRV1\": \"group_id + f1\"}).summary()\nfit.vcov({\"CRV3\": \"group_id\"}).summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.088 |   -10.839 |      0.000 |  -1.133 |   -0.765 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  CRV3\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.095 |   -10.005 |      0.000 |  -1.149 |   -0.750 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n\n\nIt is also possible to run a wild (cluster) bootstrap after estimation (via the wildboottest module):\n\nfit2 = feols(fml=\"Y~ X1\", data=data, vcov={\"CRV1\": \"group_id\"})\nfit2.wildboottest(param=\"X1\", B=999)\n\nparam                            X1\nt value                   -8.567587\nPr(>|t|)                        0.0\nbootstrap_type                   11\ninference         CRV(['group_id'])\nimpose_null                    True\ndtype: object\n\n\nNote that the wild bootstrap currently does not support fixed effects in the regression model. Supporting fixed effects is work in progress.\n\n\n\nIt is also possible to estimate instrumental variable models with one endogenous variable and (potentially multiple) instruments:\n\niv_fit = feols(fml=\"Y2~ 1 | f1 + f2 | X1 ~ Z1 + Z2\", data=data)\niv_fit.summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y2, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -1.600 |        0.333 |    -4.801 |      0.000 |  -2.282 |   -0.919 |\n---\n\n\nIf the model does not contain any fixed effects, just drop the second part of the formula above:\n\nfeols(fml=\"Y~ 1 | X1 ~ Z1 + Z2\", data=data).summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y\nInference:  iid\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.911 |        0.156 |     5.843 |      0.000 |   0.605 |    1.217 |\n| X1            |     -0.993 |        0.134 |    -7.398 |      0.000 |  -1.256 |   -0.730 |\n---\n\n\nIV estimation with multiple endogenous variables and multiple estimation syntax is currently not supported. The syntax is “depvar ~ exog.vars | fixef effects | endog.vars ~ instruments”.\n\n\n\nWith version 0.8.4, it is possible to estimate Poisson Regressions (not yet on PyPi):\n\nfrom pyfixest.utils import get_data\n\npois_data = get_data(model=\"Fepois\")\npois_fit = fepois(fml=\"Y~X1 | f1+f2\", data=pois_data, vcov={\"CRV1\": \"group_id\"})\npois_fit.summary()\n\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.007 |        0.031 |    -0.237 |      0.813 |  -0.069 |    0.054 |\n---\nDeviance: 1070.729\n\n\n\n\n\nPyFixest supports a range of multiple estimation functionality: sw, sw0, csw, csw0, and multiple dependent variables. If multiple regression syntax is used, feols() and fepois returns an instance of a FixestMulti object, which essentially consists of a dicionary of Fepois or [Feols(/reference/Feols.qmd) instances.\n\nmulti_fit = feols(fml=\"Y~X1 | csw0(f1, f2)\", data=data, vcov=\"HC1\")\nmulti_fit\n\n<pyfixest.FixestMulti.FixestMulti at 0x23bd899c3d0>\n\n\n\nmulti_fit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y\nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.919 |        0.112 |     8.223 |      0.000 |   0.699 |    1.138 |\n| X1            |     -1.000 |        0.082 |   -12.134 |      0.000 |  -1.162 |   -0.838 |\n---\nRMSE: 2.158   R2: 0.123\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.066 |   -14.311 |      0.000 |  -1.080 |   -0.819 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.919 |        0.058 |   -15.918 |      0.000 |  -1.033 |   -0.806 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\n\nAlternatively, you can look at the estimation results via the etable() method:\n\nmulti_fit.etable()\n\n\n\n\n\n  \n    \n      fml\n      Y~X1\n      Y~X1|f1\n      Y~X1|f1+f2\n    \n    \n      Coefficient\n      Intercept\n      X1\n      X1\n      X1\n    \n  \n  \n    \n      Estimate\n      0.919\n      -1.000\n      -0.949\n      -0.919\n    \n    \n      Std. Error\n      0.112\n      0.082\n      0.066\n      0.058\n    \n    \n      t value\n      8.223\n      -12.134\n      -14.311\n      -15.918\n    \n    \n      Pr(>|t|)\n      0.000\n      0.000\n      0.000\n      0.000\n    \n    \n      2.5 %\n      0.699\n      -1.162\n      -1.080\n      -1.033\n    \n    \n      97.5 %\n      1.138\n      -0.838\n      -0.819\n      -0.806\n    \n  \n\n\n\n\nIf you are only insterested in some parameters, e.g. “X1”, you can use the following syntax:\n\nmulti_fit.etable().xs(\"X1\", level=1, axis=1)\n\n\n\n\n\n  \n    \n      fml\n      Y~X1\n      Y~X1|f1\n      Y~X1|f1+f2\n    \n  \n  \n    \n      Estimate\n      -1.000\n      -0.949\n      -0.919\n    \n    \n      Std. Error\n      0.082\n      0.066\n      0.058\n    \n    \n      t value\n      -12.134\n      -14.311\n      -15.918\n    \n    \n      Pr(>|t|)\n      0.000\n      0.000\n      0.000\n    \n    \n      2.5 %\n      -1.162\n      -1.080\n      -1.033\n    \n    \n      97.5 %\n      -0.838\n      -0.819\n      -0.806\n    \n  \n\n\n\n\nYou can access an individual model by its name - i.e. a formula - via the all_fitted_models attribure.\n\nmulti_fit.all_fitted_models[\"Y~X1\"].tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      0.918518\n      0.111707\n      8.222580\n      6.661338e-16\n      0.699310\n      1.137725\n    \n    \n      X1\n      -1.000086\n      0.082420\n      -12.134086\n      0.000000e+00\n      -1.161822\n      -0.838350\n    \n  \n\n\n\n\nor equivalently via the fetch_model method:\n\nmulti_fit.fetch_model(0).tidy()\n\nModel:  Y~X1\n\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      0.918518\n      0.111707\n      8.222580\n      6.661338e-16\n      0.699310\n      1.137725\n    \n    \n      X1\n      -1.000086\n      0.082420\n      -12.134086\n      0.000000e+00\n      -1.161822\n      -0.838350\n    \n  \n\n\n\n\nHere, 0 simply fetches the first model stored in the all_fitted_models dictionary, 1 the second etc.\nObjects of type Fixest come with a range of additional methods: tidy(), coef(), vcov() etc, which essentially loop over the equivalent methods of all fitted models. E.g. Fixest.vcov() updates inference for all models stored in Fixest.\n\nmulti_fit.vcov(\"iid\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y\nInference:  iid\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.919 |        0.112 |     8.214 |      0.000 |   0.699 |    1.138 |\n| X1            |     -1.000 |        0.085 |   -11.802 |      0.000 |  -1.166 |   -0.834 |\n---\nRMSE: 2.158   R2: 0.123\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.069 |   -13.846 |      0.000 |  -1.084 |   -0.815 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.919 |        0.058 |   -15.797 |      0.000 |  -1.033 |   -0.805 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\n\nIf you have estimated multiple models without multiple estimation syntax and still want to compare them, you can use the etable() function:\n\nfrom pyfixest.summarize import etable\n\netable([fit, fit2])\n\n                           est1              est2\n------------  -----------------  ----------------\ndepvar                        Y                 Y\n-------------------------------------------------\nX1            -0.949*** (0.095)   -1.0*** (0.117)\nIntercept                        0.919*** (0.121)\n-------------------------------------------------\nf1                            x                 -\n-------------------------------------------------\nR2                        0.437             0.123\nS.E. type          by: group_id      by: group_id\nObservations                997               998\n-------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\n\nPyFixest provides two functions to visualize the results of a regression: coefplot and iplot.\n\nfrom lets_plot import *\n\nLetsPlot.setup_html()\n\nmulti_fit.coefplot().show()\n\n\n            \n            \n            \n\n\n   \n   \n\n\n\n\n\nPyFixest supports eventy study designs via two-way fixed effects and Gardner’s 2-stage estimator.\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.did.estimation import did2s\n\nurl = \"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\ndf_het.head()\n\n\n\n\n\n  \n    \n      \n      unit\n      state\n      group\n      unit_fe\n      g\n      year\n      year_fe\n      treat\n      rel_year\n      rel_year_binned\n      error\n      te\n      te_dynamic\n      dep_var\n    \n  \n  \n    \n      0\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1990\n      0.066159\n      False\n      -20.0\n      -6\n      -0.086466\n      0\n      0.0\n      7.022709\n    \n    \n      1\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1991\n      -0.030980\n      False\n      -19.0\n      -6\n      0.766593\n      0\n      0.0\n      7.778628\n    \n    \n      2\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1992\n      -0.119607\n      False\n      -18.0\n      -6\n      1.512968\n      0\n      0.0\n      8.436377\n    \n    \n      3\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1993\n      0.126321\n      False\n      -17.0\n      -6\n      0.021870\n      0\n      0.0\n      7.191207\n    \n    \n      4\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1994\n      -0.106921\n      False\n      -16.0\n      -6\n      -0.017603\n      0\n      0.0\n      6.918492\n    \n  \n\n\n\n\n\nfit_did2s = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n    i_ref1=[-1.0, np.inf],\n)\n\nfit_twfe = feols(\n    \"dep_var ~ i(rel_year) | state + year\",\n    df_het,\n    i_ref1=[-1.0, np.inf],\n    vcov={\"CRV1\": \"state\"},\n)\n\niplot(\n    [fit_did2s, fit_twfe], coord_flip=False, figsize=(900, 400), title=\"TWFE vs DID2S\"\n)\n\n   \n   \n\n\nThe event_study() function provides a common API for several event study estimators.\n\nfrom pyfixest.did.event_study import event_study\nfrom pyfixest.summarize import etable\n\nfit_twfe = event_study(\n    data=df_het,\n    yname=\"dep_var\",\n    idname=\"state\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"twfe\",\n)\n\nfit_did2s = event_study(\n    data=df_het,\n    yname=\"dep_var\",\n    idname=\"state\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"did2s\",\n)\n\netable([fit_twfe, fit_did2s])\n\n                          est1              est2\n------------  ----------------  ----------------\ndepvar                 dep_var       dep_var_hat\n------------------------------------------------\nATT           2.135*** (0.044)  2.152*** (0.048)\n------------------------------------------------\nstate                        x                 -\nyear                         x                 -\n------------------------------------------------\nR2                           -                 -\nS.E. type            by: state              CRV1\nObservations             46500             46500\n------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001"
  }
]