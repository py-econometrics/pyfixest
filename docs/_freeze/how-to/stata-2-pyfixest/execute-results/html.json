{
  "hash": "ce34b8b52b65784016f60929cef4730d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Translating Stata to PyFixest\"\naliases:\n  - /stata-2-pyfixest.html\nformat:\n  html:\n    html-table-processing: none\ntoc: true\ntoc-title: \"On this page\"\ntoc-location: left\n---\n\n# How to Get Started\n\nThis guide will focus on how to replicate the regression results you would get in Stata\nwith the Python package `pyfixest` and assumes you know how to do things like install\nPython packages and load data into Pandas.  For a broader introduction to doing\neconmetrics in Python you might check out Arthur Turrell's\n[Coding for Economist](https://aeturrell.github.io/coding-for-economists/intro.html),\nwhich includes a section on\n[Coming from Stata](https://aeturrell.github.io/coding-for-economists/coming-from-stata.html),\nor [Tidy Finance with Python](https://www.tidy-finance.org/python/) by Christopher\nScheuch, Stefan Voigt, Patrick Weiss, and Christoph Frey. You can also check out the fixest section\nof [stata2r](https://stata2r.github.io/fixest/) as there is a lot of overlap between fixest and PyFixest\nsyntax.\n\n# Data\n\n`pyfixest` includes a function to generate a dataset for testing.\n\n::: {#fa2fa782 .cell execution_count=1}\n``` {.python .cell-code}\nimport pyfixest as pf\ndf = pf.get_data()\n```\n:::\n\n\nIf you want to use the same dataset in Stata, you can save the data to your home\ndirectory as a .dta file with\n\n::: {#5a85c105 .cell execution_count=2}\n``` {.python .cell-code}\nimport os\ndf.to_stata(os.path.join(os.path.expanduser(\"~\"), \"pyfixest-data.dta\"))\n```\n:::\n\n\nand then load the data in Stata with\n\n```stata\ncd ~\nuse pyfixest-data.dta\n```\n\n# Basic OLS\n\nTo do a basic linear regression in `pyfixest` you would simply use\n\n::: {#9a550319 .cell execution_count=3}\n``` {.python .cell-code}\nfit1 = pf.feols(\"Y ~ X1\", data = df)\nfit2 = pf.feols(\"Y ~ X1 + X2\", data = df)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n            <div id=\"xj1haL\"></div>\n            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n                if(!window.letsPlotCallQueue) {\n                    window.letsPlotCallQueue = [];\n                }; \n                window.letsPlotCall = function(f) {\n                    window.letsPlotCallQueue.push(f);\n                };\n                (function() {\n                    var script = document.createElement(\"script\");\n                    script.type = \"text/javascript\";\n                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.7.3/js-package/distr/lets-plot.min.js\";\n                    script.onload = function() {\n                        window.letsPlotCall = function(f) {f();};\n                        window.letsPlotCallQueue.forEach(function(f) {f();});\n                        window.letsPlotCallQueue = [];\n                        \n                    };\n                    script.onerror = function(event) {\n                        window.letsPlotCall = function(f) {};    // noop\n                        window.letsPlotCallQueue = [];\n                        var div = document.createElement(\"div\");\n                        div.style.color = 'darkred';\n                        div.textContent = 'Error loading Lets-Plot JS';\n                        document.getElementById(\"xj1haL\").appendChild(div);\n                    };\n                    var e = document.getElementById(\"xj1haL\");\n                    e.appendChild(script);\n                })()\n            </script>\n            \n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n            <div id=\"ZNU1Mn\"></div>\n            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n                if(!window.letsPlotCallQueue) {\n                    window.letsPlotCallQueue = [];\n                }; \n                window.letsPlotCall = function(f) {\n                    window.letsPlotCallQueue.push(f);\n                };\n                (function() {\n                    var script = document.createElement(\"script\");\n                    script.type = \"text/javascript\";\n                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.7.3/js-package/distr/lets-plot.min.js\";\n                    script.onload = function() {\n                        window.letsPlotCall = function(f) {f();};\n                        window.letsPlotCallQueue.forEach(function(f) {f();});\n                        window.letsPlotCallQueue = [];\n                        \n                    };\n                    script.onerror = function(event) {\n                        window.letsPlotCall = function(f) {};    // noop\n                        window.letsPlotCallQueue = [];\n                        var div = document.createElement(\"div\");\n                        div.style.color = 'darkred';\n                        div.textContent = 'Error loading Lets-Plot JS';\n                        document.getElementById(\"ZNU1Mn\").appendChild(div);\n                    };\n                    var e = document.getElementById(\"ZNU1Mn\");\n                    e.appendChild(script);\n                })()\n            </script>\n            \n```\n:::\n:::\n\n\nwhich is equivalent to\n\n```stata\nreg Y X1\n\n*       Source |       SS           df       MS      Number of obs   =       998\n* -------------+----------------------------------   F(1, 996)       =    139.30\n*        Model |  650.171727         1  650.171727   Prob > F        =    0.0000\n*     Residual |  4648.80985       996  4.66747977   R-squared       =    0.1227\n* -------------+----------------------------------   Adj R-squared   =    0.1218\n*        Total |  5298.98157       997  5.31492635   Root MSE        =    2.1604\n*\n* ------------------------------------------------------------------------------\n*            Y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -1.000086   .0847353   -11.80   0.000    -1.166366   -.8338056\n*        _cons |   .9185178   .1118212     8.21   0.000     .6990856     1.13795\n* ------------------------------------------------------------------------------\n\nreg y X1 X2\n\n*       Source |       SS           df       MS      Number of obs   =       998\n* -------------+----------------------------------   F(2, 995)       =    106.99\n*        Model |  937.866146         2  468.933073   Prob > F        =    0.0000\n*     Residual |  4361.11543       995  4.38303058   R-squared       =    0.1770\n* -------------+----------------------------------   Adj R-squared   =    0.1753\n*        Total |  5298.98157       997  5.31492635   Root MSE        =    2.0936\n*\n* ------------------------------------------------------------------------------\n*            Y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9929358   .0821175   -12.09   0.000    -1.154079   -.8317925\n*           X2 |  -.1763424    .021766    -8.10   0.000    -.2190549   -.1336299\n*        _cons |   .8887791   .1084224     8.20   0.000     .6760163    1.101542\n* ------------------------------------------------------------------------------\n```\n\nin Stata.  However, you should note that this will only run the regressions and store\nthe results in `fit1` and `fit2`.  To show the results you can use some of the following\nmethods and functions.\n\n::: {#e425fa55 .cell execution_count=4}\n``` {.python .cell-code}\nfit1.summary() # Basic summary statisticsmodels\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: 0\nInference:  iid\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.919 |        0.112 |     8.214 |      0.000 |  0.699 |   1.138 |\n| X1            |     -1.000 |        0.085 |   -11.802 |      0.000 | -1.166 |  -0.834 |\n---\nRMSE: 2.158 R2: 0.123 \n```\n:::\n:::\n\n\n::: {#31e40945 .cell execution_count=5}\n``` {.python .cell-code}\nfit1.tidy() # Estimates, std errors, t-values, etc. in a \"tidy\" tablemodels\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Estimate</th>\n      <th>Std. Error</th>\n      <th>t value</th>\n      <th>Pr(&gt;|t|)</th>\n      <th>2.5%</th>\n      <th>97.5%</th>\n    </tr>\n    <tr>\n      <th>Coefficient</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>0.918518</td>\n      <td>0.111821</td>\n      <td>8.214166</td>\n      <td>6.661338e-16</td>\n      <td>0.699086</td>\n      <td>1.137950</td>\n    </tr>\n    <tr>\n      <th>X1</th>\n      <td>-1.000086</td>\n      <td>0.084735</td>\n      <td>-11.802468</td>\n      <td>0.000000e+00</td>\n      <td>-1.166366</td>\n      <td>-0.833806</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#6f6d7c2f .cell execution_count=6}\n``` {.python .cell-code}\npf.report.etable([fit1, fit2]) # Customizable table that can include results for multiple models\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div id=\"xtergozxbf\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>\n#xtergozxbf table {\n          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n          -webkit-font-smoothing: antialiased;\n          -moz-osx-font-smoothing: grayscale;\n        }\n\n#xtergozxbf thead, tbody, tfoot, tr, td, th { border-style: none; }\n tr { background-color: transparent; }\n#xtergozxbf p { margin: 0; padding: 0; }\n #xtergozxbf .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: hidden; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n #xtergozxbf .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n #xtergozxbf .gt_title { color: #333333; font-size: 16px; font-weight: initial; padding-top: 6px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n #xtergozxbf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 5px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n #xtergozxbf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #xtergozxbf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #xtergozxbf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 0.25px; border-bottom-color: black; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #xtergozxbf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 16px; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 0px; border-left-color: white; border-right-style: none; border-right-width: 0px; border-right-color: white; vertical-align: bottom; padding-top: 2px; padding-bottom: 7px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n #xtergozxbf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 16px; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n #xtergozxbf .gt_column_spanner_outer:first-child { padding-left: 0; }\n #xtergozxbf .gt_column_spanner_outer:last-child { padding-right: 0; }\n #xtergozxbf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 0.25px; border-bottom-color: black; vertical-align: bottom; padding-top: 2px; padding-bottom: 2px; overflow-x: hidden; display: inline-block; width: 100%; }\n #xtergozxbf .gt_spanner_row { border-bottom-style: hidden; }\n #xtergozxbf .gt_group_heading { padding-top: 0px; padding-bottom: 0px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 0px; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 0.25px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 0.25px; border-bottom-color: black; border-left-style: none; border-left-width: 1px; border-left-color: white; border-right-style: none; border-right-width: 1px; border-right-color: white; vertical-align: middle; text-align: left; }\n #xtergozxbf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 0px; font-weight: initial; border-top-style: solid; border-top-width: 0.25px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 0.25px; border-bottom-color: black; vertical-align: middle; }\n #xtergozxbf .gt_from_md> :first-child { margin-top: 0; }\n #xtergozxbf .gt_from_md> :last-child { margin-bottom: 0; }\n #xtergozxbf .gt_row { padding-top: 2px; padding-bottom: 2px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: none; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 0px; border-left-color: white; border-right-style: none; border-right-width: 0px; border-right-color: white; vertical-align: middle; overflow-x: hidden; }\n #xtergozxbf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 16px; font-weight: initial; text-transform: inherit; border-right-style: hidden; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n #xtergozxbf .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n #xtergozxbf .gt_row_group_first td { border-top-width: 0.25px; }\n #xtergozxbf .gt_row_group_first th { border-top-width: 0.25px; }\n #xtergozxbf .gt_striped { color: #333333; background-color: #F4F4F4; }\n #xtergozxbf .gt_table_body { border-top-style: solid; border-top-width: 0px; border-top-color: black; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: black; }\n #xtergozxbf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; }\n #xtergozxbf .gt_first_grand_summary_row_bottom { border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; }\n #xtergozxbf .gt_last_grand_summary_row_top { border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; }\n #xtergozxbf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n #xtergozxbf .gt_sourcenote { font-size: 10px; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n #xtergozxbf .gt_left { text-align: left; }\n #xtergozxbf .gt_center { text-align: center; }\n #xtergozxbf .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n #xtergozxbf .gt_font_normal { font-weight: normal; }\n #xtergozxbf .gt_font_bold { font-weight: bold; }\n #xtergozxbf .gt_font_italic { font-style: italic; }\n #xtergozxbf .gt_super { font-size: 65%; }\n #xtergozxbf .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n #xtergozxbf .gt_asterisk { font-size: 100%; vertical-align: 0; }\n \n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n<thead>\n\n<tr class=\"gt_col_headings gt_spanner_row\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n  <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Y\">\n    <span class=\"gt_column_spanner\">Y</span>\n  </th>\n</tr>\n<tr class=\"gt_col_headings\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"0\">(1)</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"1\">(2)</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n  <tr class=\"gt_group_heading_row\">\n    <th class=\"gt_group_heading\" colspan=\"3\">coef</th>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">X1</th>\n    <td class=\"gt_row gt_center\">-1.000*** <br> (0.085)</td>\n    <td class=\"gt_row gt_center\">-0.993*** <br> (0.082)</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">X2</th>\n    <td class=\"gt_row gt_center\"></td>\n    <td class=\"gt_row gt_center\">-0.176*** <br> (0.022)</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">Intercept</th>\n    <td class=\"gt_row gt_center\">0.919*** <br> (0.112)</td>\n    <td class=\"gt_row gt_center\">0.889*** <br> (0.108)</td>\n  </tr>\n  <tr class=\"gt_group_heading_row\">\n    <th class=\"gt_group_heading\" colspan=\"3\">stats</th>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">Observations</th>\n    <td class=\"gt_row gt_center\">998</td>\n    <td class=\"gt_row gt_center\">998</td>\n  </tr>\n  <tr>\n    <th class=\"gt_row gt_left gt_stub\">R<sup>2</sup></th>\n    <td class=\"gt_row gt_center\">0.123</td>\n    <td class=\"gt_row gt_center\">0.177</td>\n  </tr>\n</tbody>\n  <tfoot class=\"gt_sourcenotes\">\n  \n  <tr>\n    <td class=\"gt_sourcenote\" colspan=\"3\">Significance levels: * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001. Format of coefficient cell: Coefficient   (Std. Error)</td>\n  </tr>\n\n</tfoot>\n\n</table>\n\n</div>\n        \n```\n:::\n:::\n\n\nYou can also access individual parts of the results with a variety of methods like\n\n::: {#499e546e .cell execution_count=7}\n``` {.python .cell-code}\nfit1.coef() # Get the coefficients\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nCoefficient\nIntercept    0.918518\nX1          -1.000086\nName: Estimate, dtype: float64\n```\n:::\n:::\n\n\n::: {#e465c4e7 .cell execution_count=8}\n``` {.python .cell-code}\nfit1.se() # Get the standard errors\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nCoefficient\nIntercept    0.111821\nX1           0.084735\nName: Std. Error, dtype: float64\n```\n:::\n:::\n\n\n::: {#76f69473 .cell execution_count=9}\n``` {.python .cell-code}\nfit1.pvalue() # Get the p-values\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nCoefficient\nIntercept    6.661338e-16\nX1           0.000000e+00\nName: Pr(>|t|), dtype: float64\n```\n:::\n:::\n\n\n## Robust Standard Errors\n\nTo get heteroskedasticity robust standard errors you can use\n\n::: {#98b7936a .cell execution_count=10}\n``` {.python .cell-code}\nfit3 = pf.feols(\"Y ~ X1 + X2\", data=df, vcov=\"HC1\")\nfit3.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: 0\nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.889 |        0.108 |     8.249 |      0.000 |  0.677 |   1.100 |\n| X1            |     -0.993 |        0.080 |   -12.439 |      0.000 | -1.150 |  -0.836 |\n| X2            |     -0.176 |        0.022 |    -8.129 |      0.000 | -0.219 |  -0.134 |\n---\nRMSE: 2.09 R2: 0.177 \n```\n:::\n:::\n\n\nwhich is equivalent to\n\n```stata\nreg Y X1 X2, robust\n\n* Linear regression                               Number of obs     =        998\n*                                                 F(2, 995)         =     107.91\n*                                                 Prob > F          =     0.0000\n*                                                 R-squared         =     0.1770\n*                                                 Root MSE          =     2.0936\n*\n* ------------------------------------------------------------------------------\n*              |               Robust\n*            Y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9929358   .0798259   -12.44   0.000    -1.149582   -.8362893\n*           X2 |  -.1763424   .0216936    -8.13   0.000    -.2189129   -.1337719\n*        _cons |   .8887791   .1077457     8.25   0.000     .6773442    1.100214\n* ------------------------------------------------------------------------------\n```\n\nor\n\n```stata\nreg Y X1 X2, vce(robust)\n\n* Identical output to above\n```\n\nor you can choose a different type of robust standard errors like \"HC3\" using\n\n::: {#b3869676 .cell execution_count=11}\n``` {.python .cell-code}\nfit4 = pf.feols(\"Y ~ X1 + X2\", data=df, vcov=\"HC3\")\nfit4.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: 0\nInference:  HC3\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.889 |        0.108 |     8.222 |      0.000 |  0.677 |   1.101 |\n| X1            |     -0.993 |        0.080 |   -12.396 |      0.000 | -1.150 |  -0.836 |\n| X2            |     -0.176 |        0.022 |    -8.087 |      0.000 | -0.219 |  -0.134 |\n---\nRMSE: 2.09 R2: 0.177 \n```\n:::\n:::\n\n\nNote: This will not exactly match the output of the equivalent Stata command, which is\n\n```stata\nreg Y X1 X2, vce(hc3)\n\n* Linear regression                               Number of obs     =        998\n*                                                 F(2, 995)         =     107.38\n*                                                 Prob > F          =     0.0000\n*                                                 R-squared         =     0.1770\n*                                                 Root MSE          =     2.0936\n*\n* ------------------------------------------------------------------------------\n*              |             Robust HC3\n*            Y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9929358   .0799832   -12.41   0.000    -1.149891   -.8359807\n*           X2 |  -.1763424   .0217734    -8.10   0.000    -.2190693   -.1336154\n*        _cons |   .8887791   .1079372     8.23   0.000     .6769684     1.10059\n* ------------------------------------------------------------------------------\n```\n\nthis is because by default, `pyfixest` uses two small sample size corrections for HC3\nrobust standard errors, while Stata only uses one of them. You can turn off the\ncorrection that Stata doesn't use with the `ssc` argument.\n\n::: {#94d3241d .cell execution_count=12}\n``` {.python .cell-code}\nfit5 = pf.feols(\"Y ~ X1 + X2\", data=df, vcov=\"HC3\", ssc=pf.ssc(k_adj = False))\nfit5.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: 0\nInference:  HC3\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.889 |        0.108 |     8.234 |      0.000 |  0.677 |   1.101 |\n| X1            |     -0.993 |        0.080 |   -12.414 |      0.000 | -1.150 |  -0.836 |\n| X2            |     -0.176 |        0.022 |    -8.099 |      0.000 | -0.219 |  -0.134 |\n---\nRMSE: 2.09 R2: 0.177 \n```\n:::\n:::\n\n\nwhich matches Stata exactly.  You can read all about the small sample size corrections\nimplememnted by `pyfixest` at\n[On Small Sample Corrections](https://py-econometrics.github.io/pyfixest/explanation/ssc.html).\n\n## Clustered Standard Errors\n\nTo cluster the standard errors by group you can use\n\n::: {#b57efc31 .cell execution_count=13}\n``` {.python .cell-code}\nfit6 = pf.feols(\"Y ~ X1 + X2\", data=df.dropna(subset=['f1']), vcov={\"CRV1\": \"f1\"})\nfit6.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: 0\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.890 |        0.262 |     3.393 |      0.002 |  0.353 |   1.426 |\n| X1            |     -0.995 |        0.076 |   -13.142 |      0.000 | -1.150 |  -0.840 |\n| X2            |     -0.177 |        0.020 |    -8.920 |      0.000 | -0.217 |  -0.136 |\n---\nRMSE: 2.091 R2: 0.177 \n```\n:::\n:::\n\n\nwhich is equivalent to\n\n```stata\nreg Y X1 X2, vce(cluster f1)\n\n* Linear regression                               Number of obs     =        997\n*                                                 F(2, 29)          =     102.51\n*                                                 Prob > F          =     0.0000\n*                                                 R-squared         =     0.1774\n*                                                 Root MSE          =      2.094\n*\n*                                     (Std. err. adjusted for 30 clusters in f1)\n* ------------------------------------------------------------------------------\n*              |               Robust\n*            Y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9951969   .0757246   -13.14   0.000    -1.150071   -.8403227\n*           X2 |  -.1766173    .019799    -8.92   0.000    -.2171109   -.1361237\n*        _cons |   .8895569   .2622066     3.39   0.002     .3532841     1.42583\n* ------------------------------------------------------------------------------\n```\n\nNote: clustered standard errors are not supported with missing values in the cluster\nvariable, which is why we drop the rows with missing values for `f1`.\n\nFor two way clustering you would need to use\n\n::: {#8c293402 .cell execution_count=14}\n``` {.python .cell-code}\nfit7 = pf.feols(\n  \"Y ~ X1 + X2\",\n  data=df.dropna(subset=['f1', 'f2']),\n  vcov={\"CRV1\": \"f1 + f2\"}\n)\nfit7.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: 0\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.890 |        0.301 |     2.958 |      0.006 |  0.274 |   1.505 |\n| X1            |     -0.995 |        0.073 |   -13.570 |      0.000 | -1.145 |  -0.845 |\n| X2            |     -0.177 |        0.023 |    -7.535 |      0.000 | -0.225 |  -0.129 |\n---\nRMSE: 2.091 R2: 0.177 \n```\n:::\n:::\n\n\nNote: This will not exactly match the output of the equivalent Stata command, which is\n\n```stata\nreg Y X1 X2, vce(cluster f1 f2)\n\n* Linear regression                                       Number of obs =    997\n* Clusters per comb.:                                     Cluster comb. =      3\n*   min =  30                                             F(2, 29)      =  88.58\n*   avg = 211                                             Prob > F      = 0.0000\n*   max = 572                                             R-squared     = 0.1774\n*                                                         Adj R-squared = 0.1758\n*                                                         Root MSE      = 2.0940\n*\n*                                   (Std. err. adjusted for multiway clustering)\n* ------------------------------------------------------------------------------\n*              |               Robust\n*            Y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9951969    .074771   -13.31   0.000    -1.148121   -.8422731\n*           X2 |  -.1766173     .02376    -7.43   0.000     -.225212   -.1280226\n*        _cons |   .8895569   .3016464     2.95   0.006     .2726208    1.506493\n* ------------------------------------------------------------------------------\n* Cluster combinations formed by f1 and f2.\n```\n\nthis is because by default, `pyfixest` uses a small sample size correction that adjusts\neach clustering dimentsion by whichever dimension has the smallest number of clusters,\nwhile in Stata the default is to adjust each dimension based on the number of clusters\nin that dimension. You can use the same correction as Stata through the `ssc` argument.\n\n::: {#eb9c06f3 .cell execution_count=15}\n``` {.python .cell-code}\nfit8 = pf.feols(\n  \"Y ~ X1 + X2\",\n  df.dropna(subset=['f1', 'f2']),\n  vcov={\"CRV1\": \"f1 + f2\"},\n  ssc=pf.ssc(G_df=\"conventional\")\n)\nfit8.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: 0\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| Intercept     |      0.890 |        0.302 |     2.949 |      0.006 |  0.273 |   1.506 |\n| X1            |     -0.995 |        0.075 |   -13.310 |      0.000 | -1.148 |  -0.842 |\n| X2            |     -0.177 |        0.024 |    -7.433 |      0.000 | -0.225 |  -0.128 |\n---\nRMSE: 2.091 R2: 0.177 \n```\n:::\n:::\n\n\nAs a reminder, for an excellent breakdown on small sample correction in the `pyfixest` package, you can check out\n[On Small Sample Correction](https://py-econometrics.github.io/pyfixest/explanation/ssc.html).\n\n# Fixed Effect Regressions\n\nTo do a fixed effect regression with one fixed effect you could use\n\n::: {#f230da9f .cell execution_count=16}\n``` {.python .cell-code}\nfit9 = pf.feols(\"Y ~ X1 + X2 | f1\", data=df, vcov=\"iid\")\nfit9.summary()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nOMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.950 |        0.066 |   -14.306 |      0.000 | -1.080 |  -0.819 |\n| X2            |     -0.174 |        0.018 |    -9.902 |      0.000 | -0.209 |  -0.140 |\n---\nRMSE: 1.648 R2: 0.489 R2 Within: 0.239 \n```\n:::\n:::\n\n\nwhich is equivalent to\n\n```stata\nxtset f1\nxtreg Y X1 X2, fe\n\n* Fixed-effects (within) regression               Number of obs     =        997\n* Group variable: f1                              Number of groups  =         30\n*\n* R-squared:                                      Obs per group:\n*      Within  = 0.2388                                         min =         23\n*      Between = 0.0770                                         avg =       33.2\n*      Overall = 0.1774                                         max =         48\n*\n*                                                 F(2, 965)         =     151.33\n* corr(u_i, Xb) = 0.0268                          Prob > F          =     0.0000\n*\n* ------------------------------------------------------------------------------\n*            Y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9495256   .0663728   -14.31   0.000    -1.079777   -.8192739\n*           X2 |  -.1742253   .0175957    -9.90   0.000    -.2087555   -.1396951\n*        _cons |    .842222   .0872525     9.65   0.000     .6709955    1.013448\n* -------------+----------------------------------------------------------------\n*      sigma_u |  1.2570454\n*      sigma_e |  1.6751049\n*          rho |  .36026283   (fraction of variance due to u_i)\n* ------------------------------------------------------------------------------\n* F test that all u_i=0: F(29, 965) = 20.29                    Prob > F = 0.0000\n```\n\nor\n\n```stata\nreghdfe Y X1 X2, absorb(f1)\n\n* HDFE Linear regression                            Number of obs   =        997\n* Absorbing 1 HDFE group                            F(   2,    965) =     151.33\n*                                                   Prob > F        =     0.0000\n*                                                   R-squared       =     0.4890\n*                                                   Adj R-squared   =     0.4726\n*                                                   Within R-sq.    =     0.2388\n*                                                   Root MSE        =     1.6751\n*\n* ------------------------------------------------------------------------------\n*            Y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9495256   .0663728   -14.31   0.000    -1.079777   -.8192739\n*           X2 |  -.1742253   .0175957    -9.90   0.000    -.2087555   -.1396951\n*        _cons |    .842222   .0872525     9.65   0.000     .6709955    1.013448\n* ------------------------------------------------------------------------------\n*\n* Absorbed degrees of freedom:\n* -----------------------------------------------------+\n*  Absorbed FE | Categories  - Redundant  = Num. Coefs |\n* -------------+---------------------------------------|\n*           f1 |        30           0          30     |\n* -----------------------------------------------------+\n```\n\nTo use cluster robust standard errors, specify the `vcov` argument:\n\n::: {#694c8e46 .cell execution_count=17}\n``` {.python .cell-code}\n# Standard iid inference\nfit10 = pf.feols(\"Y ~ X1 + X2 | f1\", data=df)\nfit10.summary()\n\n# Cluster robust standard errors\nfit10_clustered = pf.feols(\"Y ~ X1 + X2 | f1\", data=df, vcov={\"CRV1\": \"f1\"})\nfit10_clustered.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.950 |        0.066 |   -14.306 |      0.000 | -1.080 |  -0.819 |\n| X2            |     -0.174 |        0.018 |    -9.902 |      0.000 | -0.209 |  -0.140 |\n---\nRMSE: 1.648 R2: 0.489 R2 Within: 0.239 \n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.950 |        0.067 |   -14.266 |      0.000 | -1.086 |  -0.813 |\n| X2            |     -0.174 |        0.018 |    -9.464 |      0.000 | -0.212 |  -0.137 |\n---\nRMSE: 1.648 R2: 0.489 R2 Within: 0.239 \n```\n:::\n:::\n\n\nThe clustered version `fit10_clustered` is equivalent to\n\n```stata\nxtset f1\nxtreg Y X1 X2, fe vce(cluster f1)\n\n* Fixed-effects (within) regression               Number of obs     =        997\n* Group variable: f1                              Number of groups  =         30\n*\n* R-squared:                                      Obs per group:\n*      Within  = 0.2388                                         min =         23\n*      Between = 0.0770                                         avg =       33.2\n*      Overall = 0.1774                                         max =         48\n*\n*                                                 F(2, 29)          =     146.33\n* corr(u_i, Xb) = 0.0268                          Prob > F          =     0.0000\n*\n*                                     (Std. err. adjusted for 30 clusters in f1)\n* ------------------------------------------------------------------------------\n*              |               Robust\n*            Y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9495256   .0665572   -14.27   0.000     -1.08565   -.8134009\n*           X2 |  -.1742253    .018409    -9.46   0.000    -.2118759   -.1365746\n*        _cons |    .842222   .0694639    12.12   0.000     .7001523    .9842916\n* -------------+----------------------------------------------------------------\n*      sigma_u |  1.2570454\n*      sigma_e |  1.6751049\n*          rho |  .36026283   (fraction of variance due to u_i)\n* ------------------------------------------------------------------------------\n```\n\nor\n\n```stata\nreghdfe Y X1 X2, absorb(f1) cluster(f1)\n\n* HDFE Linear regression                            Number of obs   =        997\n* Absorbing 1 HDFE group                            F(   2,     29) =     146.33\n* Statistics robust to heteroskedasticity           Prob > F        =     0.0000\n*                                                   R-squared       =     0.4890\n*                                                   Adj R-squared   =     0.4726\n*                                                   Within R-sq.    =     0.2388\n* Number of clusters (f1)      =         30         Root MSE        =     1.6751\n*\n*                                     (Std. err. adjusted for 30 clusters in f1)\n* ------------------------------------------------------------------------------\n*              |               Robust\n*            Y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9495256   .0665572   -14.27   0.000     -1.08565   -.8134009\n*           X2 |  -.1742253    .018409    -9.46   0.000    -.2118759   -.1365746\n*        _cons |    .842222   .0694639    12.12   0.000     .7001523    .9842916\n* ------------------------------------------------------------------------------\n*\n* Absorbed degrees of freedom:\n* -----------------------------------------------------+\n*  Absorbed FE | Categories  - Redundant  = Num. Coefs |\n* -------------+---------------------------------------|\n*           f1 |        30          30           0    *|\n* -----------------------------------------------------+\n* * = FE nested within cluster; treated as redundant for DoF computation\n```\n\nFor multiple fixed effects you could do\n\n::: {#543c79f1 .cell execution_count=18}\n``` {.python .cell-code}\nfit11 = pf.feols(\"Y ~ X1 + X2 | f1 + f2\", data=df)\nfit11.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5% |   97.5% |\n|:--------------|-----------:|-------------:|----------:|-----------:|-------:|--------:|\n| X1            |     -0.924 |        0.056 |   -16.483 |      0.000 | -1.034 |  -0.814 |\n| X2            |     -0.174 |        0.015 |   -11.717 |      0.000 | -0.203 |  -0.145 |\n---\nRMSE: 1.346 R2: 0.659 R2 Within: 0.303 \n```\n:::\n:::\n\n\nwhich is equivalent to\n\n```stata\nreghdfe Y X1 X2, absorb(f1 f2) cluster(f1)\n\n* HDFE Linear regression                            Number of obs   =        997\n* Absorbing 2 HDFE groups                           F(   2,     29) =     182.76\n* Statistics robust to heteroskedasticity           Prob > F        =     0.0000\n*                                                   R-squared       =     0.6590\n*                                                   Adj R-squared   =     0.6372\n*                                                   Within R-sq.    =     0.3026\n* Number of clusters (f1)      =         30         Root MSE        =     1.3893\n*\n*                                     (Std. err. adjusted for 30 clusters in f1)\n* ------------------------------------------------------------------------------\n*              |               Robust\n*            Y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n* -------------+----------------------------------------------------------------\n*           X1 |  -.9240462   .0618743   -14.93   0.000    -1.050593   -.7974991\n*           X2 |  -.1741073   .0148338   -11.74   0.000    -.2044458   -.1437689\n*        _cons |   .8156588    .064596    12.63   0.000     .6835452    .9477723\n* ------------------------------------------------------------------------------\n*\n* Absorbed degrees of freedom:\n* -----------------------------------------------------+\n*  Absorbed FE | Categories  - Redundant  = Num. Coefs |\n* -------------+---------------------------------------|\n*           f1 |        30          30           0    *|\n*           f2 |        30           1          29     |\n* -----------------------------------------------------+\n* * = FE nested within cluster; treated as redundant for DoF computation\n```\n\nNote: To cluster standard errors by a specific group, use the `vcov` argument.\nSee the `fit8` example above for how to specify two way clustering.\n\n",
    "supporting": [
      "stata-2-pyfixest_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}