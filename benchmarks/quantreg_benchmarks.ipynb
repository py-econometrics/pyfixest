{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2853b2cf",
   "metadata": {},
   "source": [
    "# Quantile Regression Benchmarks\n",
    "\n",
    "We benchmark multiple implementations for the quantile regression process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f266b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyfixest as pf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def generate_data(N: int, k: int) -> pd.DataFrame:\n",
    "    \"\"\"Simulate t-distributed noise linear model.\"\"\"\n",
    "    X = np.random.randn(N, k)\n",
    "    beta = np.random.randn(k)\n",
    "    y = X @ beta + np.random.normal(0, 1, N)\n",
    "    data = pd.DataFrame(X, columns=[f\"X{i + 1}\" for i in range(k)])\n",
    "    data[\"Y\"] = y\n",
    "    data[\"id\"] = np.arange(N)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20d2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_benchmarks(df):\n",
    "    \"\"\"\n",
    "    Visualize benchmark timings by N, with separate panels for each k,\n",
    "    arranged horizontally. All estimates are averages of three iterations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Must contain columns: 'N', 'k', 'method', 'seconds'\n",
    "    \"\"\"\n",
    "    unique_ks = sorted(df[\"k\"].unique())\n",
    "    num_panels = len(unique_ks)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_panels, figsize=(5 * num_panels, 5), sharey=True)\n",
    "\n",
    "    if num_panels == 1:\n",
    "        axes = [axes]  # ensure iterable\n",
    "\n",
    "    for ax, k_val in zip(axes, unique_ks):\n",
    "        subset = df[df[\"k\"] == k_val]\n",
    "        for method, group in subset.groupby(\"method\"):\n",
    "            grp = group.sort_values(\"N\")\n",
    "            ax.plot(grp[\"N\"], grp[\"seconds\"], marker=\"o\", label=method, linewidth=2)\n",
    "        ax.set_title(f\"k = {k_val}\", fontsize=13, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Sample Size (N)\", fontsize=11)\n",
    "        ax.set_xlim(df[\"N\"].min(), df[\"N\"].max())\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    axes[0].set_ylabel(\"Avg. Time (seconds)\", fontsize=11)\n",
    "\n",
    "    # Add legend outside the last plot\n",
    "    axes[-1].legend(title=\"Method\", loc=\"upper left\", bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"Benchmark Timing of the Quantile Regression Process with 10 Quantiles by N and k (Average of 3 Runs)\",\n",
    "        fontsize=15,\n",
    "        fontweight=\"semibold\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.92, 0.95])  # leave space for title + legend\n",
    "    plt.show()\n",
    "    plt.savefig(\"quantreg_benchmarks.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7b40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quant_benchmark(\n",
    "    Ns,\n",
    "    ks,\n",
    "    quantile_sets,\n",
    "    vcov=\"iid\",\n",
    "    method=\"cfm1_fn\",\n",
    "    seed=231,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run timing benchmarks for different quantreg methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Ns : iterable of int\n",
    "    ks : iterable of int\n",
    "    quantile_sets : dict[str, list[float]]\n",
    "    vcov : str\n",
    "    method : str\n",
    "        One of \"loop_pfn\", \"loop_fn\", \"sm_loop\",\n",
    "        \"cfm1_pfn\", \"cfm2_pfn\", \"cfm1_fn\", \"cfm2_fn\".\n",
    "    reps_small : int\n",
    "    reps_large : int\n",
    "    seed : int\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for N, k, Q in tqdm(itertools.product(Ns, ks, quantile_sets.keys())):\n",
    "        # reps = reps_small if N < 100_000 else reps_large\n",
    "        reps = 3\n",
    "        data = generate_data(N, k)\n",
    "        fml = \"Y ~ \" + \" + \".join(f\"X{i + 1}\" for i in range(k))\n",
    "        quantiles = quantile_sets[Q]\n",
    "\n",
    "        def _timeit(fn, reps_local=reps):\n",
    "            t0 = time.time()\n",
    "            for _ in range(reps_local):\n",
    "                fn()\n",
    "            return (time.time() - t0) / reps_local\n",
    "\n",
    "        if method == \"loop_pfn\":\n",
    "            secs = _timeit(\n",
    "                lambda fml=fml, data=data, vcov=vcov, quantiles=quantiles: [\n",
    "                    pf.quantreg(fml, data=data, quantile=q, method=\"pfn\", vcov=vcov)\n",
    "                    for q in quantiles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif method == \"loop_fn\":\n",
    "            secs = _timeit(\n",
    "                lambda fml=fml, data=data, vcov=vcov, quantiles=quantiles: [\n",
    "                    pf.quantreg(fml, data=data, quantile=q, method=\"fn\", vcov=vcov)\n",
    "                    for q in quantiles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif method == \"sm_loop\":\n",
    "            secs = _timeit(\n",
    "                lambda fml=fml, data=data, quantiles=quantiles: [\n",
    "                    smf.quantreg(fml, data=data).fit(q=q) for q in quantiles\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif method in (\"cfm1_pfn\", \"cfm2_pfn\", \"cfm1_fn\", \"cfm2_fn\"):\n",
    "            multi_method, base_method = method.split(\"_\")\n",
    "            # multi_method is \"cfm1\" or \"cfm2\"\n",
    "            # base_method is \"pfn\" or \"fn\"\n",
    "            secs = _timeit(\n",
    "                lambda fml=fml,\n",
    "                base_method=base_method,\n",
    "                multi_method=multi_method,\n",
    "                seed=seed,\n",
    "                quantiles=quantiles,\n",
    "                data=data,\n",
    "                vcov=vcov: pf.quantreg(\n",
    "                    fml=fml,\n",
    "                    method=base_method,\n",
    "                    multi_method=multi_method,\n",
    "                    seed=seed,\n",
    "                    quantile=quantiles,\n",
    "                    data=data,\n",
    "                    vcov=vcov,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method!r}\")\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"N\": N,\n",
    "                \"k\": k,\n",
    "                \"Q\": Q,\n",
    "                \"method\": method,\n",
    "                \"seconds\": secs,\n",
    "                \"reps\": reps,\n",
    "                \"n_quantiles\": len(quantiles),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    records = pd.DataFrame(records)\n",
    "    records.to_csv(\n",
    "        f\"data/quantreg/quant_benchmark_{method}_{N}_{k}_{len(quantiles)}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1225f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(991)\n",
    "\n",
    "Ns = [1_000_000]\n",
    "ks = [5, 20, 50]\n",
    "\n",
    "quantile_sets = {\n",
    "    10: np.linspace(0.05, 0.95, 10).tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b12406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark for method: cfm2_fn\n",
      "Running for N=1000000, k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:05, 65.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for N=1000000, k=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:41, 101.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for N=1000000, k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [05:23, 323.21s/it]\n",
      " 50%|█████     | 1/2 [08:10<08:10, 490.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running benchmark for method: cfm2_pfn\n",
      "Running for N=1000000, k=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:42, 102.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for N=1000000, k=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:17, 137.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for N=1000000, k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for method in tqdm(\n",
    "    [\n",
    "        # \"cfm1_fn\",\n",
    "        \"cfm2_fn\",\n",
    "        # \"loop_pfn\", \"loop_fn\",\n",
    "        # \"sm_loop\",\n",
    "        # \"cfm1_pfn\",\n",
    "        \"cfm2_pfn\",\n",
    "    ]\n",
    "):\n",
    "    print(f\"Running benchmark for method: {method}\")\n",
    "    for N in Ns:\n",
    "        for k in ks:\n",
    "            print(f\"Running for N={N}, k={k}\")\n",
    "            run_quant_benchmark(\n",
    "                Ns=[N],\n",
    "                ks=[k],\n",
    "                quantile_sets=quantile_sets,\n",
    "                vcov=\"iid\",\n",
    "                method=method,\n",
    "                seed=1231231,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c1b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_benchmarks = pd.concat(\n",
    "    [pd.read_csv(f) for f in glob.glob(\"data/quantreg/*.csv\")], ignore_index=True\n",
    ").sort_values([\"N\", \"k\", \"Q\", \"method\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542725b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_benchmarks(all_benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d650dc7a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
