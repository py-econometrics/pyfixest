[
  {
    "objectID": "benchmarks/readme.html",
    "href": "benchmarks/readme.html",
    "title": "",
    "section": "",
    "text": "All benchmarks follow fixest’s benchmarks, which you can find here. PyFixest benchmarks were run on a Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz, 2304Mhz, 4 Core(s), 8 Logical Processor(s). Timings for R, Stata and Julia programs are taken from the fixest’s benchmarks.\nTo run the python benchmarks, you need to install the following packages: - pyfixest - pandas - numpy - tqdm First, you need to create the data by running the data_generation.R files. This will populate the _STATA and data folders. Then, you can run the run_benchmarks.ipynb notebook to run the benchmarks. This will populate the results_py.csv file. Finally, you can run the plot_benchmarks.ipynb notebook to generate the plots."
  },
  {
    "objectID": "benchmarks/run_benchmarks.html",
    "href": "benchmarks/run_benchmarks.html",
    "title": "",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\nimport time\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.estimation import feols, fepois\nfrom tqdm import tqdm  # note: tqdm is not a dependency of pyfixest\n\n\ndef run_standard_benchmark(model, fixed_effect):\n    \"\"\"\n    Runs the fixest standard benchmark.\n    Args:\n        model (str): \"feols\" or \"fepois\"\n        fixed_effect (str): \"dum_1\" or \"dum_1+dum_2\" or \"dum_1+dum_2+dum_3\"\n    Returns:\n        A pd.DataFrame with the results.\n    \"\"\"\n\n    assert model in [\"feols\", \"fepois\"]\n    assert fixed_effect in [\"dum_1\", \"dum_1+dum_2\", \"dum_1+dum_2+dum_3\"]\n\n    # one fixed effect\n    res = []\n\n    if model == \"feols\":\n        fml_base = \"ln_y ~ X1\"\n        model2 = \"Gaussian\"\n    else:\n        fml_base = \"y ~ X1\"\n        model2 = \"Poisson\"\n\n    fml = f\"{fml_base} | {fixed_effect}\"\n\n    # warmup\n    df = pd.read_stata(f\"./data/_STATA/base_s2_r1.dta\")\n    feols(fml, data=df)\n\n    for size in tqdm(range(1, 6)):\n        if size == 5:\n            if model == \"fepois\":\n                pass\n            else:\n                df = pd.read_csv(\"./data/data/base_10M.csv\")\n\n        for rep in range(1, 11):\n            if size < 5:\n                df = pd.read_stata(f\"./data/_STATA/base_s{size}_r{rep}.dta\")\n\n            tic = time.time()\n            if model == \"feols\":\n                feols(fml, data=df)\n            else:\n                fepois(fml, data=df)\n            toc = time.time()\n\n            res.append(\n                pd.Series(\n                    {\n                        \"method\": model,\n                        \"n_obs\": df.shape[0],\n                        \"G\": len(fixed_effect.split(\"+\")),\n                        \"rep\": rep,\n                        \"time\": toc - tic,\n                    }\n                )\n            )\n\n    return pd.concat(res, axis=1).T\n\n\ndef run_all_benchmarks():\n    \"\"\"\n    Run all the benchmarks.\n    \"\"\"\n\n    res = pd.DataFrame()\n    for model in [\"feols\", \"fepois\"]:\n        for fixef in [\"dum_1\", \"dum_1+dum_2\", \"dum_1+dum_2+dum_3\"]:\n            res = pd.concat([res, run_standard_benchmark(model, fixef)], axis=1)\n\n    res.to_csv(\"./results_py.csv\")\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\nrun_all_benchmarks()\n\n100%|██████████| 3/3 [00:00<00:00,  3.54it/s]\n100%|██████████| 3/3 [00:00<00:00,  3.33it/s]\n\n\n\na = run_standard_benchmark(\"feols\", \"dum_1\")\na\n\n100%|██████████| 3/3 [00:00<00:00,  3.61it/s]\n\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n    \n  \n  \n    \n      0\n      feols\n      1000\n      1\n      1\n      0.011204\n    \n    \n      1\n      feols\n      1000\n      1\n      2\n      0.009486\n    \n    \n      2\n      feols\n      1000\n      1\n      3\n      0.010987\n    \n    \n      3\n      feols\n      1000\n      1\n      4\n      0.010687\n    \n    \n      4\n      feols\n      1000\n      1\n      5\n      0.011018\n    \n    \n      5\n      feols\n      1000\n      1\n      6\n      0.009798\n    \n    \n      6\n      feols\n      1000\n      1\n      7\n      0.008976\n    \n    \n      7\n      feols\n      1000\n      1\n      8\n      0.008977\n    \n    \n      8\n      feols\n      1000\n      1\n      9\n      0.008486\n    \n    \n      9\n      feols\n      1000\n      1\n      10\n      0.007978\n    \n    \n      10\n      feols\n      10000\n      1\n      1\n      0.01097\n    \n    \n      11\n      feols\n      10000\n      1\n      2\n      0.012004\n    \n    \n      12\n      feols\n      10000\n      1\n      3\n      0.013207\n    \n    \n      13\n      feols\n      10000\n      1\n      4\n      0.011819\n    \n    \n      14\n      feols\n      10000\n      1\n      5\n      0.010875\n    \n    \n      15\n      feols\n      10000\n      1\n      6\n      0.011104\n    \n    \n      16\n      feols\n      10000\n      1\n      7\n      0.009973\n    \n    \n      17\n      feols\n      10000\n      1\n      8\n      0.009973\n    \n    \n      18\n      feols\n      10000\n      1\n      9\n      0.01097\n    \n    \n      19\n      feols\n      10000\n      1\n      10\n      0.009974\n    \n    \n      20\n      feols\n      100000\n      1\n      1\n      0.042234\n    \n    \n      21\n      feols\n      100000\n      1\n      2\n      0.04016\n    \n    \n      22\n      feols\n      100000\n      1\n      3\n      0.043736\n    \n    \n      23\n      feols\n      100000\n      1\n      4\n      0.049093\n    \n    \n      24\n      feols\n      100000\n      1\n      5\n      0.052659\n    \n    \n      25\n      feols\n      100000\n      1\n      6\n      0.048541\n    \n    \n      26\n      feols\n      100000\n      1\n      7\n      0.051272\n    \n    \n      27\n      feols\n      100000\n      1\n      8\n      0.044816\n    \n    \n      28\n      feols\n      100000\n      1\n      9\n      0.041823\n    \n    \n      29\n      feols\n      100000\n      1\n      10\n      0.044947\n    \n  \n\n\n\n\n\na.T\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n      method\n      n_obs\n      G\n      rep\n      time\n      ...\n      method\n      n_obs\n      G\n      rep\n      time\n      method\n      n_obs\n      G\n      rep\n      time\n    \n  \n  \n    \n      0\n      feols\n      1000\n      1\n      1\n      0.009973\n      feols\n      1000\n      1\n      2\n      0.01043\n      ...\n      feols\n      10000000\n      2\n      9\n      10.188134\n      feols\n      10000000\n      2\n      10\n      10.136924\n    \n  \n\n1 rows × 500 columns\n\n\n\n\n\n\nres_all = pd.concat(\n    [\n        pd.read_csv(\"./benchmarks/results_py.csv\"),\n        pd.read_csv(\"./benchmarks/results_all.txt\"),\n    ]\n)\n\n\nres_all\n\n\n\n\n\n  \n    \n      \n      method\n      n_obs\n      G\n      rep\n      time\n      model\n    \n  \n  \n    \n      0\n      fepois\n      1000.0\n      1\n      1\n      0.060000\n      Poisson\n    \n    \n      1\n      glmmboot\n      1000.0\n      1\n      1\n      0.020000\n      Poisson\n    \n    \n      2\n      feglm (alpaca)\n      1000.0\n      1\n      1\n      0.020000\n      Poisson\n    \n    \n      3\n      fepois\n      1000.0\n      1\n      2\n      0.030000\n      Poisson\n    \n    \n      4\n      glmmboot\n      1000.0\n      1\n      2\n      0.010000\n      Poisson\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1575\n      FixedEffectModels\n      10000000.0\n      3\n      6\n      6.800669\n      Gaussian\n    \n    \n      1576\n      FixedEffectModels\n      10000000.0\n      3\n      7\n      6.756505\n      Gaussian\n    \n    \n      1577\n      FixedEffectModels\n      10000000.0\n      3\n      8\n      6.802480\n      Gaussian\n    \n    \n      1578\n      FixedEffectModels\n      10000000.0\n      3\n      9\n      6.761793\n      Gaussian\n    \n    \n      1579\n      FixedEffectModels\n      10000000.0\n      3\n      10\n      6.759143\n      Gaussian\n    \n  \n\n1580 rows × 6 columns"
  },
  {
    "objectID": "benchmarks/visualise_benchmarks.html",
    "href": "benchmarks/visualise_benchmarks.html",
    "title": "",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom lets_plot import *\n\nLetsPlot.setup_html(no_js=True)\n\n\nres_py = pd.read_csv(\"./results_py.csv\")\nres_py[\"model\"] = np.where(res_py[\"method\"] == \"feols\", \"Gaussian\", \"Poisson\")\nres_py[\"method\"] = \"pyfixest\"\nres_other = pd.read_csv(\"./results_all.txt\")\nres_all = pd.concat([res_py, res_other], axis=0)\n\n\nres_all.method.unique()\n\narray(['pyfixest', 'fepois', 'glmmboot', 'feglm (alpaca)', 'ppmlhdfe',\n       'fenegbin', 'glmnb', 'nbreg', 'feglm (fixest)', 'logit', 'feols',\n       'lfe', 'reghdfe', 'FixedEffectModels'], dtype=object)\n\n\n\nres_agg = (\n    res_all.groupby([\"method\", \"n_obs\", \"G\", \"model\"]).mean()[\"time\"].reset_index()\n)\nres_agg[\"G\"] = res_agg[\"G\"].apply(lambda x: f\"{x} FE\")\nres_agg[\"method\"] = pd.Categorical(\n    res_agg[\"method\"],\n    [\n        \"pyfixest\",\n        \"feols\",\n        \"reghdfe\",\n        \"lfe\",\n        \"FixedEffectModels\",\n        \"fepois\",\n        \"glmmboot\",\n        \"ppmlhdfe\",\n        \"feglm (alpaca)\",\n    ],\n)\n\n\nplot_ols = (\n    ggplot(\n        res_agg[res_agg[\"model\"] == \"Gaussian\"],\n        aes(x=\"n_obs\", y=\"time\", color=\"method\"),\n    )\n    + geom_line()\n    + geom_point()\n    + facet_wrap(\"G\", nrow=1)\n    + scale_x_discrete()\n    + scale_y_continuous(trans=\"log10\", limits=(0, 120))\n    + ylab(\"Time in Seconds\")\n    + xlab(\"Number of Observations\")\n    + ggtitle(\"Fixest Standard Benchmark for OLS\")\n    + ggsize(1000, 500)\n)\nggsave(plot_ols, filename=\"benchmarks_ols.svg\")\n\n\nplot_ols\n\n\n  \n  \n    \n    \n    \n      \n        \n        1 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n            \n            0.01\n            \n          \n        \n        \n          \n            \n            0.03\n            \n          \n        \n        \n          \n            \n            0.10\n            \n          \n        \n        \n          \n            \n            0.3\n            \n          \n        \n        \n          \n            \n            1.0\n            \n          \n        \n        \n          \n            \n            3\n            \n          \n        \n        \n          \n            \n            10\n            \n          \n        \n        \n          \n            \n            32\n            \n          \n        \n        \n          \n            \n            100\n            \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        2 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        3 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1.0E7\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n      Fixest Standard Benchmark for OLS\n      \n    \n    \n      \n      Time in Seconds\n      \n    \n    \n      \n      Number of Observations\n      \n    \n    \n      \n      \n      \n        \n          \n          method\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              FixedEffectModels\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              feols\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              lfe\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              pyfixest\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              reghdfe\n              \n            \n          \n        \n      \n    \n    \n    \n  \n  \n  \n\n\n\n\nplot_poisson = (\n    ggplot(\n        res_agg[(res_agg[\"model\"] == \"Poisson\") & (res_agg.n_obs < 1e07)],\n        aes(x=\"n_obs\", y=\"time\", color=\"method\"),\n    )\n    + geom_line()\n    + geom_point()\n    + facet_wrap(\"G\", nrow=1)\n    + scale_x_discrete()\n    + scale_y_continuous(trans=\"log10\", limits=(0, 120))\n    + ylab(\"Time in Seconds\")\n    + xlab(\"Number of Observations\")\n    + ggtitle(\"Fixest Standard Benchmark for Poisson Regression\")\n    + ggsize(1000, 500)\n)\n\nggsave(plot_poisson, filename=\"benchmarks_poisson.svg\")\n\nplot_poisson\n\n\n  \n  \n    \n    \n    \n      \n        \n        1 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n            \n            0.03\n            \n          \n        \n        \n          \n            \n            0.10\n            \n          \n        \n        \n          \n            \n            0.3\n            \n          \n        \n        \n          \n            \n            1.0\n            \n          \n        \n        \n          \n            \n            3\n            \n          \n        \n        \n          \n            \n            10\n            \n          \n        \n        \n          \n            \n            32\n            \n          \n        \n        \n          \n            \n            100\n            \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        2 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n        \n        3 FE\n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n          \n          \n          \n            \n            1000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            10000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            100000.0\n            \n          \n        \n        \n          \n          \n          \n            \n            1000000.0\n            \n          \n        \n        \n        \n      \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n        \n          \n          \n        \n      \n      \n        \n          \n            \n            \n          \n        \n        \n          \n          \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n          \n        \n      \n    \n    \n      \n      Fixest Standard Benchmark for Poisson Regression\n      \n    \n    \n      \n      Time in Seconds\n      \n    \n    \n      \n      Number of Observations\n      \n    \n    \n      \n      \n      \n        \n          \n          method\n          \n        \n        \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              feglm (alpaca)\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              fepois\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              glmmboot\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              ppmlhdfe\n              \n            \n          \n          \n            \n              \n              \n              \n                \n                  \n                  \n                \n                \n                  \n                  \n                    \n                  \n                \n              \n              \n              \n            \n            \n              \n              pyfixest"
  },
  {
    "objectID": "docs/difference-in-differences-estimation.html",
    "href": "docs/difference-in-differences-estimation.html",
    "title": "",
    "section": "",
    "text": "PyFixest supports eventy study designs via - the canonical two-way fixed effects design - Gardner’s 2-stage estimator - and the local projections approach following Dube et al (2023)\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.estimation import feols\nfrom pyfixest.did.did2s import did2s\nfrom pyfixest.did.lpdid import lpdid\n\nurl = \"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\ndf_het.head()\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\n\n\n  \n    \n      \n      unit\n      state\n      group\n      unit_fe\n      g\n      year\n      year_fe\n      treat\n      rel_year\n      rel_year_binned\n      error\n      te\n      te_dynamic\n      dep_var\n    \n  \n  \n    \n      0\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1990\n      0.066159\n      False\n      -20.0\n      -6\n      -0.086466\n      0\n      0.0\n      7.022709\n    \n    \n      1\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1991\n      -0.030980\n      False\n      -19.0\n      -6\n      0.766593\n      0\n      0.0\n      7.778628\n    \n    \n      2\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1992\n      -0.119607\n      False\n      -18.0\n      -6\n      1.512968\n      0\n      0.0\n      8.436377\n    \n    \n      3\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1993\n      0.126321\n      False\n      -17.0\n      -6\n      0.021870\n      0\n      0.0\n      7.191207\n    \n    \n      4\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1994\n      -0.106921\n      False\n      -16.0\n      -6\n      -0.017603\n      0\n      0.0\n      6.918492\n    \n  \n\n\n\n\n\n\nWe can estimate a simple two-way fixed effects DiD regression via feols():\n\nfit_twfe = feols(\n    \"dep_var ~ i(rel_year) | state + year\",\n    df_het,\n    i_ref1=[-1.0, np.inf],\n    vcov={\"CRV1\": \"state\"},\n)\n\nTo do the same via Gardners 2-stage estimator, we employ the the did2s() function:\n\nfrom pyfixest.did.did2s import did2s\n\nfit_did2s = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n    i_ref1=[-1.0, np.inf],\n)\n\nLast, we can estimate the ATT for each time period via local projections by using the lpdid() function:\n\nfrom pyfixest.did.lpdid import lpdid\n\nfit_lpdid = lpdid(\n    data=df_het,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=False,\n)\n\nLet’s look at some results:\n\nfigsize = [1200, 400]\n\n\nfit_twfe.iplot(\n    coord_flip=False,\n    title=\"TWFE-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n)\n\n   \n   \n\n\n\nfit_did2s.iplot(\n    coord_flip=False,\n    title=\"DID2s-Estimator\",\n    figsize=figsize,\n    xintercept=18.5,\n    yintercept=0,\n)\n\n   \n   \n\n\n\nfit_lpdid.iplot(\n    coord_flip=False,\n    title=\"Local-Projections-Estimator\",\n    figsize=figsize,\n    yintercept=0,\n    xintercept=18.5,\n)\n\n   \n   \n\n\nWhat if we are not interested in the ATT per treatment period, but in a pooled effects?\n\nfit_twfe = feols(\n    \"dep_var ~ i(treat) | unit + year\",\n    df_het,\n    vcov={\"CRV1\": \"state\"},\n)\n\nfit_did2s = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | unit + year\",\n    second_stage=\"~i(treat)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n)\n\nfit_lpdid = lpdid(\n    data=df_het,\n    yname=\"dep_var\",\n    gname=\"g\",\n    tname=\"year\",\n    idname=\"unit\",\n    vcov={\"CRV1\": \"state\"},\n    pre_window=-20,\n    post_window=20,\n    att=True,\n)\n\n\nfit_twfe.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(treat)[T.True]\n      1.98254\n      0.019331\n      102.55618\n      0.0\n      1.943439\n      2.021642\n    \n  \n\n\n\n\n\nfit_did2s.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(treat)[T.True]\n      2.230482\n      0.024709\n      90.271437\n      0.0\n      2.182052\n      2.278911\n    \n  \n\n\n\n\n\nfit_lpdid.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n      N\n    \n  \n  \n    \n      treat_diff\n      2.506746\n      0.071357\n      35.129648\n      0.0\n      2.362413\n      2.65108\n      5716.0"
  },
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "",
    "section": "",
    "text": "PyFixest is a Python clone of the excellent fixest package. The package aims to mimic fixest syntax and functionality as closely as Python allows. For a quick introduction, see the tutorial or take a look at the regression chapter of Arthur Turrell’s book on Coding for Economists.\n\n%load_ext autoreload\n%autoreload 2\n\nfrom pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\n\ndata = get_data()\n\n# fit a model via OLS\nfit = feols(\"Y ~ X1 | f1 + f2\", data=data)\nfit.summary()\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.919 |        0.065 |   -14.057 |      0.000 |  -1.053 |   -0.786 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\n\n\n\nAt the moment, PyFixest supports\n\nOLS and IV Regression\nPoisson Regression\nMultiple Estimation Syntax\nSeveral Robust and Cluster Robust Variance-Covariance Types\nWild Cluster Bootstrap Inference (via wildboottest)\nDifference-in-Difference Estimators:\n\nThe canonical Two-Way Fixed Effects Estimator\nGardner’s two-stage (“Did2s”) estimator\nBasic Versions of the Local Projections estimator following Dube et al (2023)\n\n\n\n\n\nYou can install the release version from PyPi by running\npip install pyfixest\nor the development version from github by running\npip install git+https://github.com/s3alfisc/pyfixest.git\n\n\n\nAll benchmarks follow the fixest benchmarks. All non-pyfixest timings are taken from the fixest benchmarks."
  },
  {
    "objectID": "docs/news.html",
    "href": "docs/news.html",
    "title": "",
    "section": "",
    "text": "Introduces a new pyfixest.did module which contains routines for Difference-in-Differences estimation.\nIntroduces support for basic versions of the local projections DiD estimator following Dube et al (2023)\nAdds a new vignette for Difference-in-Differences estimation.\nReports R2 values in etable().\n\n\n\n\n\n\n\n\nGood performance improvements for singleton fixed effects detection. Thanks to @styfenschaer for the PR! See #229.\nUses the r2u project for installing R and R packages on github actions, with great performance improvements.\nAllows to pass polars data frames to feols(), fepois() and predict(). #232. Thanks to @vincentarelbundock for the suggestion!\n\n\n\n\n\nMissing variables in features were not always handled correctly in predict() with newdata not None in the presence of missing data, which would lead to an error. See #246 for details.\nCategorical variables were not always handled correctly in predict() with newdata not None, because the number of fixed effects levels in newdata might be smaller than in data. In consequence, some levels were not found, which lead to an error. See #245 for details. Thanks to @jiafengkevinchen for the pointer!\nMulticollinearity checks for over-identified IV was not implemented correctly, which lead to a dimension error. See #236 for details. Thanks to @jiafengkevinchen for the pointer!\nThe number of degrees of freedom k was computed incorrectly if columns were dropped from the design matrix X in the presence of multicollinearity. See #235 for details. Thanks to @jiafengkevinchen for the pointer!\nIf all variables were dropped due to multicollinearity, an unclear and imprecise error message was produced. See #228 for details. Thanks to @manferdinig for the pointer!\nIf selection fixef_rm = 'singleton', feols() and fepois() would fail, which has been fixed. #192\n\n\n\n\n\nFor now, sets formulaic versions to be 0.6.6 or lower as version 1.0.0 seems to have introduced a problem with the i() operator, See #244 for details.\nDrops dependency on pyhdfe.\n\n\n\n\n\n\nFixes some bugs around the computation of R-squared values (see issue #103).\nReports R-squared values again when calling .summary().\n\n\n\n\n\nSignificant speedups for CRV1 inference.\n\n\n\n\nFixes a small bug with the separation check for poisson regression #138.\n\n\n\nFixes bugs with i(var1, var2) syntax introduced with PyFixest 0.10.10.\n\n\n\nFixes a bug with variable interactions via i(var) syntax. See issue #221.\n\n\n\nMakes etable() prettier and more informative.\n\n\n\n\n\nReference levels for the i() formula syntax can no longer be set within the formula, but need to be added via the i_ref1 function argument to either feols() and fepois().\n\n\n\nA dids2() function is added, which implements the 2-stage difference-in-differences procedure à la Gardner and follows the syntax of @kylebutts did2s R package.\nfrom pyfixest.did.did import did2s\nfrom pyfixest.estimation import feols\nfrom pyfixest.visualize import iplot\nimport pandas as pd\nimport numpy as np\n\ndf_het = pd.read_csv(\"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\")\n\nfit = did2s(\n    df_het,\n    yname = \"dep_var\",\n    first_stage = \"~ 0 | state + year\",\n    second_stage = \"~i(rel_year)\",\n    treatment = \"treat\",\n    cluster = \"state\",\n    i_ref1 = [-1.0, np.inf],\n)\n\nfit_twfe = feols(\n    \"dep_var ~ i(rel_year) | state + year\",\n    df_het,\n    i_ref1 = [-1.0, np.inf]\n)\n\niplot([fit, fit_twfe], coord_flip=False, figsize = (900, 400), title = \"TWFE vs DID2S\")\n\n\n\n\n\n\nAdds basic support for event study estimation via two-way fixed effects and Gardner’s two-stage “Did2s” approach. This is a beta version and experimental. Further updates (i.e. proper event studies vs “only” ATTs) and a more flexible did2s front end will follow in future releases.\n\n%load_ext autoreload\n%autoreload 2\n\nfrom pyfixest.did.did import event_study\nfrom pyfixest.summarize import etable\nimport pandas as pd\ndf_het = pd.read_csv(\"pyfixest/did/data/df_het.csv\")\n\nfit_twfe = event_study(\n    data = df_het,\n    yname = \"dep_var\",\n    idname= \"state\",\n    tname = \"year\",\n    gname = \"g\",\n    estimator = \"twfe\"\n)\n\nfit_did2s = event_study(\n    data = df_het,\n    yname = \"dep_var\",\n    idname= \"state\",\n    tname = \"year\",\n    gname = \"g\",\n    estimator = \"did2s\"\n)\n\netable([fit_twfe, fit_did2s])\n# | Coefficient   | est1             | est2             |\n# |:--------------|:-----------------|:-----------------|\n# | ATT           | 2.135*** (0.044) | 2.152*** (0.048) |\n# Significance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\nAdds an etable() function that outputs markdown, latex or a pd.DataFrame.\n\n\n\n\n\nFixes a big in IV estimation that would trigger an error. See here for details. Thanks to @aeturrell for reporting!\n\n\n\n\n\nImplements a custom function to drop singleton fixed effects.\nAdditional small performance improvements.\n\n\n\n\n\nAllows for white space in the multiway clustering formula.\nAdds documentation for multiway clustering.\n\n\n\n\n\nAdds support for two-way clustering.\nAdds support for CRV3 inference for Poisson regression.\n\n\n\n\n\nAdapts the internal fixed effects demeaning criteron to match `PyHDFE’s default.\nAdds Styfen as coauthor.\n\n\n\n\n\nMultiple performance improvements.\nMost importantly, implements a custom demeaning algorithm in numba - thanks to Styfen Schaer (@styfenschaer), which leads to performance improvements of 5x or more:\n\n%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport time\nimport pyhdfe\nfrom pyfixest.demean import demean\n\nnp.random.seed(1238)\nN = 10_000_000\nx = np.random.normal(0, 1, 10*N).reshape((N,10))\nf1 = np.random.choice(list(range(1000)), N).reshape((N,1))\nf2 = np.random.choice(list(range(1000)), N).reshape((N,1))\n\nflist = np.concatenate((f1, f2), axis = 1)\nweights = np.ones(N)\n\nalgorithm = pyhdfe.create(flist)\n\nstart_time = time.time()\nres_pyhdfe = algorithm.residualize(x)\nend_time = time.time()\nprint(end_time - start_time)\n# 26.04527711868286\n\n\nstart_time = time.time()\nres_pyfixest, success = demean(x, flist, weights, tol = 1e-10)\n# Calculate the execution time\nend_time = time.time()\nprint(end_time - start_time)\n#4.334428071975708\n\nnp.allclose(res_pyhdfe , res_pyfixest)\n# True\n\n\n\n\nBump required formulaic version to 0.6.5.\nStop copying the data frame in fixef().\n\n\n\n\n\nFixes a big in the wildboottest method (see #158).\nAllows to run a wild bootstrap after fixed effect estimation.\n\n\n\n\n\nAdds support for wildboottest for Python 3.11.\n\n\n\n\n\nFixes a couple more bugs in the predict() and fixef() methods.\nThe predict() argument data is renamed to newdata.\n\n\n\n\nFixes a bug in predict() produced when multicollinear variables are dropped.\n\n\n\nImproved Collinearity handling. See #145\n\n\n\n\nMoves plotting from matplotlib to lets-plot.\nFixes a few minor bugs in plotting and the fixef() method.\n\n\n\n\n\n\nIt is no longer required to initiate an object of type Fixest prior to running feols or fepois. Instead, you can now simply use feols() and fepois() as functions, just as in fixest. Both function can be found in an estimation module and need to obtain a pd.DataFrame as a function argument:\nfrom pyfixest.estimation import fixest, fepois\nfrom pyfixest.utils import get_data\n\ndata = get_data()\nfit = feols(\"Y ~ X1 | f1\", data = data, vcov = \"iid\")\nCalling feols() will return an instance of class Feols, while calling fepois() will return an instance of class Fepois. Multiple estimation syntax will return an instance of class FixestMulti.\nPost processing works as before via .summary(), .tidy() and other methods.\n\n\n\nA summary function allows to compare multiple models:\nfrom pyfixest.summarize import summary\nfit2 = feols(\"Y ~ X1 + X2| f1\", data = data, vcov = \"iid\")\nsummary([fit, fit2])\nVisualization is possible via custom methods (.iplot() & .coefplot()), but a new module allows to visualize a list of Feols and/or Fepois instances:\nfrom pyfixest.visualize import coefplot, iplot\ncoefplot([fit, fit2])\nThe documentation has been improved (though there is still room for progress), and the code has been cleaned up a bit (also lots of room for improvements)."
  },
  {
    "objectID": "docs/Replicating-the-Effect.html",
    "href": "docs/Replicating-the-Effect.html",
    "title": "",
    "section": "",
    "text": "This notebook replicates code examples from Nick Huntington-Klein’s book on causal inference, The Effect.\n\n%load_ext autoreload\n%autoreload 2\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.estimation import feols\nfrom pyfixest.summarize import summary\n\n\n            \n            \n            \n\n\n\n\n\nfrom causaldata import Mroz\n\n# Read in data\ndt = Mroz.load_pandas().data\n# Keep just working women\ndt = dt[dt[\"lfp\"] == True]\n# Create unlogged earnings\ndt.loc[:, \"earn\"] = dt[\"lwg\"].apply(\"exp\")\n\n# 5. Run multiple linear regression models by succesively adding controls\nfit = feols(fml=\"lwg ~ csw(inc, wc, k5)\", data=dt, vcov=\"iid\")\nfit.summary()\n\nC:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_3680\\3519125210.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  dt.loc[:, \"earn\"] = dt[\"lwg\"].apply(\"exp\")\n\n\n> c:\\users\\alexa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pyfixest\\model_matrix_fixest.py(261)model_matrix_fixest()\n    259 \n    260     import pdb; pdb.set_trace()\n--> 261     if fe is not None:\n    262         if drop_singletons:\n    263             dropped_singleton_bool = detect_singletons(fe.to_numpy())\n\n\n\n\n\n\n\n\n\nfrom causaldata import restaurant_inspections\n\nres = restaurant_inspections.load_pandas().data\nres.inspection_score = res.inspection_score.astype(float)\nres.NumberofLocations = res.NumberofLocations.astype(float)\nres.dtypes\n\nfit = feols(fml=\"inspection_score ~ NumberofLocations\", data=res)\nsummary(fit)\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  iid\nObservations:  27178\n\n| Coefficient       |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept         |     94.866 |        0.046 |  2049.047 |      0.000 |  94.775 |   94.956 |\n| NumberofLocations |     -0.019 |        0.000 |   -43.321 |      0.000 |  -0.020 |   -0.018 |\n---\nRMSE: 6.051  Adj. R2: 0.065  Adj. R2 Within: 0.065\n\n\n\n\n\n\ndf = restaurant_inspections.load_pandas().data\n\nfit1 = feols(\n    fml=\"inspection_score ~ NumberofLocations + I(NumberofLocations^2) + Year\", data=df\n)\nfit2 = feols(fml=\"inspection_score ~ NumberofLocations*Weekend + Year\", data=df)\n\nsummary([fit1, fit2])\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  iid\nObservations:  27178\n\n| Coefficient            |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:-----------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept              |    225.504 |       12.409 |    18.172 |      0.000 | 201.181 |  249.827 |\n| NumberofLocations      |     -0.075 |        0.019 |    -4.041 |      0.000 |  -0.111 |   -0.039 |\n| I(NumberofLocations^2) |      0.056 |        0.019 |     3.009 |      0.003 |   0.020 |    0.093 |\n| Year                   |     -0.065 |        0.006 |   -10.527 |      0.000 |  -0.077 |   -0.053 |\n---\nRMSE: 6.038  Adj. R2: 0.069  Adj. R2 Within: 0.069\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  iid\nObservations:  27178\n\n| Coefficient               |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept                 |    225.126 |       12.415 |    18.134 |      0.000 | 200.793 |  249.460 |\n| NumberofLocations         |     -0.019 |        0.000 |   -43.759 |      0.000 |  -0.020 |   -0.018 |\n| Weekend                   |      1.759 |        0.488 |     3.606 |      0.000 |   0.803 |    2.715 |\n| Year                      |     -0.065 |        0.006 |   -10.494 |      0.000 |  -0.077 |   -0.053 |\n| NumberofLocations:Weekend |     -0.010 |        0.008 |    -1.307 |      0.191 |  -0.025 |    0.005 |\n---\nRMSE: 6.038  Adj. R2: 0.069  Adj. R2 Within: 0.069\n\n\n\n\n\n\nfeols(fml=\"inspection_score ~ Year + Weekend\", data=df, vcov=\"HC3\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: inspection_score\nInference:  HC3\nObservations:  27178\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |    185.380 |       12.150 |    15.257 |      0.000 | 161.564 |  209.196 |\n| Year          |     -0.046 |        0.006 |    -7.551 |      0.000 |  -0.057 |   -0.034 |\n| Weekend       |      2.057 |        0.353 |     5.829 |      0.000 |   1.365 |    2.749 |\n---\nRMSE: 6.248  Adj. R2: 0.003  Adj. R2 Within: 0.003\n\n\n\n\n\n\nfeols(fml=\"inspection_score ~ Year + Weekend\", data=df, vcov={\"CRV1\": \"Weekend\"}).tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      185.380033\n      3.264345\n      56.789343\n      0.011209\n      143.902592\n      226.857474\n    \n    \n      Year\n      -0.045640\n      0.001624\n      -28.107556\n      0.022640\n      -0.066272\n      -0.025008\n    \n    \n      Weekend\n      2.057166\n      0.001401\n      1468.256800\n      0.000434\n      2.039364\n      2.074969\n    \n  \n\n\n\n\n\n\n\n\nfit = feols(fml=\"inspection_score ~ Year + Weekend\", data=df)\nfit.wildboottest(B=999, param=\"Year\")\n\nparam                Year\nt value          -7.55233\nPr(>|t|)              0.0\nbootstrap_type         11\ninference              HC\nimpose_null          True\ndtype: object\n\n\n\n\n\n\n\n\ntba\n\n\n\n\nfrom causaldata import gapminder\n\ngm = gapminder.load_pandas().data\ngm[\"logGDPpercap\"] = gm[\"gdpPercap\"].apply(\"log\")\n\nfit = feols(fml=\"lifeExp ~ C(country) + np.log(gdpPercap)\", data=gm)\nfit.tidy().head()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      -27.773459\n      2.500533\n      -11.107015\n      0.000000e+00\n      -32.678217\n      -22.868701\n    \n    \n      C(country)[T.Albania]\n      17.782625\n      2.195160\n      8.100835\n      1.110223e-15\n      13.476853\n      22.088397\n    \n    \n      C(country)[T.Algeria]\n      5.241055\n      2.214496\n      2.366704\n      1.806875e-02\n      0.897356\n      9.584755\n    \n    \n      C(country)[T.Angola]\n      -13.907122\n      2.201727\n      -6.316460\n      3.481857e-10\n      -18.225777\n      -9.588468\n    \n    \n      C(country)[T.Argentina]\n      8.132158\n      2.272781\n      3.578065\n      3.567229e-04\n      3.674133\n      12.590183\n    \n  \n\n\n\n\n\n\n\n\n# Set our individual and time (index) for our data\nfit = feols(fml=\"lifeExp ~ np.log(gdpPercap) | country + year\", data=gm)\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: lifeExp, Fixed effects: country+year\nInference:  CRV1\nObservations:  1704\n\n| Coefficient       |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:------------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| np.log(gdpPercap) |      1.450 |        0.677 |     2.141 |      0.034 |   0.111 |    2.788 |\n---\nRMSE: 3.267  Adj. R2: 0.018  Adj. R2 Within: 0.018\n\n\n\n\n\n\n\n\n\nfrom causaldata import organ_donations\n\nod = organ_donations.load_pandas().data\n\n# Create Treatment Variable\nod[\"California\"] = od[\"State\"] == \"California\"\nod[\"After\"] = od[\"Quarter_Num\"] > 3\nod[\"Treated\"] = 1 * (od[\"California\"] & od[\"After\"])\n\ndid = feols(fml=\"Rate ~ Treated | State + Quarter\", data=od)\ndid.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Rate, Fixed effects: State+Quarter\nInference:  CRV1\nObservations:  162\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Treated       |     -0.022 |        0.006 |    -3.733 |      0.001 |  -0.035 |   -0.010 |\n---\nRMSE: 0.022  Adj. R2: 0.003  Adj. R2 Within: 0.003\n\n\n\n\n\n\nfrom causaldata import organ_donations\nfrom pyfixest.visualize import iplot\n\nod = organ_donations.load_pandas().data\n\n# Create Treatment Variable\nod[\"California\"] = od[\"State\"] == \"California\"\n# od[\"Quarter_Num\"] = pd.Categorical(od.Quarter_Num)\nod[\"California\"] = od.California.astype(float)\n\ndid2 = feols(\n    fml=\"Rate ~ i(Quarter_Num, California) | State + Quarter_Num\", data=od, i_ref1=3\n)\n\ndid2.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.1]:California\n      -0.002942\n      0.004986\n      -0.590105\n      0.560215\n      -0.013191\n      0.007307\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.2]:California\n      0.006296\n      0.002222\n      2.833502\n      0.008782\n      0.001729\n      0.010864\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.4]:California\n      -0.021565\n      0.004937\n      -4.368464\n      0.000178\n      -0.031713\n      -0.011418\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.5]:California\n      -0.020292\n      0.004387\n      -4.625529\n      0.000090\n      -0.029310\n      -0.011275\n    \n    \n      C(Quarter_Num,contr.treatment(base=3))[T.6]:California\n      -0.022165\n      0.009820\n      -2.257160\n      0.032627\n      -0.042351\n      -0.001980"
  },
  {
    "objectID": "docs/tutorial.html",
    "href": "docs/tutorial.html",
    "title": "",
    "section": "",
    "text": "In a first step, we load the module and some example data:\n\n%load_ext autoreload\n%autoreload 2\n\nfrom pyfixest.estimation import feols, fepois\nfrom pyfixest.summarize import summary, etable\nfrom pyfixest.visualize import coefplot, iplot\nfrom pyfixest.utils import get_data\n\n\n            \n            \n            \n\n\n\ndata = get_data()\ndata.head()\n\n\n\n\n\n  \n    \n      \n      Y\n      Y2\n      X1\n      X2\n      f1\n      f2\n      f3\n      group_id\n      Z1\n      Z2\n    \n  \n  \n    \n      0\n      NaN\n      2.357103\n      0.0\n      0.457858\n      15.0\n      0.0\n      7.0\n      9.0\n      -0.330607\n      1.054826\n    \n    \n      1\n      -1.458643\n      5.163147\n      NaN\n      -4.998406\n      6.0\n      21.0\n      4.0\n      8.0\n      NaN\n      -4.113690\n    \n    \n      2\n      0.169132\n      0.751140\n      2.0\n      1.558480\n      NaN\n      1.0\n      7.0\n      16.0\n      1.207778\n      0.465282\n    \n    \n      3\n      3.319513\n      -2.656368\n      1.0\n      1.560402\n      1.0\n      10.0\n      11.0\n      3.0\n      2.869997\n      0.467570\n    \n    \n      4\n      0.134420\n      -1.866416\n      2.0\n      -3.472232\n      19.0\n      20.0\n      6.0\n      14.0\n      0.835819\n      -3.115669\n    \n  \n\n\n\n\n\n\nWe can estimate a fixed effects regression via the feols() function. feols() has three arguments: a two-sided model formula, the data, and optionally, the type of inference.\n\nfit = feols(fml=\"Y~X1 | f1\", data=data, vcov=\"HC1\")\ntype(fit)\n\npyfixest.feols.Feols\n\n\nThe first part of the formula contains the dependent variable and “regular” covariates, while the second part contains fixed effects.\nfeols() returns an instance of the Fixest class.\nTo inspect the results, we can use a summary function or method:\n\nfit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.066 |   -14.311 |      0.000 |  -1.080 |   -0.819 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n\n\nAlternatively, the .summarize module contains a summary function, which can be applied on instances of regression model objects or lists of regression model objects.\n\nsummary(fit)\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.066 |   -14.311 |      0.000 |  -1.080 |   -0.819 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n\n\nYou can access individual elements of the summary via dedicated methods: .tidy() returns a “tidy” pd.DataFrame, .coef() returns estimated parameters, and se() estimated standard errors. Other methods include pvalue(), confint() and tstat().\n\nfit.coef()\n\nCoefficient\nX1   -0.949441\nName: Estimate, dtype: float64\n\n\n\nfit.se()\n\nCoefficient\nX1    0.066343\nName: Std. Error, dtype: float64\n\n\n\n\n\nSupported covariance types are “iid”, “HC1-3”, CRV1 and CRV3 (up to two-way clustering). Inference can be adjusted “on-the-fly” via the .vcov() method:\n\nfit.vcov({\"CRV1\": \"group_id + f1\"}).summary()\nfit.vcov({\"CRV3\": \"group_id\"}).summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.088 |   -10.839 |      0.000 |  -1.133 |   -0.765 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  CRV3\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.095 |   -10.005 |      0.000 |  -1.149 |   -0.750 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n\n\nIt is also possible to run a wild (cluster) bootstrap after estimation (via the wildboottest module):\n\nfit2 = feols(fml=\"Y~ X1\", data=data, vcov={\"CRV1\": \"group_id\"})\nfit2.wildboottest(param=\"X1\", B=999)\n\nparam                            X1\nt value                   -8.567587\nPr(>|t|)                        0.0\nbootstrap_type                   11\ninference         CRV(['group_id'])\nimpose_null                    True\ndtype: object\n\n\nNote that the wild bootstrap currently does not support fixed effects in the regression model. Supporting fixed effects is work in progress.\n\n\n\nIt is also possible to estimate instrumental variable models with one endogenous variable and (potentially multiple) instruments:\n\niv_fit = feols(fml=\"Y2~ 1 | f1 + f2 | X1 ~ Z1 + Z2\", data=data)\niv_fit.summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y2, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -1.600 |        0.333 |    -4.801 |      0.000 |  -2.282 |   -0.919 |\n---\n\n\nIf the model does not contain any fixed effects, just drop the second part of the formula above:\n\nfeols(fml=\"Y~ 1 | X1 ~ Z1 + Z2\", data=data).summary()\n\n###\n\nEstimation:  IV\nDep. var.: Y\nInference:  iid\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.911 |        0.156 |     5.843 |      0.000 |   0.605 |    1.217 |\n| X1            |     -0.993 |        0.134 |    -7.398 |      0.000 |  -1.256 |   -0.730 |\n---\n\n\nIV estimation with multiple endogenous variables and multiple estimation syntax is currently not supported. The syntax is “depvar ~ exog.vars | fixef effects | endog.vars ~ instruments”.\n\n\n\nWith version 0.8.4, it is possible to estimate Poisson Regressions (not yet on PyPi):\n\nfrom pyfixest.utils import get_data\n\npois_data = get_data(model=\"Fepois\")\npois_fit = fepois(fml=\"Y~X1 | f1+f2\", data=pois_data, vcov={\"CRV1\": \"group_id\"})\npois_fit.summary()\n\n###\n\nEstimation:  Poisson\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.007 |        0.031 |    -0.237 |      0.813 |  -0.069 |    0.054 |\n---\nDeviance: 1070.729\n\n\n\n\n\nPyFixest supports a range of multiple estimation functionality: sw, sw0, csw, csw0, and multiple dependent variables. If multiple regression syntax is used, feols() and fepois returns an instance of a FixestMulti object, which essentially consists of a dicionary of Fepois or Feols instances.\n\nmulti_fit = feols(fml=\"Y~X1 | csw0(f1, f2)\", data=data, vcov=\"HC1\")\nmulti_fit\n\n<pyfixest.FixestMulti.FixestMulti at 0x23bd899c3d0>\n\n\n\nmulti_fit.summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y\nInference:  HC1\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.919 |        0.112 |     8.223 |      0.000 |   0.699 |    1.138 |\n| X1            |     -1.000 |        0.082 |   -12.134 |      0.000 |  -1.162 |   -0.838 |\n---\nRMSE: 2.158   R2: 0.123\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.066 |   -14.311 |      0.000 |  -1.080 |   -0.819 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  HC1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.919 |        0.058 |   -15.918 |      0.000 |  -1.033 |   -0.806 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\n\nAlternatively, you can look at the estimation results via the etable() method:\n\nmulti_fit.etable()\n\n\n\n\n\n  \n    \n      fml\n      Y~X1\n      Y~X1|f1\n      Y~X1|f1+f2\n    \n    \n      Coefficient\n      Intercept\n      X1\n      X1\n      X1\n    \n  \n  \n    \n      Estimate\n      0.919\n      -1.000\n      -0.949\n      -0.919\n    \n    \n      Std. Error\n      0.112\n      0.082\n      0.066\n      0.058\n    \n    \n      t value\n      8.223\n      -12.134\n      -14.311\n      -15.918\n    \n    \n      Pr(>|t|)\n      0.000\n      0.000\n      0.000\n      0.000\n    \n    \n      2.5 %\n      0.699\n      -1.162\n      -1.080\n      -1.033\n    \n    \n      97.5 %\n      1.138\n      -0.838\n      -0.819\n      -0.806\n    \n  \n\n\n\n\nIf you are only insterested in some parameters, e.g. “X1”, you can use the following syntax:\n\nmulti_fit.etable().xs(\"X1\", level=1, axis=1)\n\n\n\n\n\n  \n    \n      fml\n      Y~X1\n      Y~X1|f1\n      Y~X1|f1+f2\n    \n  \n  \n    \n      Estimate\n      -1.000\n      -0.949\n      -0.919\n    \n    \n      Std. Error\n      0.082\n      0.066\n      0.058\n    \n    \n      t value\n      -12.134\n      -14.311\n      -15.918\n    \n    \n      Pr(>|t|)\n      0.000\n      0.000\n      0.000\n    \n    \n      2.5 %\n      -1.162\n      -1.080\n      -1.033\n    \n    \n      97.5 %\n      -0.838\n      -0.819\n      -0.806\n    \n  \n\n\n\n\nYou can access an individual model by its name - i.e. a formula - via the all_fitted_models attribure.\n\nmulti_fit.all_fitted_models[\"Y~X1\"].tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      0.918518\n      0.111707\n      8.222580\n      6.661338e-16\n      0.699310\n      1.137725\n    \n    \n      X1\n      -1.000086\n      0.082420\n      -12.134086\n      0.000000e+00\n      -1.161822\n      -0.838350\n    \n  \n\n\n\n\nor equivalently via the fetch_model method:\n\nmulti_fit.fetch_model(0).tidy()\n\nModel:  Y~X1\n\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      0.918518\n      0.111707\n      8.222580\n      6.661338e-16\n      0.699310\n      1.137725\n    \n    \n      X1\n      -1.000086\n      0.082420\n      -12.134086\n      0.000000e+00\n      -1.161822\n      -0.838350\n    \n  \n\n\n\n\nHere, 0 simply fetches the first model stored in the all_fitted_models dictionary, 1 the second etc.\nObjects of type Fixest come with a range of additional methods: tidy(), coef(), vcov() etc, which essentially loop over the equivalent methods of all fitted models. E.g. Fixest.vcov() updates inference for all models stored in Fixest.\n\nmulti_fit.vcov(\"iid\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y\nInference:  iid\nObservations:  998\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| Intercept     |      0.919 |        0.112 |     8.214 |      0.000 |   0.699 |    1.138 |\n| X1            |     -1.000 |        0.085 |   -11.802 |      0.000 |  -1.166 |   -0.834 |\n---\nRMSE: 2.158   R2: 0.123\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.949 |        0.069 |   -13.846 |      0.000 |  -1.084 |   -0.815 |\n---\nRMSE: 1.73   R2: 0.437   R2 Within: 0.161\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.919 |        0.058 |   -15.797 |      0.000 |  -1.033 |   -0.805 |\n---\nRMSE: 1.441   R2: 0.609   R2 Within: 0.2\n\n\nIf you have estimated multiple models without multiple estimation syntax and still want to compare them, you can use the etable() function:\n\nfrom pyfixest.summarize import etable\n\netable([fit, fit2])\n\n                           est1              est2\n------------  -----------------  ----------------\ndepvar                        Y                 Y\n-------------------------------------------------\nX1            -0.949*** (0.095)   -1.0*** (0.117)\nIntercept                        0.919*** (0.121)\n-------------------------------------------------\nf1                            x                 -\n-------------------------------------------------\nR2                        0.437             0.123\nS.E. type          by: group_id      by: group_id\nObservations                997               998\n-------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\n\n\n\nPyFixest provides two functions to visualize the results of a regression: coefplot and iplot.\n\nfrom lets_plot import *\n\nLetsPlot.setup_html()\n\nmulti_fit.coefplot().show()\n\n\n            \n            \n            \n\n\n   \n   \n\n\n\n\n\nPyFixest supports eventy study designs via two-way fixed effects and Gardner’s 2-stage estimator.\n\nimport pandas as pd\nimport numpy as np\nfrom pyfixest.did.did2s import did2s\n\nurl = \"https://raw.githubusercontent.com/s3alfisc/pyfixest/master/pyfixest/did/data/df_het.csv\"\ndf_het = pd.read_csv(url)\ndf_het.head()\n\n\n\n\n\n  \n    \n      \n      unit\n      state\n      group\n      unit_fe\n      g\n      year\n      year_fe\n      treat\n      rel_year\n      rel_year_binned\n      error\n      te\n      te_dynamic\n      dep_var\n    \n  \n  \n    \n      0\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1990\n      0.066159\n      False\n      -20.0\n      -6\n      -0.086466\n      0\n      0.0\n      7.022709\n    \n    \n      1\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1991\n      -0.030980\n      False\n      -19.0\n      -6\n      0.766593\n      0\n      0.0\n      7.778628\n    \n    \n      2\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1992\n      -0.119607\n      False\n      -18.0\n      -6\n      1.512968\n      0\n      0.0\n      8.436377\n    \n    \n      3\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1993\n      0.126321\n      False\n      -17.0\n      -6\n      0.021870\n      0\n      0.0\n      7.191207\n    \n    \n      4\n      1\n      33\n      Group 2\n      7.043016\n      2010\n      1994\n      -0.106921\n      False\n      -16.0\n      -6\n      -0.017603\n      0\n      0.0\n      6.918492\n    \n  \n\n\n\n\n\nfit_did2s = did2s(\n    df_het,\n    yname=\"dep_var\",\n    first_stage=\"~ 0 | state + year\",\n    second_stage=\"~i(rel_year)\",\n    treatment=\"treat\",\n    cluster=\"state\",\n    i_ref1=[-1.0, np.inf],\n)\n\nfit_twfe = feols(\n    \"dep_var ~ i(rel_year) | state + year\",\n    df_het,\n    i_ref1=[-1.0, np.inf],\n    vcov={\"CRV1\": \"state\"},\n)\n\niplot(\n    [fit_did2s, fit_twfe], coord_flip=False, figsize=(900, 400), title=\"TWFE vs DID2S\"\n)\n\n   \n   \n\n\nThe event_study() function provides a common API for several event study estimators.\n\nfrom pyfixest.did.event_study import event_study\nfrom pyfixest.summarize import etable\n\nfit_twfe = event_study(\n    data=df_het,\n    yname=\"dep_var\",\n    idname=\"state\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"twfe\",\n)\n\nfit_did2s = event_study(\n    data=df_het,\n    yname=\"dep_var\",\n    idname=\"state\",\n    tname=\"year\",\n    gname=\"g\",\n    estimator=\"did2s\",\n)\n\netable([fit_twfe, fit_did2s])\n\n                          est1              est2\n------------  ----------------  ----------------\ndepvar                 dep_var       dep_var_hat\n------------------------------------------------\nATT           2.135*** (0.044)  2.152*** (0.048)\n------------------------------------------------\nstate                        x                 -\nyear                         x                 -\n------------------------------------------------\nR2                           -                 -\nS.E. type            by: state              CRV1\nObservations             46500             46500\n------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "",
    "section": "",
    "text": "Copyright (c) 2022 pyfixest authors\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "reference/detect_singletons.detect_singletons.html",
    "href": "reference/detect_singletons.detect_singletons.html",
    "title": "",
    "section": "",
    "text": "detect_singletons.detect_singletons(ids)\nDetect singleton fixed effects in a dataset.\nThis function iterates over the columns of a 2D numpy array representing fixed effects to identify singleton fixed effects. An observation is considered a singleton if it is the only one in its group (fixed effect identifier).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nids\nnumpy.numpy.ndarray\nA 2D numpy array representing fixed effects, with a shape of (n_samples, n_features). Elements should be non-negative integers representing fixed effect identifiers.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnumpy.numpy.ndarray\nA boolean array of shape (n_samples,), indicating which observations have a singleton fixed effect.\n\n\n\n\n\n\nThe algorithm iterates over columns to identify fixed effects. After each column is processed, it updates the record of non-singleton rows. This approach accounts for the possibility that removing an observation in one column can lead to the emergence of new singletons in subsequent columns.\nFor performance reasons, the input array should be in column-major order. Operating on a row-major array can lead to significant performance losses."
  },
  {
    "objectID": "reference/estimation.feols.html",
    "href": "reference/estimation.feols.html",
    "title": "",
    "section": "",
    "text": "estimation.feols(fml, data, vcov=None, ssc=ssc(), fixef_rm='none', collin_tol=1e-10, drop_intercept=False, i_ref1=None, i_ref2=None)\nEstimate linear regression models with fixed effects using fixest formula syntax.\nThis method accommodates complex models with stepwise regressions, multiple dependent variables, interaction of variables, interacted fixed effects, and instruments. It’s compatible with various syntax elements from the formulaic module.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfml\nstr\nA three-sided formula string using fixest formula syntax. Syntax: “Y ~ X1 + X2 | FE1 + FE2 | X1 ~ Z1”. “|” separates dependent variable, fixed effects, and instruments. Special syntax includes stepwise regressions, cumulative stepwise regression, multiple dependent variables, interaction of variables (i(X1,X2)), and interacted fixed effects (fe1^fe2).\nrequired\n\n\ndata\npyfixest.dev_utils.DataFrameType\nA pandas or polars dataframe containing the variables in the formula.\nrequired\n\n\nvcov\ntyping.Union[str, dict[str, str]]\nType of variance-covariance matrix for inference. Options include “iid”, “hetero”, “HC1”, “HC2”, “HC3”, or a dictionary for CRV1/CRV3 inference.\nNone\n\n\nssc\nstr\nA ssc object specifying the small sample correction for inference.\nssc()\n\n\nfixef_rm\nstr\nSpecifies whether to drop singleton fixed effects. Options: “none” (default), “singleton”.\n'none'\n\n\ncollin_tol\nfloat\nTolerance for collinearity check, by default 1e-06.\n1e-10\n\n\ndrop_intercept\nbool\nWhether to drop the intercept from the model, by default False.\nFalse\n\n\ni_ref1\ntyping.Optional[typing.Union[list, str]]\nReference category for the first set of categorical variables interacted via “i()”, by default None.\nNone\n\n\ni_ref2\ntyping.Optional[typing.Union[list, str]]\nReference category for the second set of categorical variables interacted via “i()”, by default None.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nobject\nAn instance of the Feols class or FixestMulti class for multiple models specified via fml.\n\n\n\n\n\n\nAs in fixest, the feols function can be used to estimate a simple linear regression model with fixed effects. The following example regresses Y on X1 and X2 with fixed effects for f1 and f2: fixed effects are specified after the | symbol.\n\nfrom pyfixest.estimation import feols\nfrom pyfixest.utils import get_data\nfrom pyfixest.summarize import etable\n\ndata = get_data()\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.summary()\n\n\n            \n            \n            \n\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.924 |        0.061 |   -15.165 |      0.000 |  -1.049 |   -0.799 |\n| X2            |     -0.174 |        0.015 |   -11.918 |      0.000 |  -0.204 |   -0.144 |\n---\nRMSE: 1.346   R2: 0.659   R2 Within: 0.303\n\n\nCalling feols() returns an instance of the Feols class. The summary() method can be used to print the results.\nAn alternative way to retrieve model results is via the tidy() method, which returns a pandas dataframe with the estimated coefficients, standard errors, t-statistics, and p-values.\n\nfit.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      X1\n      -0.924046\n      0.060934\n      -15.164621\n      2.664535e-15\n      -1.048671\n      -0.799421\n    \n    \n      X2\n      -0.174107\n      0.014608\n      -11.918277\n      1.069367e-12\n      -0.203985\n      -0.144230\n    \n  \n\n\n\n\nYou can also access all elements in the tidy data frame by dedicated methods, e.g. fit.coef() for the coefficients, fit.se() for the standard errors, fit.tstat() for the t-statistics, and fit.pval() for the p-values, and fit.confint() for the confidence intervals.\nThe employed type of inference can be specified via the vcov argument. If vcov is not provided, PyFixest employs the fixest default of iid inference, unless there are fixed effects in the model, in which case feols() clusters the standard error by the first fixed effect (CRV1 inference).\n\nfit1 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov=\"iid\")\nfit2 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov=\"hetero\")\nfit3 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov={\"CRV1\": \"f1\"})\n\nSupported inference types are “iid”, “hetero”, “HC1”, “HC2”, “HC3”, and “CRV1”/“CRV3”. Clustered standard errors are specified via a dictionary, e.g. {\"CRV1\": \"f1\"} for CRV1 inference with clustering by f1 or {\"CRV3\": \"f1\"} for CRV3 inference with clustering by f1. For two-way clustering, you can provide a formula string, e.g. {\"CRV1\": \"f1 + f2\"} for CRV1 inference with clustering by f1.\n\nfit4 = feols(\"Y ~ X1 + X2 | f1 + f2\", data, vcov={\"CRV1\": \"f1 + f2\"})\n\nInference can be adjusted post estimation via the vcov method:\n\nfit.summary()\nfit.vcov(\"iid\").summary()\n\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  CRV1\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.924 |        0.061 |   -15.165 |      0.000 |  -1.049 |   -0.799 |\n| X2            |     -0.174 |        0.015 |   -11.918 |      0.000 |  -0.204 |   -0.144 |\n---\nRMSE: 1.346   R2: 0.659   R2 Within: 0.303\n###\n\nEstimation:  OLS\nDep. var.: Y, Fixed effects: f1+f2\nInference:  iid\nObservations:  997\n\n| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n| X1            |     -0.924 |        0.054 |   -16.995 |      0.000 |  -1.031 |   -0.817 |\n| X2            |     -0.174 |        0.014 |   -12.081 |      0.000 |  -0.202 |   -0.146 |\n---\nRMSE: 1.346   R2: 0.659   R2 Within: 0.303\n\n\nThe ssc argument specifies the small sample correction for inference. In general, feols() uses all of fixest::feols() defaults, but sets the fixef.K argument to \"none\" whereas the fixest::feols() default is \"nested\". See here for more details: link to github.\nfeols() supports a range of multiple estimation syntax, i.e. you can estimate multiple models in one call. The following example estimates two models, one with fixed effects for f1 and one with fixed effects for f2 using the sw() syntax.\n\nfit = feols(\"Y ~ X1 + X2 | sw(f1, f2)\", data)\ntype(fit)\n\npyfixest.FixestMulti.FixestMulti\n\n\nThe returned object is an instance of the FixestMulti class. You can access the results of the first model via fit.fetch_model(0) and the results of the second model via fit.fetch_model(1). You can compare the model results via the etable() function:\n\netable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f2\n                           est1               est2\n------------  -----------------  -----------------\ndepvar                        Y                  Y\n--------------------------------------------------\nX1             -0.95*** (0.067)  -0.979*** (0.077)\nX2            -0.174*** (0.018)  -0.175*** (0.022)\n--------------------------------------------------\nf2                            -                  x\nf1                            x                  -\n--------------------------------------------------\nR2                        0.489              0.354\nS.E. type                by: f1             by: f2\nObservations                997                998\n--------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nOther supported multiple estimation syntax include sw0(), csw() and csw0(). While sw() adds variables in a “stepwise” fashinon, csw() does so cumulatively.\n\nfit = feols(\"Y ~ X1 + X2 | csw(f1, f2)\", data)\netable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f1+f2\n                           est1               est2\n------------  -----------------  -----------------\ndepvar                        Y                  Y\n--------------------------------------------------\nX1             -0.95*** (0.067)  -0.924*** (0.061)\nX2            -0.174*** (0.018)  -0.174*** (0.015)\n--------------------------------------------------\nf2                            -                  x\nf1                            x                  x\n--------------------------------------------------\nR2                        0.489              0.659\nS.E. type                by: f1             by: f1\nObservations                997                997\n--------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nThe sw0() and csw0() syntax are similar to sw() and csw(), but start with a model that exludes the variables specified in sw() and csw():\n\nfit = feols(\"Y ~ X1 + X2 | sw0(f1, f2)\", data)\netable([fit.fetch_model(0), fit.fetch_model(1), fit.fetch_model(2)])\n\nModel:  Y~X1+X2\nModel:  Y~X1+X2|f1\nModel:  Y~X1+X2|f2\n                           est1               est2               est3\n------------  -----------------  -----------------  -----------------\ndepvar                        Y                  Y                  Y\n---------------------------------------------------------------------\nIntercept      0.889*** (0.108)\nX1            -0.993*** (0.082)   -0.95*** (0.067)  -0.979*** (0.077)\nX2            -0.176*** (0.022)  -0.174*** (0.018)  -0.175*** (0.022)\n---------------------------------------------------------------------\nf2                            -                  -                  x\nf1                            -                  x                  -\n---------------------------------------------------------------------\nR2                        0.177              0.489              0.354\nS.E. type                   iid             by: f1             by: f2\nObservations                998                997                998\n---------------------------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nThe feols() function also supports multiple dependent variables. The following example estimates two models, one with Y1 as the dependent variable and one with Y2 as the dependent variable.\n\nfit = feols(\"Y + Y2 ~ X1 | f1 + f2\", data)\netable([fit.fetch_model(0), fit.fetch_model(1)])\n\nModel:  Y~X1|f1+f2\nModel:  Y2~X1|f1+f2\n                           est1               est2\n------------  -----------------  -----------------\ndepvar                        Y                 Y2\n--------------------------------------------------\nX1            -0.919*** (0.065)  -1.228*** (0.195)\n--------------------------------------------------\nf2                            x                  x\nf1                            x                  x\n--------------------------------------------------\nR2                        0.609              0.168\nS.E. type                by: f1             by: f1\nObservations                997                998\n--------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nIt is possible to combine different multiple estimation operators:\n\nfit = feols(\"Y + Y2 ~ X1 | sw(f1, f2)\", data)\netable([fit.fetch_model(0), fit.fetch_model(1), fit.fetch_model(2), fit.fetch_model(3)])\n\nModel:  Y~X1|f1\nModel:  Y2~X1|f1\nModel:  Y~X1|f2\nModel:  Y2~X1|f2\n                           est1               est2               est3               est4\n------------  -----------------  -----------------  -----------------  -----------------\ndepvar                        Y                 Y2                  Y                 Y2\n----------------------------------------------------------------------------------------\nX1            -0.949*** (0.069)  -1.266*** (0.176)  -0.982*** (0.081)  -1.301*** (0.205)\n----------------------------------------------------------------------------------------\nf2                            -                  -                  x                  x\nf1                            x                  x                  -                  -\n----------------------------------------------------------------------------------------\nR2                        0.437              0.115              0.302               0.09\nS.E. type                by: f1             by: f1             by: f2             by: f2\nObservations                997                998                998                999\n----------------------------------------------------------------------------------------\nSignificance levels: * p < 0.05, ** p < 0.01, *** p < 0.001\n\n\nIn general, using muliple estimation syntax can improve the estimation time as covariates that are demeaned in one model and are used in another model do not need to be demeaned again: feols() implements a caching mechanism that stores the demeaned covariates.\nBesides OLS, feols() also supports IV estimation via three part formulas:\n\nfit = feols(\"Y ~  X2 | f1 + f2 | X1 ~ Z1\", data)\nfit.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      X1\n      -1.050097\n      0.085493\n      -12.282912\n      5.133671e-13\n      -1.224949\n      -0.875245\n    \n    \n      X2\n      -0.174351\n      0.014779\n      -11.797039\n      1.369793e-12\n      -0.204578\n      -0.144124\n    \n  \n\n\n\n\nHere, X1 is the endogenous variable and Z1 is the instrument. f1 and f2 are the fixed effects, as before. To estimate IV models without fixed effects, simply omit the fixed effects part of the formula:\n\nfit = feols(\"Y ~  X2 | X1 ~ Z1\", data)\nfit.tidy()\n\n\n\n\n\n  \n    \n      \n      Estimate\n      Std. Error\n      t value\n      Pr(>|t|)\n      2.5 %\n      97.5 %\n    \n    \n      Coefficient\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Intercept\n      0.861939\n      0.151187\n      5.701137\n      1.567858e-08\n      0.565257\n      1.158622\n    \n    \n      X1\n      -0.967238\n      0.130078\n      -7.435847\n      2.238210e-13\n      -1.222497\n      -0.711980\n    \n    \n      X2\n      -0.176416\n      0.021769\n      -8.104001\n      1.554312e-15\n      -0.219134\n      -0.133697\n    \n  \n\n\n\n\nLast, feols() supports interaction of variables via the i() syntax. Documentation on this is tba.\nAfter fitting a model via feols(), you can use the predict() method to get the predicted values:\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.predict()[0:5]\n\narray([ 3.0633663 , -0.69574133, -0.91240433, -0.46370257, -1.67331154])\n\n\nThe predict() method also supports a newdata argument to predict on new data, which returns a numpy array of the predicted values:\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.predict(newdata=data)[0:5]\n\narray([ 2.14598765,         nan,         nan,  3.0633663 , -0.69574133])\n\n\nLast, you can plot the results of a model via the coefplot() method:\n\nfit = feols(\"Y ~ X1 + X2 | f1 + f2\", data)\nfit.coefplot()"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "",
    "section": "",
    "text": "PyFixest internals and utilities\n\n\n\ndemean"
  },
  {
    "objectID": "tests/readme.html",
    "href": "tests/readme.html",
    "title": "",
    "section": "",
    "text": "Check How close PyFixest reproduces standard errors produced via fixest and stats::glm\nTest PyFixest against fixest\npandas needs to be a version lower than 1.5.3 to be compatible with rpy2, else you’ll run into this error. The github actions for testing ensures that pandas is of a version lower than 1.5.3."
  },
  {
    "objectID": "reference/demean.demean.html",
    "href": "reference/demean.demean.html",
    "title": "",
    "section": "",
    "text": "demean.demean(x, flist, weights, tol=1e-08, maxiter=100000)"
  },
  {
    "objectID": "reference/demean.html",
    "href": "reference/demean.html",
    "title": "",
    "section": "",
    "text": "demean\n\n\n\n\n\nName\nDescription\n\n\n\n\ndemean_model\nDemeans a single regression model.\n\n\n\n\n\ndemean.demean_model(Y, X, fe, weights, lookup_demeaned_data, na_index_str)\nDemeans a single regression model.\nIf the model has fixed effects, the fixed effects are demeaned using the PyHDFE package. Prior to demeaning, the function checks if some of the variables have already been demeaned and uses values from the cache lookup_demeaned_data if possible. If the model has no fixed effects, the function does not demean the data.\nArgs: Y (pd.DataFrame): A DataFrame of the dependent variable. X (pd.DataFrame): A DataFrame of the covariates. fe (pd.DataFrame or None): A DataFrame of the fixed effects. None if no fixed effects specified. weights (np.ndarray or None): A numpy array of weights. None if no weights. lookup_demeaned_data (Dict[str, Any]): A dictionary with keys for each fixed effects combination and potentially values of demeaned data frames. The function checks this dictionary to see if some of the variables have already been demeaned. na_index_str (str): A string with indices of dropped columns. Used for caching of demeaned variables.\nReturns: Tuple[pd.DataFrame, pd.DataFrame, Optional[pd.DataFrame]]: A tuple of the following elements: - Yd (pd.DataFrame): A DataFrame of the demeaned dependent variable. - Xd (pd.DataFrame): A DataFrame of the demeaned covariates. - Id (pd.DataFrame or None): A DataFrame of the demeaned Instruments. None if no IV."
  }
]